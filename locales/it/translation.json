{
  "AISettings": "Impostazioni AI",
  "APIKeyInstruction": "Puoi ottenere la chiave API qui sotto. Inserisci la chiave API ottenuta nel modulo.",
  "APIKeyNotEntered": "Chiave API non inserita.",
  "AboutThisApplication": "Informazioni sull'applicazione",
  "AboutThisApplicationDescription": "Interagisci con un personaggio 3D direttamente nel browser tramite microfono o testo e sintesi vocale. Puoi cambiare il personaggio (VRM), regolare la personalità e la voce del personaggio.\nLe impostazioni possono essere modificate dal pulsante menu in alto a sinistra.",
  "AboutThisApplicationDescription2": "Se vuoi cambiare personaggio, consulta la scheda \"Impostazioni personaggio\".",
  "AivisSpeechInfo": "Utilizza AivisSpeech. Supporta solo il giapponese. Usa API locale, devi scaricare e avviare l'applicazione adatta al tuo sistema.",
  "AivisSpeechIntonation": "Intonazione",
  "AivisSpeechPitch": "Tono",
  "AivisSpeechServerUrl": "URL server AivisSpeech",
  "AivisSpeechSpeaker": "Speaker",
  "AivisSpeechSpeed": "Velocità",
  "AnswerGenerating": "Generazione risposta",
  "AnthropicAPIKeyLabel": "Chiave API Anthropic",
  "AudioMode": "Modalità audio",
  "AuthFileInstruction": "È richiesta una chiave API o file di autenticazione. Ottienila dall'URL sotto e posizionala nella root se è un file JSON.",
  "AzureAPIKeyLabel": "Chiave API Azure OpenAI",
  "AzureAPIURL": "URL API Azure OpenAI",
  "AzureEndpoint": "Endpoint Azure",
  "AzureTTSInfo": "Usando Azure OpenAI. Supporta più lingue.",
  "BackgroundImage": "Immagine di sfondo",
  "BackgroundSettings": "Impostazioni dello sfondo",
  "BackgroundSettingsDescription": "You can translate the Japanese text to Italian as follows:\n\n\"Puoi caricare e selezionare l'immagine di sfondo dell'applicazione.",
  "BasedSettings": "Impostazioni di base",
  "BrowserSpeechRecognition": "Utilizza il riconoscimento vocale standard del browser",
  "CannotUseParameters": "Se la modalità API in tempo reale o la modalità audio è attivata, i parametri Temperature e Max Tokens non possono essere specificati.",
  "CannotUseVoice": "Se la modalità API in tempo reale o la modalità audio è attivata,\nle impostazioni della voce sintetizzata non sono necessarie.",
  "ChangeBackgroundImage": "Cambia immagine di sfondo",
  "CharacterModelInfo": "Il modello potrebbe richiedere tempo per caricarsi alla prima visualizzazione.",
  "CharacterModelLabel": "Modello personaggio",
  "CharacterName": "Nome personaggio",
  "CharacterSettings": "Impostazioni del personaggio",
  "CharacterSettingsInfo": "Questo valore viene impostato come prompt di sistema.\nFai riferimento al prompt iniziale e specifica i tag delle emozioni per controllare le espressioni e i movimenti del personaggio. Esempio: [neutral]Buongiorno![happy]Anche oggi sarà una giornata impegnativa!",
  "CharacterSettingsPrompt": "Prompt personaggio",
  "Characterpreset1": "Preset 1",
  "Characterpreset2": "Preset 2",
  "Characterpreset3": "Preset 3",
  "Characterpreset4": "Preset 4",
  "Characterpreset5": "Preset 5",
  "CharacterpresetInfo": "Selezionando un preset, il prompt del personaggio verrà modificato.\nCmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows) per utilizzare le scorciatoie.",
  "ChatLog": "Log chat",
  "ClientID": "ID cliente",
  "Close": "CHIUDI",
  "CohereAPIKeyLabel": "Chiave API Cohere",
  "Contact": "Contatti",
  "ContactDescription": "Per domande su questa applicazione, contattaci tramite l'indirizzo email o l'account Twitter sotto.",
  "ContinuousMic": "Input microfono continuo",
  "ContinuousMicActive": "Input microfono continuo attivo",
  "ContinuousMicInfo": "Il microfono riprenderà automaticamente l'input quando l'AI termina di parlare. Verrà inviato automaticamente dopo il tempo di silenzio impostato.\nSe il tempo impostato viene superato senza riconoscimento vocale, l'input microfono continuo si disattiverà automaticamente, quindi se desideri mantenerlo sempre attivo, imposta il timeout per il riconoscimento vocale a 0 secondi.",
  "ContinuousMicModeOff": "La modalità di input microfono continuo è disattivata",
  "ContinuousMicModeOn": "La modalità di input microfono continuo è attivata",
  "ConversationContinuityMode": "Modalità continuità conversazione (Beta)",
  "ConversationContinuityModeInfo": "Quando non ci sono commenti, l'IA cerca di continuare la conversazione. Attualmente supportato solo da OpenAI, Anthropic Claude, Google Gemini.",
  "ConversationContinuityModeInfo2": "Una risposta richiede più chiamate LLM, quindi l'utilizzo dell'API potrebbe aumentare. Si prega di tenerne conto.",
  "ConversationContinuityModeInfo3": "gpt-4, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet funzionano in modo relativamente stabile.",
  "ConversationHistory": "Cronologia conversazione",
  "ConversationHistoryInfo": "Le ultime {{count}} conversazioni saranno memorizzate come memoria.",
  "ConversationHistoryReset": "Reimposta cronologia conversazione",
  "Creator": "Creatore",
  "CreatorDescription": "Creatore: Tegan",
  "CustomAPIBody": "Corpo personalizzato",
  "CustomAPIBodyInfo": "Inserisci le informazioni del corpo da includere nella richiesta API in formato JSON. I messaggi verranno inclusi automaticamente.",
  "CustomAPIDescription": "Nota: i messaggi vengono inclusi automaticamente nel corpo della richiesta. Nella modalità streaming, il server deve restituire text/event-stream.",
  "CustomAPIEndpoint": "Endpoint API personalizzato",
  "CustomAPIEndpointInfo": "Inserisci l'URL dell'endpoint API a cui inviare la richiesta POST.",
  "CustomAPIHeaders": "Intestazioni personalizzate",
  "CustomAPIHeadersInfo": "Inserisci le informazioni delle intestazioni da includere nella richiesta API in formato JSON.",
  "CustomAPIStream": "Modalità streaming",
  "CustomAPIStreamForced": "Attualmente, la modalità streaming è sempre attivata.",
  "DeepSeekAPIKeyLabel": "Chiave API DeepSeek",
  "DefaultBackground": "Sfondo predefinito",
  "Description": "Informazioni sull'app",
  "DifyAPIKeyLabel": "Chiave API Dify",
  "DifyInfo": "Dify supporta solo i tipi chatbot e agent.",
  "DifyInfo2": "La lunghezza della cronologia conversazioni dipende dalle specifiche di Dify.",
  "DifyInfo3": "Esempio: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "Se usi Dify, il prompt di sistema non verrà utilizzato. Configura il chatbot Dify.",
  "DocumentationDescription": "Puoi trovare dettagli su come utilizzare AITuberKit e tutorial al seguente URL.",
  "DontShowIntroductionNextTime": "Non mostrare questa finestra la prossima volta",
  "DragToReorder": "Trascina per riordinare",
  "ElevenLabsApiKey": "Chiave API ElevenLabs",
  "ElevenLabsInfo": "Utilizza l'API ElevenLabs. Supporta più lingue. La chiave API può essere ottenuta dall'URL sotto.",
  "ElevenLabsVoiceId": "ID voce ElevenLabs",
  "ElevenLabsVoiceIdInfo": "L'ID voce può essere selezionato dall'URL sotto.",
  "EnterPresetQuestion": "Inserisci una domanda",
  "EnterURL": "URL",
  "EnterYourQuestion": "Inserisci qui la tua domanda",
  "Errors": {
    "AIAPIError": "Si è verificato un errore durante l'esecuzione dell'API IA",
    "AIInvalidProperty": "La configurazione del servizio IA non è corretta",
    "CustomAPIError": "Si è verificato un errore nell'API personalizzata",
    "EmptyAPIKey": "La chiave API non è configurata",
    "EmptyLocalLLMURL": "L'URL del LLM locale non è impostato",
    "InvalidAIService": "Il servizio IA selezionato non è valido",
    "InvalidJSON": "Il formato JSON non è corretto",
    "LocalLLMAPIError": "Errore API LLM locale",
    "LocalLLMConnectionError": "Errore connessione al server LLM locale",
    "LocalLLMError": "Errore LLM locale",
    "LocalLLMNotFound": "Endpoint LLM locale non trovato",
    "LocalLLMStreamError": "Errore stream LLM locale",
    "MethodNotAllowed": "La richiesta non è appropriata",
    "TTSServiceError": "Si è verificato un errore nel servizio TTS {{serviceName}}: {{message}}",
    "UnexpectedError": "Si è verificato un errore imprevisto"
  },
  "ExternalLinkageMode": "Modalità di collegamento esterno (versione beta)",
  "FireworksAPIKeyLabel": "Chiave API Fireworks",
  "GSVITTSBatchSize": "Dimensione batch GSVI TTS (1 ~ 100 Maggiore è il valore, più veloce sarà l'inferenza, ma potrebbe esaurire la memoria se troppo grande)",
  "GSVITTSInfo": "Impostazioni GSVI TTS",
  "GSVITTSModelID": "ID modello GSVI TTS",
  "GSVITTSServerUrl": "Endpoint API GSVI TTS",
  "GSVITTSSpeechRate": "Velocità parlato (0.5 ~ 2.0 Maggiore è il valore, più veloce sarà)",
  "GoogleAPIKeyLabel": "Chiave API Google Gemini",
  "GoogleTTSInfo": "Utilizza Google Cloud Text-to-Speech. Supporta più lingue.",
  "GroqAPIKeyLabel": "Chiave API Groq",
  "GroqInfo": "L'API Groq è accessibile direttamente dal browser.",
  "IncludeTimestampInUserMessage": "Includi timestamp nei messaggi utente",
  "IncludeTimestampInUserMessageInfo": "Includere il timestamp aiuta l'IA a generare risposte considerando l'ora di invio.\nInserisci la seguente stringa nel prompt di sistema:\n\n\"L'input dell'utente può includere [timestamp]. Questo è l'orario UTC al momento della richiesta, genera la risposta considerando questa informazione.\"",
  "InitialSpeechTimeout": "Timeout per il riconoscimento vocale",
  "InitialSpeechTimeoutInfo": "Imposta il tempo di attesa fino al rilevamento della prima emissione dopo l'inizio del riconoscimento vocale. Se non viene rilevata alcuna emissione entro questo tempo, il riconoscimento vocale si fermerà automaticamente.\nImpostando a 0 secondi, il tempo di attesa diventa illimitato.",
  "InputAudio": "Audio",
  "InputText": "Testo",
  "KoeiromapInfo": "Utilizza l'API Koeiromap di Koemotion. Supporta solo il giapponese. Vedi il link sotto per i dettagli.",
  "Language": "Lingua",
  "LanguageChoice": "Scelta lingua",
  "LanguageModelURL": "Seleziona il modello linguistico dall'URL sotto.",
  "ListeningContinuously": "In attesa di input vocale...",
  "Live2D": {
    "EmotionInfo": "Le emozioni possono essere specificate in formato separato da virgole. Se vengono specificate più emozioni, vengono selezionate casualmente.\nIl valore iniziale è per il modello fornito da AITuberKit. Se stai usando un modello originale, inserisci il valore secondo il tuo modello.\nDopo il completamento della conversazione, viene mostrata l'emozione \"Neutrale\".",
    "Emotions": "Impostazioni emozioni",
    "FileInfo": "Posiziona il modello Live2D che vuoi usare nella cartella public/live2d. Il file model3.json deve esistere nella root di questa cartella.\nSe non viene visualizzato nella selezione, ricarica la schermata o verifica che il percorso della cartella sia corretto.",
    "Info": "Puoi specificare emozioni e movimenti.\nOgni emozione è controllata dal prompt. Per maggiori dettagli, consulta \"Impostazioni IA => Impostazioni personaggio\".",
    "MotionGroups": "Impostazioni gruppi movimento",
    "MotionGroupsInfo": "I gruppi di movimento vengono selezionati casualmente dal gruppo selezionato.\nCome per le impostazioni emozioni, configuralo secondo il tuo modello.\n\"Idle\" è il movimento mostrato dopo il completamento della conversazione.",
    "SelectMotionGroup": "Seleziona gruppo movimento",
    "angryEmotions": "Arrabbiato",
    "angryMotionGroup": "Arrabbiato",
    "happyEmotions": "Felice",
    "happyMotionGroup": "Felice",
    "idleMotionGroup": "Inattivo",
    "neutralEmotions": "Neutrale",
    "neutralMotionGroup": "Neutrale",
    "relaxedEmotions": "Rilassato",
    "relaxedMotionGroup": "Rilassato",
    "sadEmotions": "Triste",
    "sadMotionGroup": "Triste",
    "surprisedEmotions": "Sorpresa",
    "surprisedMotionGroup": "Sorpresa"
  },
  "LocalLLM": "LLM locale",
  "LocalLLMInfo": "Il server LLM locale deve essere in esecuzione. La configurazione è la seguente.",
  "LocalLLMInfo2": "Inserisci l'URL del server LLM locale (incluso il numero di porta) e il nome del modello.",
  "LocalStorageReset": "Reimposta impostazioni",
  "LocalStorageResetButton": "Reimposta impostazioni",
  "LocalStorageResetInfo": "Le variabili d'ambiente hanno la priorità se impostate. La pagina verrà ricaricata.",
  "LogSettings": "Cronologia delle conversazioni",
  "MaxPastMessages": "Numero di messaggi passati da mantenere",
  "MaxTokens": "Numero massimo di token",
  "MaxTokensInfo": "Il numero massimo di token varia a seconda del modello AI in uso. Controlla le specifiche di ciascun modello.",
  "MessageReceiver": "Ricevi istruzioni dall'esterno",
  "MessageReceiverDescription": "Puoi usare l'API per far parlare i personaggi IA dall'esterno.",
  "Milliseconds": "Millisecondi",
  "MistralAIAPIKeyLabel": "Chiave API MistralAI",
  "NijiVoiceActorId": "ID attore",
  "NijiVoiceApiKey": "Chiave API NijiVoice",
  "NijiVoiceEmotionalLevel": "Livello emotivo",
  "NijiVoiceInfo": "Utilizza API NijiVoice. Supporta solo il giapponese. La chiave API può essere ottenuta dall'URL sotto.",
  "NijiVoiceSoundDuration": "Durata audio",
  "NijiVoiceSpeed": "Velocità parlato",
  "NotConnectedToExternalAssistant": "Non connesso all'assistente esterno.",
  "OpenAIAPIKeyLabel": "Chiave API OpenAI",
  "OpenAITTSInfo": "Usando OpenAI. Supporta più lingue. Se selezioni OpenAI come servizio IA, non devi configurare la chiave API sotto.",
  "OpenAITTSModel": "Modello",
  "OpenAITTSSpeed": "Velocità",
  "OpenAITTSVoice": "Tipo di voce",
  "OpenSendMessagePage": "Apri pagina invio messaggio",
  "OpenVRM": "Apri VRM",
  "OtherSettings": "Altro",
  "PdfConvertButton": "Converti PDF in presentazione",
  "PdfConvertDescription": "Converti PDF in dati modalità presentazione. Disponibile solo quando il servizio IA selezionato è OpenAI, Anthropic Claude o Google Gemini.",
  "PdfConvertError": "Errore nella conversione",
  "PdfConvertFileUpload": "Seleziona file PDF",
  "PdfConvertFolderName": "Nome cartella salvataggio",
  "PdfConvertLabel": "Conversione PDF presentazione",
  "PdfConvertLoading": "Conversione in corso...",
  "PdfConvertModelSelect": "Seleziona modello",
  "PdfConvertSubmitError": "Assicurati che il file PDF, il nome della cartella e la chiave API siano configurati.",
  "PdfConvertSuccess": "Conversione completata",
  "PerplexityAPIKeyLabel": "Chiave API Perplexity",
  "PresetQuestions": "Domande preimpostate",
  "PresetQuestionsInfo": "Puoi creare e registrare in anticipo più modelli di domande. Le domande registrate verranno visualizzate come pulsanti nell'interfaccia utente e, quando cliccate, verranno impostate nella barra di input della chat.",
  "RealtimeAPIMode": "Modalità API in tempo reale",
  "RealtimeAPIModeContentType": "Tipo di invio",
  "RealtimeAPIModeVoice": "Tipo di voce",
  "RepositoryURL": "URL repository:",
  "SearchGrounding": "Usa ricerca contestuale",
  "SearchGroundingDescription": "Quando si usa la funzione multimodale, la funzione di ricerca viene disattivata automaticamente.",
  "Select": "Seleziona",
  "SelectAIService": "Seleziona servizio IA",
  "SelectModel": "Seleziona modello",
  "SelectedSlideDocs": "Documenti presentazione selezionati",
  "SendMessage": {
    "aiGenerateDescription": "L'IA genera una risposta dal messaggio inviato e poi la pronuncia. Se vengono inviati più messaggi, vengono elaborati in ordine. Il modello IA e il modello vocale sono quelli selezionati nelle impostazioni di AITuberKit. Il prompt di sistema può essere selezionato per usare il prompt di sistema di AITuberKit o un prompt di sistema personalizzato. Se vuoi caricare la cronologia conversazioni precedente, includi la stringa [conversation_history] nel prompt di sistema o nel messaggio utente.",
    "aiGenerateTitle": "Genera risposta IA e poi parla",
    "directSendDescription": "Puoi inviare il messaggio direttamente al personaggio IA. Se vengono inviati più messaggi, vengono elaborati in ordine. Il modello vocale è quello selezionato nelle impostazioni di AITuberKit.",
    "directSendTitle": "Parla direttamente al personaggio IA",
    "title": "Adattatore esterno AITuberKit",
    "useCurrentSystemPrompt": "Usa prompt di sistema AITuberKit",
    "userInputDescription": "Il messaggio inviato viene elaborato come quando viene inserito dal modulo di input di AITuberKit. Se vengono inviati più messaggi, vengono elaborati in ordine. Il modello IA e il modello vocale sono quelli selezionati nelle impostazioni di AITuberKit. Il prompt di sistema e la cronologia conversazioni sono i valori configurati in AITuberKit.",
    "userInputTitle": "Invia input utente"
  },
  "ShowAssistantText": "Mostra riquadro risposta",
  "ShowCharacterName": "Mostra nome personaggio nel riquadro risposta",
  "ShowCharacterPresetMenu": "Mostra il pulsante del menu dei preset del personaggio",
  "ShowControlPanel": "Mostra pulsante impostazioni",
  "ShowControlPanelInfo": "Puoi visualizzare la schermata delle impostazioni premendo Cmd + . (Mac) / Ctrl + . (Windows).\nSe stai utilizzando uno smartphone, puoi anche tenere premuto il lato sinistro dello schermo per circa 1 secondo.",
  "ShowSilenceProgressBar": "Mostra la barra di avanzamento del rilevamento del silenzio",
  "SlideMode": "Modalità presentazione",
  "SlideModeDescription": "Questa è una modalità in cui l'IA presenta automaticamente le diapositive. Disponibile solo quando il servizio IA selezionato è OpenAI, Anthropic Claude o Google Gemini.",
  "SlideSettings": "Impostazioni dello slide",
  "SourceCodeDescription1": "Il codice sorgente di questa applicazione è condiviso su GitHub. Sei libero di modificarlo.",
  "SourceCodeDescription2": "Per l'uso commerciale, consulta il README del repository.",
  "SpeakerSelection": "Selezione speaker",
  "SpeechInputSettings": "Impostazioni di input vocale",
  "SpeechRecognitionMode": "Modalità di riconoscimento vocale",
  "SpeechRecognitionModeDisabledInfo": "Se la modalità audio è attivata, è disponibile solo il riconoscimento vocale del browser.\nInoltre, nella modalità API in tempo reale, è disponibile solo il riconoscimento vocale del browser e la funzione di timeout per il riconoscimento vocale sarà disabilitata.",
  "SpeechRecognitionModeInfo": "Puoi scegliere la modalità di riconoscimento vocale.\n\"Standard del browser\" utilizza il riconoscimento vocale integrato nel browser. \"OpenAI TTS\" utilizza l'API Text to Speech di OpenAI.\nIn generale, si consiglia di utilizzare \"Standard del browser\" poiché offre una maggiore precisione e velocità di riconoscimento. Tuttavia, se stai utilizzando un browser che non supporta l'API WebSpeech come Firefox, scegli \"OpenAI TTS\".",
  "StatusOff": "Stato: DISATTIVO",
  "StatusOn": "Stato: ATTIVO",
  "StyleBeatVITS2ApiKey": "Chiave API",
  "StyleBeatVITS2Length": "Velocità parlato",
  "StyleBeatVITS2ModelID": "ID modello",
  "StyleBeatVITS2SdpRatio": "Rapporto mix SDP/DP",
  "StyleBeatVITS2ServerURL": "URL server",
  "StyleBeatVITS2Style": "Stile",
  "StyleBertVITS2Info": "Utilizza Style-Bert-VITS2. Supporta solo giapponese, inglese e cinese. Se usi API locale, scarica e avvia l'applicazione adatta. Se necessario, imposta anche la chiave API.",
  "SyntheticVoiceEngineChoice": "Scegli motore sintesi vocale",
  "TechnologyIntroduction": "Introduzione tecnologia",
  "TechnologyIntroductionDescription1": "Questa applicazione è basata sul progetto <b>ChatVRM</b> di pixiv. Il codice sorgente originale è disponibile",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "Per la visualizzazione e manipolazione del modello 3D viene utilizzato",
  "TechnologyIntroductionDescription4": "Per la generazione del testo della conversazione vengono utilizzati vari LLM come",
  "TechnologyIntroductionDescription5": "Per la sintesi vocale vengono utilizzati vari motori TTS come",
  "TechnologyIntroductionDescription6": "Per maggiori dettagli, consulta questo",
  "TechnologyIntroductionDescription7": ".",
  "TechnologyIntroductionLink1": "qui",
  "TechnologyIntroductionLink2": "articolo esplicativo",
  "Temperature": "Temperatura",
  "TestVoice": "Test voce",
  "Toasts": {
    "FirefoxNotSupported": "Questa funzione non è supportata in Firefox",
    "FunctionExecuting": "Esecuzione {{funcName}}",
    "FunctionExecutionFailed": "Esecuzione {{funcName}} fallita",
    "PresetSwitching": "È stato cambiato a {{presetName}}.",
    "SpeechRecognitionError": "Si è verificato un errore di riconoscimento vocale",
    "WebSocketConnectionAttempt": "Tentativo connessione WebSocket...",
    "WebSocketConnectionClosed": "Connessione WebSocket chiusa",
    "WebSocketConnectionError": "Errore connessione WebSocket",
    "WebSocketConnectionSuccess": "Connessione WebSocket riuscita",
    "WhisperError": "Si è verificato un errore nel riconoscimento vocale tramite Whisper"
  },
  "UpdateRealtimeAPISettings": "Aggiorna impostazioni API in tempo reale",
  "UpdateRealtimeAPISettingsInfo": "Quando aggiorni la chiave API, endpoint Azure, tipo di voce, modello o prompt di sistema, premi il pulsante di aggiornamento per avviare una nuova sessione WebSocket.",
  "UpdateSpeakerList": "Aggiorna lista speaker",
  "UploadBackground": "Testo italiano: \"Carica immagine di sfondo",
  "UseVideoAsBackground": "Usa schermo condiviso o webcam come sfondo",
  "UsingAivisSpeech": "AivisSpeech",
  "UsingAzureTTS": "Usando Azure OpenAI",
  "UsingElevenLabs": "ElevenLabs",
  "UsingGSVITTS": "GSVI TTS",
  "UsingGoogleTTS": "Utilizzare Google Text-to-Speech",
  "UsingKoeiromap": "Koeiromap",
  "UsingNijiVoice": "NijiVoice",
  "UsingOpenAITTS": "Usando OpenAI",
  "UsingStyleBertVITS2": "Style-Bert-VITS2",
  "UsingVoiceVox": "VOICEVOX",
  "VoiceAdjustment": "Regolazione voce",
  "VoiceEngineInstruction": "Seleziona il motore di sintesi vocale che desideri utilizzare.",
  "VoiceSettings": "Impostazioni della voce sintetizzata",
  "VoiceVoxInfo": "Utilizza VOICEVOX. Supporta solo il giapponese. Usa API locale, devi scaricare e avviare l'applicazione adatta al tuo sistema.",
  "VoicevoxIntonation": "Intonazione",
  "VoicevoxPitch": "Tono",
  "VoicevoxServerUrl": "URL server VOICEVOX",
  "VoicevoxSpeed": "Velocità",
  "WhisperAPIKeyInfo": "In modalità Whisper è necessaria una chiave API di OpenAI. Si prega di impostare la chiave API di OpenAI nelle impostazioni AI.",
  "WhisperSpeechRecognition": "Utilizza il riconoscimento vocale OpenAI TTS",
  "WhisperTranscriptionModel": "Modello di trascrizione",
  "WhisperTranscriptionModelInfo": "Puoi scegliere il modello da utilizzare per il riconoscimento vocale. Modelli più performanti possono riconoscere con maggiore precisione, ma potrebbero comportare costi API più elevati.",
  "YoutubeAPIKey": "Chiave API YouTube",
  "YoutubeInfo": "Il primo carattere del commento è '#' e verrà ignorato.",
  "YoutubeLiveID": "ID diretta YouTube",
  "YoutubeMode": "Modalità YouTube",
  "YoutubeSettings": "Impostazioni di YouTube",
  "characterpresetInfo": "Selezionando una preimpostazione si cambia la richiesta di caratteri.\nCmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows) per le scorciatoie.\nSe si seleziona una preimpostazione tenendo premuto il tasto Shift, la richiesta di caratteri corrente viene salvata nella preimpostazione."
}
