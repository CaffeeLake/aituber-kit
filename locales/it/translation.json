{
  "AISettings": "Impostazioni AI",
  "APIKeyInstruction": "Le chiavi API possono essere ottenute dal link sottostante. Inserisci la chiave API ottenuta nel modulo.",
  "APIKeyNotEntered": "Chiave API non inserita.",
  "AboutThisApplication": "Informazioni su questa applicazione",
  "AboutThisApplicationDescription": "Puoi conversare con un personaggio 3D direttamente nel browser web utilizzando microfono, input di testo e sintesi vocale. Puoi modificare il personaggio (VRM), impostare la personalità e regolare la voce.<br />Le impostazioni possono essere modificate dal pulsante menu nell'angolo in alto a sinistra.",
  "AboutThisApplicationDescription2": "Con AITuberKit, puoi divertirti a conversare con un personaggio AI direttamente nel browser web. Controlla le impostazioni corrispondenti per modificare il personaggio, impostare la personalità e regolare la voce.",
  "AivisSpeechInfo": "Stiamo utilizzando AivisSpeech. Supporta solo il giapponese. Poiché utilizza un'API locale, è necessario scaricare e avviare l'applicazione appropriata per il tuo ambiente dal sito sottostante.",
  "AivisSpeechIntonation": "Modulazione",
  "AivisSpeechPitch": "Intonazione",
  "AivisSpeechServerUrl": "URL server AivisSpeech",
  "AivisSpeechSpeaker": "Parlante",
  "AivisSpeechSpeed": "Velocità del parlato",
  "AnswerGenerating": "Generazione risposta in corso",
  "AnthropicAPIKeyLabel": "Chiave API Anthropic",
  "AudioMode": "Modalità audio",
  "AuthFileInstruction": "È necessaria una chiave API o un file JSON per l'autenticazione. Ottienilo dal link sottostante e, se utilizzi un file JSON, posizionalo nella cartella principale del repository con il nome credentials.json.",
  "AzureAPIKeyLabel": "Chiave API Azure OpenAI",
  "AzureAPIURL": "URL API Azure OpenAI",
  "AzureEndpoint": "Endpoint Azure",
  "AzureTTSInfo": "Stiamo utilizzando Azure OpenAI. Supporta più lingue.",
  "BackgroundImage": "Immagine di sfondo",
  "BackgroundSettings": "Impostazioni sfondo",
  "BackgroundSettingsDescription": "Puoi caricare e selezionare un'immagine di sfondo per l'applicazione.",
  "BasedSettings": "Impostazioni di base",
  "BrowserSpeechRecognition": "Usa riconoscimento vocale standard del browser",
  "CannotUseParameters": "Quando la modalità API in tempo reale o la modalità audio è attiva, non è possibile specificare i parametri Temperatura e Numero massimo di token.",
  "CannotUseVoice": "Quando la modalità API in tempo reale o la modalità audio è attiva,\nle impostazioni della voce sintetica non sono necessarie.",
  "ChangeBackgroundImage": "Cambia immagine di sfondo",
  "CharacterModelInfo": "Alcuni modelli potrebbero richiedere più tempo per caricarsi durante la visualizzazione iniziale.",
  "CharacterModelLabel": "Modello del personaggio",
  "CharacterName": "Nome personaggio",
  "CharacterSettings": "Impostazioni del personaggio",
  "CharacterSettingsInfo": "Questo valore sarà impostato come prompt di sistema.\nFacendo riferimento al prompt iniziale, puoi controllare le espressioni e i movimenti del personaggio specificando tag emotivi. Esempio: [neutral]Buongiorno![happy]Anche oggi hai lavorato duramente!",
  "CharacterSettingsPrompt": "Prompt del personaggio",
  "Characterpreset1": "Preset 1",
  "Characterpreset2": "Preset 2",
  "Characterpreset3": "Preset 3",
  "Characterpreset4": "Preset 4",
  "Characterpreset5": "Preset 5",
  "CharacterpresetInfo": "Selezionando un preset, il prompt del personaggio verrà modificato.\nÈ possibile utilizzare scorciatoie Cmd + Shift + 1~5, (Mac) / Ctrl + Shift + 1~5 (Windows).",
  "ChatLog": "Registro chat",
  "ClientID": "ID Cliente",
  "Close": "Chiudi",
  "CohereAPIKeyLabel": "Chiave API Cohere",
  "Contact": "Contatti",
  "ContactDescription": "Per domande su questa applicazione, contattaci all'indirizzo email o account Twitter sottostante.",
  "ContinuousMic": "Input microfono continuo",
  "ContinuousMicActive": "Input microfono continuo attivo",
  "ContinuousMicInfo": "Riavvia automaticamente l'input del microfono quando l'AI finisce di parlare. Invia automaticamente dopo il tempo di silenzio impostato.\nSe il riconoscimento vocale non avviene entro il tempo impostato, l'input microfono continuo si disattiva automaticamente. Se desideri mantenerlo sempre attivo, imposta il timeout del riconoscimento vocale a 0 secondi.",
  "ContinuousMicModeOff": "Modalità input microfono continuo disattiva",
  "ContinuousMicModeOn": "Modalità input microfono continuo attiva",
  "ConversationContinuityMode": "Modalità continuità conversazione (Beta)",
  "ConversationContinuityModeInfo": "Modalità in cui l'AI cerca di continuare la conversazione quando non ci sono commenti. Attualmente supportata solo da OpenAI, Anthropic Claude e Google Gemini.",
  "ConversationContinuityModeInfo2": "Poiché vengono effettuate più chiamate LLM per una singola risposta, le spese API potrebbero aumentare. Si prega di fare attenzione.",
  "ConversationContinuityModeInfo3": "Funziona relativamente in modo stabile con gpt-4o, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet.",
  "ConversationHistory": "Cronologia conversazioni",
  "ConversationHistoryInfo": "Gli ultimi {{count}} messaggi della conversazione vengono conservati come memoria.",
  "ConversationHistoryReset": "Resetta cronologia conversazioni",
  "Creator": "Informazioni creatore",
  "CreatorDescription": "Creatore: Nike",
  "CustomAPIBody": "Body personalizzato",
  "CustomAPIBodyInfo": "Inserisci in formato JSON le informazioni del body da includere nella richiesta API. I messaggi verranno inclusi automaticamente.",
  "CustomAPIDescription": "Nota: i messaggi verranno inclusi automaticamente nel body della richiesta. In modalità streaming, il server deve restituire text/event-stream.",
  "CustomAPIEndpoint": "Endpoint API personalizzato",
  "CustomAPIEndpointInfo": "Inserisci l'URL dell'endpoint API a cui inviare le richieste POST.",
  "CustomAPIHeaders": "Header personalizzati",
  "CustomAPIHeadersInfo": "Inserisci in formato JSON le informazioni degli header da includere nella richiesta API.",
  "CustomAPIStream": "Modalità streaming",
  "CustomAPIStreamForced": "Attualmente, la modalità streaming è sempre abilitata.",
  "CustomVoiceTextPlaceholder": "Inserisci il testo che desideri ascoltare",
  "DeepSeekAPIKeyLabel": "Chiave API DeepSeek",
  "DefaultBackground": "Sfondo predefinito",
  "Description": "Informazioni sull'applicazione",
  "DifyAPIKeyLabel": "Chiave API Dify",
  "DifyInfo": "Dify supporta solo chatbot o tipi di agenti.",
  "DifyInfo2": "La lunghezza della cronologia delle conversazioni dipende dalle impostazioni del chatbot Dify.",
  "DifyInfo3": "Esempio: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "Quando si utilizza Dify, questo prompt di sistema non viene utilizzato. Configuralo nel chatbot Dify.",
  "Documentation": "Documentazione",
  "DocumentationDescription": "Per istruzioni dettagliate e tutorial su AITuberKit, visita l'URL sottostante.",
  "DontShowIntroductionNextTime": "Non mostrare questa finestra la prossima volta",
  "DragToReorder": "Trascina per riordinare",
  "EditSlideScripts": "セリフ編集",
  "ElevenLabsApiKey": "Chiave API ElevenLabs",
  "ElevenLabsInfo": "Stiamo utilizzando l'API ElevenLabs. Supporta più lingue. Ottieni la chiave API dall'URL sottostante.",
  "ElevenLabsVoiceId": "ID voce ElevenLabs",
  "ElevenLabsVoiceIdInfo": "Seleziona l'ID voce dall'URL sottostante.",
  "EnglishToJapanese": "Leggi le parole inglesi in giapponese",
  "EnterPresetQuestion": "Inserisci una domanda",
  "EnterURL": "Inserisci URL",
  "EnterYourQuestion": "Inserisci la tua domanda",
  "Errors": {
    "AIAPIError": "Si è verificato un errore durante l'esecuzione dell'API AI",
    "AIInvalidProperty": "Valore impostazione servizio AI non valido",
    "CustomAPIError": "Si è verificato un errore nell'API personalizzata",
    "EmptyAPIKey": "Chiave API non impostata",
    "EmptyLocalLLMURL": "URL LLM locale non impostato",
    "InvalidAIService": "Il servizio AI selezionato non è valido",
    "InvalidJSON": "Formato JSON non valido",
    "LocalLLMAPIError": "Si è verificato un errore nell'API LLM locale",
    "LocalLLMConnectionError": "Impossibile connettersi al server LLM locale",
    "LocalLLMError": "Si è verificato un errore nel LLM locale",
    "LocalLLMNotFound": "Endpoint LLM locale non trovato",
    "LocalLLMStreamError": "Si è verificato un errore nell'elaborazione dello stream del LLM locale",
    "MethodNotAllowed": "La richiesta non è appropriata",
    "TTSServiceError": "Si è verificato un errore nel servizio TTS {{serviceName}}: {{message}}",
    "UnexpectedError": "Si è verificato un errore sconosciuto"
  },
  "ExternalLinkageMode": "Modalità collegamento esterno (Beta)",
  "FireworksAPIKeyLabel": "Chiave API Fireworks",
  "GSVITTSBatchSize": "Dimensione batch GSVI TTS (1 ~ 100 valori più alti aumentano la velocità di inferenza, ma valori troppo alti possono esaurire la memoria)",
  "GSVITTSInfo": "Impostazioni GSVI TTS",
  "GSVITTSModelID": "ID modello GSVI TTS",
  "GSVITTSServerUrl": "URL server GSVI TTS",
  "GSVITTSSpeechRate": "Velocità parlato (0.5 ~ 2.0 valori più alti = più veloce)",
  "GoogleAPIKeyLabel": "Chiave API Google Gemini",
  "GoogleTTSInfo": "Stiamo utilizzando Google Cloud Text-to-Speech. Supporta più lingue.",
  "GroqAPIKeyLabel": "Chiave API Groq",
  "GroqInfo": "L'API Groq è accessibile direttamente dal browser.",
  "IncludeSystemMessages": "Includi messaggi del sistema",
  "IncludeTimestampInUserMessage": "Includi timestamp nei messaggi utente",
  "IncludeTimestampInUserMessageInfo": "Includendo il timestamp nei messaggi utente, l'AI può generare risposte considerando l'orario.\nAggiungere la seguente frase al prompt di sistema:\n\n\"Le richieste utente potrebbero contenere un [timestamp], che rappresenta l'ora corrente nel fuso orario UTC. Considera questo orario quando generi la tua risposta.\"",
  "InitialSpeechTimeout": "Timeout riconoscimento vocale",
  "InitialSpeechTimeoutInfo": "Imposta il tempo di attesa per il rilevamento del primo discorso dopo l'avvio del riconoscimento vocale. Se non viene rilevato alcun discorso entro questo tempo, il riconoscimento vocale si interrompe automaticamente.\nImpostando a 0 secondi, il tempo di attesa diventa illimitato.",
  "InputAudio": "Audio",
  "InputText": "Testo",
  "KoeiromapInfo": "Stiamo utilizzando l'API Koeiromap di Koemotion. Supporta solo il giapponese. Per ulteriori dettagli, consulta il seguente.",
  "Language": "Impostazioni lingua",
  "LanguageChoice": "Selezione lingua",
  "LanguageModelURL": "Seleziona il modello linguistico dal seguente URL.",
  "ListeningContinuously": "In attesa di input vocale...",
  "Live2D": {
    "EmotionInfo": "Le emozioni possono essere specificate separandole con virgole. In caso di più specificazioni, verrà selezionata casualmente.\nI valori predefiniti sono compatibili con i modelli forniti da AITuberKit. Se utilizzi un modello originale, inserisci valori adatti al tuo modello.\nDopo il completamento della conversazione, verrà mostrata l'espressione \"normale\".",
    "Emotions": "Impostazioni espressioni",
    "FileInfo": "Posiziona la cartella del modello Live2D che desideri utilizzare in public/live2d. È necessario che il file model3.json si trovi direttamente in questa cartella.\nSe non appare nelle opzioni, ricarica la pagina o verifica che il percorso della cartella sia corretto.",
    "Info": "Puoi specificare emozioni e movimenti.\nOgni emozione è controllata dal prompt. Per maggiori dettagli, consulta \"Impostazioni AI => Impostazioni personaggio\".",
    "MotionGroups": "Impostazioni gruppi di movimento",
    "MotionGroupsInfo": "I movimenti vengono selezionati casualmente dal gruppo scelto.\nCome per le impostazioni delle espressioni, configurali in base al tuo modello.\n\"Inattivo\" è il movimento mostrato dopo il completamento della conversazione.",
    "SelectMotionGroup": "Seleziona gruppo di movimento",
    "angryEmotions": "Arrabbiato",
    "angryMotionGroup": "Arrabbiato",
    "happyEmotions": "Felice",
    "happyMotionGroup": "Felice",
    "idleMotionGroup": "Inattivo",
    "neutralEmotions": "Normale",
    "neutralMotionGroup": "Normale",
    "relaxedEmotions": "Rilassato",
    "relaxedMotionGroup": "Rilassato",
    "sadEmotions": "Triste",
    "sadMotionGroup": "Triste",
    "surprisedEmotions": "Sorpreso",
    "surprisedMotionGroup": "Sorpreso"
  },
  "LocalLLM": "LLM locale",
  "LocalLLMInfo": "È necessario avviare il server LLM locale.",
  "LocalLLMInfo2": "Inserisci l'URL del LLM locale (incluso il numero di porta) e il nome del modello.",
  "LocalStorageReset": "Ripristina impostazioni",
  "LocalStorageResetButton": "Ripristina impostazioni",
  "LocalStorageResetInfo": "Se sono impostate variabili d'ambiente, quei valori avranno la priorità. La pagina verrà ricaricata.",
  "LogSettings": "Cronologia conversazioni",
  "MaxPastMessages": "Numero di messaggi passati da conservare",
  "MaxTokens": "Numero massimo di token",
  "MaxTokensInfo": "Il numero massimo di token varia in base al modello AI utilizzato. Verifica le specifiche di ciascun modello.",
  "MessageReceiver": "Accetta istruzioni esterne",
  "MessageReceiverDescription": "Puoi istruire esternamente il personaggio AI su cosa dire utilizzando l'API.",
  "Milliseconds": "millisecondi",
  "MistralAIAPIKeyLabel": "Chiave API MistralAI",
  "NijiVoiceActorId": "ID parlante",
  "NijiVoiceApiKey": "Chiave API NijiVoice",
  "NijiVoiceEmotionalLevel": "Livello emotivo",
  "NijiVoiceInfo": "Stiamo utilizzando l'API NijiVoice. Supporta solo il giapponese. Ottieni la chiave API dall'URL sottostante.",
  "NijiVoiceSoundDuration": "Durata audio",
  "NijiVoiceSpeed": "Velocità del parlato",
  "NoSpeechTimeout": "Timeout rilevamento silenzio",
  "NoSpeechTimeoutInfo": "Imposta il tempo dopo il quale l'input viene terminato automaticamente quando c'è silenzio durante l'input vocale.\nImpostando a 0 secondi, disabilita l'invio automatico basato sul rilevamento del silenzio.",
  "NotConnectedToExternalAssistant": "Non connesso a un assistente esterno.",
  "OpenAIAPIKeyLabel": "Chiave API OpenAI",
  "OpenAITTSInfo": "Stiamo utilizzando OpenAI. Supporta più lingue. Se hai selezionato OpenAI come servizio AI, non è necessario impostare la chiave API sottostante.",
  "OpenAITTSModel": "Modello",
  "OpenAITTSSpeed": "Velocità parlato",
  "OpenAITTSVoice": "Tipo di voce",
  "OpenSendMessagePage": "Apri pagina invio messaggi",
  "OpenVRM": "Apri VRM",
  "OtherSettings": "Altro",
  "PdfConvertButton": "Converti PDF in slide",
  "PdfConvertDescription": "Converti PDF in dati per la modalità presentazione. Disponibile solo quando il servizio AI selezionato è OpenAI, Anthropic Claude o Google Gemini.",
  "PdfConvertError": "Conversione fallita",
  "PdfConvertFileUpload": "Seleziona file PDF",
  "PdfConvertFolderName": "Nome cartella di salvataggio",
  "PdfConvertLabel": "Conversione slide PDF",
  "PdfConvertLoading": "Conversione in corso...",
  "PdfConvertModelSelect": "Seleziona modello",
  "PdfConvertSubmitError": "Verifica che il file PDF, il nome della cartella e la chiave API siano impostati",
  "PdfConvertSuccess": "Conversione completata",
  "PerplexityAPIKeyLabel": "Chiave API Perplexity",
  "PleaseSelectSlide": "スライドを選択してください",
  "PresetQuestions": "Domande preimpostate",
  "PresetQuestionsInfo": "Puoi creare e registrare in anticipo più modelli di domande. Le domande registrate verranno visualizzate come pulsanti nell'interfaccia utente e, quando cliccate, verranno inserite nel campo di input della chat.",
  "RealtimeAPIMode": "Modalità API in tempo reale",
  "RealtimeAPIModeContentType": "Tipo di invio",
  "RealtimeAPIModeVoice": "Tipo di voce",
  "RepositoryURL": "URL repository:",
  "SearchGrounding": "Utilizza funzione di ricerca",
  "SearchGroundingDescription": "Quando si utilizza la funzione multimodale, la funzione di ricerca viene automaticamente disabilitata.",
  "Select": "Seleziona",
  "SelectAIService": "Seleziona servizio AI",
  "SelectModel": "Seleziona modello",
  "SelectedSlideDocs": "Slide da utilizzare",
  "SendMessage": {
    "aiGenerateDescription": "L'AI genererà una risposta dal messaggio inviato e il personaggio AI pronuncerà quella risposta. Se invii più messaggi, verranno elaborati in ordine.\nVengono utilizzati il modello AI e il modello vocale selezionati nelle impostazioni di AITuberKit.\nPuoi scegliere se utilizzare il prompt di sistema di AITuberKit o un prompt di sistema personalizzato.\nPer caricare la cronologia delle conversazioni precedenti, includi la stringa [conversation_history] in qualsiasi posizione nel prompt di sistema o nel messaggio utente.",
    "aiGenerateTitle": "Genera una risposta con l'AI e poi falla pronunciare",
    "directSendDescription": "Puoi far parlare direttamente al personaggio AI il messaggio inviato. Se invii più messaggi, verranno elaborati in ordine.\nViene utilizzato il modello vocale selezionato nelle impostazioni di AITuberKit.",
    "directSendTitle": "Fai parlare direttamente il personaggio AI",
    "title": "Adattatore esterno AITuberKit",
    "useCurrentSystemPrompt": "Utilizza il prompt di sistema di AITuberKit",
    "userInputDescription": "Il messaggio inviato verrà elaborato come se fosse stato inserito dal modulo di input di AITuberKit. Se invii più messaggi, verranno elaborati in ordine.\nVengono utilizzati il modello AI e il modello vocale selezionati nelle impostazioni di AITuberKit.\nVengono utilizzati il prompt di sistema e la cronologia delle conversazioni di AITuberKit.",
    "userInputTitle": "Invia input utente"
  },
  "ShowAssistantText": "Mostra area risposta",
  "ShowCharacterName": "Mostra nome personaggio nell'area risposta",
  "ShowCharacterPresetMenu": "Mostra pulsante menu preset personaggio",
  "ShowControlPanel": "Mostra pannello di controllo",
  "ShowControlPanelInfo": "La schermata delle impostazioni può essere visualizzata con Cmd + . (Mac) / Ctrl + . (Windows).\nSe utilizzi uno smartphone, puoi anche tenere premuto (circa 1 secondo) nell'angolo in alto a sinistra dello schermo.",
  "ShowSilenceProgressBar": "Mostra barra di progresso rilevamento silenzio",
  "SlideMode": "Modalità presentazione",
  "SlideModeDescription": "Modalità in cui l'AI presenta automaticamente le slide. Attiva solo quando il servizio AI selezionato è OpenAI, Anthropic Claude o Google Gemini.",
  "SlideSettings": "Impostazioni presentazione",
  "SourceCodeDescription1": "Il codice sorgente di questa applicazione è disponibile su GitHub. Puoi modificarlo liberamente.",
  "SourceCodeDescription2": "Per l'uso commerciale, consulta il README nello stesso repository.",
  "SpeakerSelection": "Selezione tipo di voce",
  "SpeechInputSettings": "Impostazioni input vocale",
  "SpeechRecognitionMode": "Modalità riconoscimento vocale",
  "SpeechRecognitionModeDisabledInfo": "Quando la modalità audio è attiva, è possibile utilizzare solo il riconoscimento vocale del browser.\nInoltre, in modalità API in tempo reale, è possibile utilizzare solo il riconoscimento vocale del browser e la funzione di timeout del riconoscimento vocale è disabilitata.",
  "SpeechRecognitionModeInfo": "Puoi selezionare la modalità di riconoscimento vocale.\n\"Standard browser\" utilizza il riconoscimento vocale integrato nel browser. \"OpenAI TTS\" utilizza l'API Text to Speech di OpenAI.\nGeneralmente, \"Standard browser\" è raccomandato perché ha una maggiore precisione e velocità di riconoscimento. Tuttavia, se stai utilizzando un browser come Firefox che non supporta l'API WebSpeech, seleziona \"OpenAI TTS\".",
  "StatusOff": "Stato: DISATTIVO",
  "StatusOn": "Stato: ATTIVO",
  "StyleBeatVITS2ApiKey": "Chiave API",
  "StyleBeatVITS2Length": "Velocità del parlato",
  "StyleBeatVITS2ModelID": "ID modello",
  "StyleBeatVITS2SdpRatio": "Rapporto mixaggio SDP/DP",
  "StyleBeatVITS2ServerURL": "URL server",
  "StyleBeatVITS2Style": "Stile",
  "StyleBertVITS2Info": "Stiamo utilizzando Style-Bert-VITS2. Supporta solo giapponese, inglese e cinese. Se utilizzi l'API locale, scarica e avvia l'applicazione appropriata per il tuo ambiente dal sito sottostante. Se necessario, configura anche la chiave API.",
  "SyntheticVoiceEngineChoice": "Selezione motore voce sintetica",
  "TechnologyIntroduction": "Introduzione tecnologica",
  "TechnologyIntroductionDescription1": "Questa applicazione è stata creata modificando <b>ChatVRM</b> di pixiv. Il codice sorgente originale è disponibile",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "Per la visualizzazione e il controllo del modello 3D utilizziamo",
  "TechnologyIntroductionDescription4": ", per la generazione delle conversazioni",
  "TechnologyIntroductionDescription5": "vari LLM, e per la sintesi vocale",
  "TechnologyIntroductionDescription6": "vari TTS. Per maggiori dettagli, consulta questo",
  "TechnologyIntroductionDescription7": ".",
  "TechnologyIntroductionLink1": "qui",
  "TechnologyIntroductionLink2": "articolo esplicativo",
  "Temperature": "Temperatura",
  "TestSelectedVoice": "Riproduci",
  "TestVoice": "Testa la voce",
  "TestVoiceSettings": "Test voce",
  "Toasts": {
    "FirefoxNotSupported": "Firefoxではこの機能はサポートされていません",
    "FunctionExecuting": "{{funcName}}を実行しています",
    "FunctionExecutionFailed": "{{funcName}}の実行に失敗しました",
    "NoSpeechDetected": "音声が検出されませんでした。",
    "PresetSwitching": "{{presetName}}に切り替わりました。",
    "SpeechRecognitionError": "音声認識エラーが発生しました",
    "UsingTool": "{{toolName}}を使用中",
    "WebSocketConnectionAttempt": "WebSocket接続を試みています...",
    "WebSocketConnectionClosed": "WebSocket接続が閉じられました",
    "WebSocketConnectionError": "WebSocket接続にエラーが発生しました",
    "WebSocketConnectionSuccess": "WebSocket接続に成功しました",
    "WhisperError": "Whisperによる音声認識でエラーが発生しました"
  },
  "UpdateRealtimeAPISettings": "Aggiorna impostazioni API in tempo reale",
  "UpdateRealtimeAPISettingsInfo": "Quando aggiorni la chiave API, l'endpoint Azure, il tipo di voce, il modello o il prompt di sistema, premi il pulsante di aggiornamento per avviare una nuova sessione WebSocket.",
  "UpdateSpeakerList": "Aggiorna lista parlanti",
  "UploadBackground": "Carica immagine di sfondo",
  "UseVideoAsBackground": "Usa condivisione schermo o webcam come sfondo",
  "UsingAivisSpeech": "Usa AivisSpeech",
  "UsingAzureTTS": "Usa Azure OpenAI",
  "UsingElevenLabs": "Usa ElevenLabs",
  "UsingGSVITTS": "Usa GSVI TTS",
  "UsingGoogleTTS": "Usa Google Text-to-Speech",
  "UsingKoeiromap": "Usa Koeiromap",
  "UsingNijiVoice": "Usa NijiVoice",
  "UsingOpenAITTS": "Usa OpenAI",
  "UsingStyleBertVITS2": "Usa Style-Bert-VITS2",
  "UsingVoiceVox": "Usa VOICEVOX",
  "VoiceAdjustment": "Regolazione voce",
  "VoiceEngineInstruction": "Seleziona il motore di sintesi vocale da utilizzare.",
  "VoiceSettings": "Impostazioni voce sintetica",
  "VoiceVoxInfo": "Stiamo utilizzando VOICEVOX. Supporta solo il giapponese. Poiché utilizza un'API locale, è necessario scaricare e avviare l'applicazione appropriata per il tuo ambiente dal sito sottostante.",
  "VoicevoxIntonation": "Modulazione",
  "VoicevoxPitch": "Intonazione",
  "VoicevoxServerUrl": "URL server VOICEVOX",
  "VoicevoxSpeed": "Velocità del parlato",
  "WhisperSpeechRecognition": "Usa riconoscimento vocale OpenAI TTS",
  "WhisperTranscriptionModel": "Modello di trascrizione",
  "WhisperTranscriptionModelInfo": "Puoi selezionare il modello da utilizzare per il riconoscimento vocale. I modelli più potenti offrono un riconoscimento più preciso, ma potrebbero comportare costi API più elevati.",
  "YoutubeAPIKey": "Chiave API YouTube",
  "YoutubeInfo": "I commenti che iniziano con '#' verranno ignorati.",
  "YoutubeLiveID": "ID YouTube Live",
  "YoutubeMode": "Modalità YouTube",
  "YoutubeSettings": "Impostazioni YouTube"
}
