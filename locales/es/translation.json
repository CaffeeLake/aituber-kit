{
  "AISettings": "Configuración de IA",
  "APIKeyInstruction": "Puede obtener la clave API abajo. Ingrese la clave API obtenida en el formulario.",
  "APIKeyNotEntered": "No se ha ingresado la clave API.",
  "AboutThisApplication": "Acerca de esta aplicación",
  "AboutThisApplicationDescription": "Disfrute de conversaciones con un personaje 3D directamente en su navegador web, usando micrófono o entrada de texto y síntesis de voz. También puede cambiar el personaje (VRM), ajustar su personalidad y modificar su voz.<br />La configuración se puede cambiar desde el botón de menú en la parte superior izquierda.",
  "AboutThisApplicationDescription2": "Si desea cambiar el personaje, consulte la pestaña \"Configuración de personaje\".",
  "AivisSpeechInfo": "Usando AivisSpeech. Solo admite japonés. Usa una API local, necesita descargar y ejecutar la aplicación que se adapte a su entorno desde el sitio de abajo.",
  "AivisSpeechIntonation": "Entonación",
  "AivisSpeechPitch": "Tono",
  "AivisSpeechServerUrl": "URL del servidor AivisSpeech",
  "AivisSpeechSpeaker": "Hablante",
  "AivisSpeechSpeed": "Velocidad",
  "AnswerGenerating": "Generando respuesta",
  "AnthropicAPIKeyLabel": "Clave API de Anthropic",
  "AudioMode": "Modo de audio",
  "AuthFileInstruction": "Se requiere una clave API o archivo de autenticación. Obténgalo desde la URL de abajo y colóquelo en la carpeta raíz del repositorio si es un archivo JSON.",
  "AzureAPIKeyLabel": "Clave API de Azure OpenAI",
  "AzureAPIURL": "URL API de Azure OpenAI",
  "AzureEndpoint": "Endpoint de Azure",
  "AzureTTSInfo": "Usando Azure OpenAI. Admite múltiples idiomas.",
  "BackgroundImage": "Imagen de fondo",
  "BackgroundSettings": "Configuración de fondo",
  "BackgroundSettingsDescription": "Puede cargar y seleccionar la imagen de fondo de la aplicación.",
  "BasedSettings": "Configuración básica",
  "BrowserSpeechRecognition": "Usar reconocimiento de voz estándar del navegador",
  "CannotUseParameters": "Si el modo API en tiempo real o el modo de audio están habilitados, no se pueden especificar los parámetros Temperature y Max Tokens.",
  "CannotUseVoice": "Si el modo de API en tiempo real o el modo de audio están habilitados,\nno se necesita la configuración de voz sintética.",
  "ChangeBackgroundImage": "Cambiar imagen de fondo",
  "CharacterModelInfo": "El modelo puede tardar en cargar cuando se muestra por primera vez.",
  "CharacterModelLabel": "Modelo de personaje",
  "CharacterName": "Nombre del personaje",
  "CharacterSettings": "Configuración de personaje",
  "CharacterSettingsInfo": "Este valor se establece como el prompt del sistema.\nPor favor, consulte el prompt inicial y especifique las etiquetas de emoción para controlar las expresiones y movimientos del personaje. Ejemplo: [neutral]¡Buenos días![happy]¡Hoy también es un día difícil!",
  "CharacterSettingsPrompt": "Prompt de personaje",
  "Characterpreset1": "Preset 1",
  "Characterpreset2": "Preset 2",
  "Characterpreset3": "Preset 3",
  "Characterpreset4": "Preset 4",
  "Characterpreset5": "Preset 5",
  "CharacterpresetInfo": "Al seleccionar un preset, se cambiará el prompt del personaje.\nCmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows) para atajos.",
  "ChatLog": "Registro de conversación",
  "ClientID": "ID de cliente",
  "Close": "CERRAR",
  "CohereAPIKeyLabel": "Clave API de Cohere",
  "Contact": "Contacto",
  "ContactDescription": "Por favor, contácteme a través del correo electrónico o la cuenta de Twitter de abajo sobre esta aplicación.",
  "ContinuousMic": "Entrada de micrófono continua",
  "ContinuousMicActive": "Entrada de micrófono continua activa",
  "ContinuousMicInfo": "Reanudará automáticamente la entrada de micrófono cuando la IA termine de hablar. Se enviará automáticamente después de que transcurra el tiempo de silencio configurado.\nSi el tiempo configurado se supera sin que se detecte voz, la entrada de micrófono continua se desactivará automáticamente, por lo que si deseas que esté siempre activada, establece el tiempo de espera de reconocimiento de voz en 0 segundos.",
  "ContinuousMicModeOff": "El modo de entrada de micrófono continua está desactivado",
  "ContinuousMicModeOn": "El modo de entrada de micrófono continua está activado",
  "ConversationContinuityMode": "Modo de continuidad de conversación (Beta)",
  "ConversationContinuityModeInfo": "Cuando no hay comentarios, la IA intenta continuar la conversación. Actualmente solo compatible con OpenAI, Anthropic Claude y Google Gemini.",
  "ConversationContinuityModeInfo2": "Una respuesta llama a LLM varias veces, por lo que el uso de la API puede aumentar. Por favor, tenga esto en cuenta.",
  "ConversationContinuityModeInfo3": "gpt-4, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet funcionan relativamente estables.",
  "ConversationHistory": "Historial de conversación",
  "ConversationHistoryInfo": "Se recordarán las últimas {{count}} conversaciones.",
  "ConversationHistoryReset": "Restablecer historial de conversación",
  "Creator": "Creador",
  "CreatorDescription": "Creador: Tegan",
  "CustomAPIBody": "Cuerpo personalizado",
  "CustomAPIBodyInfo": "Por favor, ingresa la información del cuerpo que se incluirá en la solicitud de API en formato JSON. messages se incluirán automáticamente.",
  "CustomAPIDescription": "Nota: Los mensajes se incluirán automáticamente en el cuerpo de la solicitud. En modo de streaming, el servidor debe devolver text/event-stream.",
  "CustomAPIEndpoint": "Endpoint de API personalizada",
  "CustomAPIEndpointInfo": "Por favor, ingresa la URL del endpoint de API al que se enviará la solicitud POST.",
  "CustomAPIHeaders": "Encabezados personalizados",
  "CustomAPIHeadersInfo": "Por favor, ingresa la información de encabezado que se incluirá en la solicitud de API en formato JSON.",
  "CustomAPIStream": "Modo de streaming",
  "CustomAPIStreamForced": "Actualmente, el modo de streaming está siempre habilitado.",
  "DeepSeekAPIKeyLabel": "Clave API de DeepSeek",
  "DefaultBackground": "Fondo predeterminado",
  "Description": "Acerca de la aplicación",
  "DifyAPIKeyLabel": "Clave API de Dify",
  "DifyInfo": "Dify solo admite tipos de chatbot y agente.",
  "DifyInfo2": "La longitud del historial de conversación depende de las especificaciones de Dify.",
  "DifyInfo3": "Ejemplo: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "Si usa Dify, no se utilizará el prompt del sistema. Por favor, configure el chatbot de Dify.",
  "DocumentationDescription": "Puede ver detalles sobre cómo usar AITuberKit y tutoriales en la siguiente URL.",
  "DontShowIntroductionNextTime": "No mostrar este diálogo la próxima vez",
  "DragToReorder": "Arrastra para cambiar el orden",
  "ElevenLabsApiKey": "Clave API de ElevenLabs",
  "ElevenLabsInfo": "Se usa la API de ElevenLabs. Admite múltiples idiomas. La clave API se puede obtener desde la URL de abajo.",
  "ElevenLabsVoiceId": "ID de voz de ElevenLabs",
  "ElevenLabsVoiceIdInfo": "El ID de voz se puede seleccionar desde la URL de abajo.",
  "EnterPresetQuestion": "Por favor, ingresa una pregunta",
  "EnterURL": "URL",
  "EnterYourQuestion": "Ingrese su pregunta aquí",
  "Errors": {
    "AIAPIError": "Ocurrió un error al ejecutar la API de IA",
    "AIInvalidProperty": "La configuración del servicio de IA es incorrecta",
    "CustomAPIError": "Se produjo un error en la API personalizada",
    "EmptyAPIKey": "La clave API no está configurada",
    "EmptyLocalLLMURL": "No se ha configurado la URL del LLM local",
    "InvalidAIService": "El servicio de IA seleccionado no es válido",
    "InvalidJSON": "El formato JSON no es correcto",
    "LocalLLMAPIError": "Error de API de LLM local",
    "LocalLLMConnectionError": "Error de conexión al servidor LLM local",
    "LocalLLMError": "Error de LLM local",
    "LocalLLMNotFound": "Endpoint de LLM local no encontrado",
    "LocalLLMStreamError": "Error de stream de LLM local",
    "MethodNotAllowed": "La solicitud no es apropiada",
    "TTSServiceError": "Ocurrió un error en el servicio TTS {{serviceName}}: {{message}}",
    "UnexpectedError": "Ocurrió un error inesperado"
  },
  "ExternalLinkageMode": "Modo de vinculación externa (versión beta)",
  "FireworksAPIKeyLabel": "Clave API de Fireworks",
  "GSVITTSBatchSize": "Tamaño de lote GSVI TTS (1 ~ 100 Cuanto mayor sea el valor, más rápida será la inferencia, pero puede agotar la memoria si es demasiado grande.)",
  "GSVITTSInfo": "Configuración de GSVI TTS",
  "GSVITTSModelID": "ID del modelo GSVI TTS",
  "GSVITTSServerUrl": "API endpoint de GSVI TTS",
  "GSVITTSSpeechRate": "Velocidad del habla (0.5 ~ 2.0 Cuanto mayor sea el valor, más rápido será.)",
  "GoogleAPIKeyLabel": "Clave API de Google Gemini",
  "GoogleTTSInfo": "Usando Google Cloud Text-to-Speech. Admite múltiples idiomas.",
  "GroqAPIKeyLabel": "Clave API de Groq",
  "GroqInfo": "La API de Groq se accede directamente desde el navegador.",
  "IncludeTimestampInUserMessage": "Incluir marca de tiempo en el mensaje del usuario",
  "IncludeTimestampInUserMessageInfo": "Al incluir marcas de tiempo en los mensajes del usuario, la IA puede generar respuestas considerando el tiempo.\nPor favor, incluya el siguiente texto en su prompt del sistema:\n\n\"La entrada del usuario puede incluir [timestamp]. Esto representa la hora UTC en el momento de la solicitud, así que por favor genere respuestas considerando esta marca de tiempo.\"",
  "InitialSpeechTimeout": "Tiempo de espera de reconocimiento de voz",
  "InitialSpeechTimeoutInfo": "Configura el tiempo de espera hasta que se detecte la primera expresión después de iniciar el reconocimiento de voz. Si no se detecta ninguna expresión dentro de este tiempo, el reconocimiento de voz se detendrá automáticamente.\nSi se establece en 0 segundos, el tiempo de espera será ilimitado.",
  "InputAudio": "Audio",
  "InputText": "Texto",
  "KoeiromapInfo": "Usando API Koeiromap de Koemotion. Solo admite japonés. Para más detalles, consulte el enlace de abajo.",
  "Language": "Idioma",
  "LanguageChoice": "Elección de idioma",
  "LanguageModelURL": "Seleccione el modelo de idioma desde la URL de abajo.",
  "ListeningContinuously": "Esperando entrada de voz...",
  "Live2D": {
    "EmotionInfo": "Las emociones se pueden especificar en formato separado por comas. Si se especifican múltiples emociones, se seleccionan aleatoriamente.\nEl valor inicial es para el modelo proporcionado por AITuberKit. Si está usando un modelo original, ingrese el valor según su modelo.\nDespués de completar la conversación, se muestra la emoción \"Neutral\".",
    "Emotions": "Configuración de emociones",
    "FileInfo": "Coloque el modelo Live2D que desea usar en la carpeta public/live2d. El archivo model3.json debe existir en la raíz de esta carpeta.\nSi no se muestra en la selección, por favor recargue la pantalla o verifique si la ruta de la carpeta es correcta.",
    "Info": "Puede especificar emociones y movimientos.\nCada emoción es controlada por el prompt. Para más detalles, consulte \"Configuración de IA => Configuración de personaje\".",
    "MotionGroups": "Configuración de grupos de movimiento",
    "MotionGroupsInfo": "Los grupos de movimiento se seleccionan aleatoriamente del grupo seleccionado.\nIgual que la configuración de emociones, configúrelo según su modelo.\n\"Idle\" es el movimiento mostrado después de completar la conversación.",
    "SelectMotionGroup": "Seleccionar grupo de movimiento",
    "angryEmotions": "Enojado",
    "angryMotionGroup": "Enojado",
    "happyEmotions": "Feliz",
    "happyMotionGroup": "Feliz",
    "idleMotionGroup": "Inactivo",
    "neutralEmotions": "Neutral",
    "neutralMotionGroup": "Neutral",
    "relaxedEmotions": "Relajado",
    "relaxedMotionGroup": "Relajado",
    "sadEmotions": "Triste",
    "sadMotionGroup": "Triste",
    "surprisedEmotions": "Sorpresa",
    "surprisedMotionGroup": "Sorpresa"
  },
  "LocalLLM": "LLM local",
  "LocalLLMInfo": "El servidor LLM local debe estar en ejecución. La configuración es la siguiente.",
  "LocalLLMInfo2": "Por favor, ingrese la URL del servidor LLM local (incluyendo el número de puerto) y el nombre del modelo.",
  "LocalStorageReset": "Restablecer configuración",
  "LocalStorageResetButton": "Restablecer configuración",
  "LocalStorageResetInfo": "Las variables de entorno tienen prioridad si están configuradas. La página se recargará.",
  "LogSettings": "Historial de conversación",
  "MaxPastMessages": "Número de mensajes anteriores a mantener",
  "MaxTokens": "Número máximo de tokens",
  "MaxTokensInfo": "El número máximo de tokens varía según el modelo de IA que esté utilizando. Consulte las especificaciones de cada modelo.",
  "MessageReceiver": "Recibir instrucciones desde el exterior",
  "MessageReceiverDescription": "Puede usar la API para hacer que los personajes de IA hablen desde el exterior.",
  "Milliseconds": "Milisegundos",
  "MistralAIAPIKeyLabel": "Clave API de MistralAI",
  "NijiVoiceActorId": "ID del actor",
  "NijiVoiceApiKey": "Clave API de NijiVoice",
  "NijiVoiceEmotionalLevel": "Nivel emocional",
  "NijiVoiceInfo": "Se usa la API de NijiVoice. Solo admite japonés. La clave API se puede obtener desde la URL de abajo.",
  "NijiVoiceSoundDuration": "Duración del sonido",
  "NijiVoiceSpeed": "Velocidad del habla",
  "NotConnectedToExternalAssistant": "No conectado a un asistente externo.",
  "OpenAIAPIKeyLabel": "Clave API de OpenAI",
  "OpenAITTSInfo": "Usando OpenAI. Admite múltiples idiomas. Si selecciona OpenAI como servicio de IA, no necesita configurar la clave API abajo.",
  "OpenAITTSModel": "Modelo",
  "OpenAITTSSpeed": "Velocidad",
  "OpenAITTSVoice": "Tipo de voz",
  "OpenSendMessagePage": "Abrir página de envío de mensaje",
  "OpenVRM": "Abrir VRM",
  "OtherSettings": "Otros",
  "PdfConvertButton": "Convertir PDF a diapositivas",
  "PdfConvertDescription": "Convertir PDF a datos de modo presentación. Solo disponible cuando el servicio de IA seleccionado es OpenAI, Anthropic Claude o Google Gemini.",
  "PdfConvertError": "Error en la conversión",
  "PdfConvertFileUpload": "Seleccionar archivo PDF",
  "PdfConvertFolderName": "Nombre de la carpeta de guardado",
  "PdfConvertLabel": "Conversión de diapositivas PDF",
  "PdfConvertLoading": "Convirtiendo...",
  "PdfConvertModelSelect": "Seleccionar modelo",
  "PdfConvertSubmitError": "Por favor, asegúrese de que el archivo PDF, el nombre de la carpeta y la clave API estén configurados.",
  "PdfConvertSuccess": "Conversión completada",
  "PerplexityAPIKeyLabel": "Clave API de Perplexity",
  "PresetQuestions": "Preguntas predefinidas",
  "PresetQuestionsInfo": "Puedes crear y registrar múltiples patrones de preguntas por adelantado. Las preguntas registradas se mostrarán en forma de botones en la interfaz de usuario del usuario y se establecerán en el campo de entrada de chat al hacer clic.",
  "RealtimeAPIMode": "Modo API en tiempo real",
  "RealtimeAPIModeContentType": "Tipo de envío",
  "RealtimeAPIModeVoice": "Tipo de voz",
  "RepositoryURL": "URL del repositorio:",
  "SearchGrounding": "Usar búsqueda contextual",
  "SearchGroundingDescription": "Al usar la función multimodal, la función de búsqueda se desactiva automáticamente.",
  "Select": "Seleccionar",
  "SelectAIService": "Seleccionar servicio de IA",
  "SelectModel": "Seleccionar modelo",
  "SelectedSlideDocs": "Documentos de presentación seleccionados",
  "SendMessage": {
    "aiGenerateDescription": "La IA genera una respuesta del mensaje enviado y luego la pronuncia. Si se envían múltiples mensajes, se procesan en orden. El modelo de IA y el modelo de voz son los seleccionados en la configuración de AITuberKit. El prompt del sistema puede seleccionarse para usar el prompt del sistema de AITuberKit o un prompt del sistema personalizado. Si desea cargar el historial de conversación anterior, incluya la cadena [conversation_history] en el prompt del sistema o mensaje del usuario.",
    "aiGenerateTitle": "Generar respuesta de IA y luego hablar",
    "directSendDescription": "Puede enviar el mensaje directamente al personaje de IA. Si se envían múltiples mensajes, se procesan en orden. El modelo de voz es el seleccionado en la configuración de AITuberKit.",
    "directSendTitle": "Hablar directamente al personaje de IA",
    "title": "Adaptador externo AITuberKit",
    "useCurrentSystemPrompt": "Usar prompt del sistema de AITuberKit",
    "userInputDescription": "El mensaje enviado se procesa igual que cuando se ingresa desde el formulario de entrada de AITuberKit. Si se envían múltiples mensajes, se procesan en orden. El modelo de IA y el modelo de voz son los seleccionados en la configuración de AITuberKit. El prompt del sistema y el historial de conversación son los valores configurados en AITuberKit.",
    "userInputTitle": "Enviar entrada de usuario"
  },
  "ShowAssistantText": "Mostrar cuadro de respuesta",
  "ShowCharacterName": "Mostrar nombre del personaje en el cuadro de respuesta",
  "ShowCharacterPresetMenu": "Mostrar botón de menú de preajustes de personaje",
  "ShowControlPanel": "Mostrar botón de configuración",
  "ShowControlPanelInfo": "La pantalla de configuración se puede mostrar con Cmd + . (Mac) / Ctrl + . (Windows).\nSi está utilizando un teléfono inteligente, también puede hacerlo manteniendo presionado en la esquina superior izquierda de la pantalla (aproximadamente 1 segundo).",
  "ShowSilenceProgressBar": "Mostrar barra de progreso de detección de silencio",
  "SlideMode": "Modo presentación",
  "SlideModeDescription": "Este es un modo donde la IA presenta diapositivas automáticamente. Solo está disponible cuando el servicio de IA seleccionado es OpenAI, Anthropic Claude o Google Gemini.",
  "SlideSettings": "Configuración de diapositivas",
  "SourceCodeDescription1": "El código fuente de esta aplicación está disponible públicamente en GitHub. Siéntase libre de modificarlo y adaptarlo como desee.",
  "SourceCodeDescription2": "Para uso comercial, consulte el README del mismo repositorio.",
  "SpeakerSelection": "Selección de hablante",
  "SpeechInputSettings": "Configuración de entrada de voz",
  "SpeechRecognitionMode": "Modo de reconocimiento de voz",
  "SpeechRecognitionModeDisabledInfo": "Si el modo de audio está habilitado, solo se puede usar el reconocimiento de voz del navegador.\nAdemás, en el modo de API en tiempo real, solo se puede usar el reconocimiento de voz del navegador y la función de tiempo de espera de reconocimiento de voz estará desactivada.",
  "SpeechRecognitionModeInfo": "Puedes seleccionar el modo de reconocimiento de voz.\n\"Estándar del navegador\" utiliza el reconocimiento de voz integrado en el navegador. \"OpenAI TTS\" utiliza la API de Texto a Voz de OpenAI.\nGeneralmente, se recomienda \"Estándar del navegador\" ya que tiene mayor precisión y velocidad de reconocimiento. Sin embargo, si estás utilizando un navegador que no es compatible con la API WebSpeech, como Firefox, selecciona \"OpenAI TTS\".",
  "StatusOff": "Estado: DESACTIVADO",
  "StatusOn": "Estado: ACTIVADO",
  "StyleBeatVITS2ApiKey": "Clave API",
  "StyleBeatVITS2Length": "Velocidad del habla",
  "StyleBeatVITS2ModelID": "ID del modelo",
  "StyleBeatVITS2SdpRatio": "Ratio de mezcla SDP/DP",
  "StyleBeatVITS2ServerURL": "URL del servidor",
  "StyleBeatVITS2Style": "Estilo",
  "StyleBertVITS2Info": "Usando Style-Bert-VITS2. Solo admite japonés, inglés y chino. Si usa una API local, necesita descargar y ejecutar la aplicación que se adapte a su entorno desde el sitio de abajo. También configure una clave API si es necesario.",
  "SyntheticVoiceEngineChoice": "Elegir motor de síntesis de voz",
  "TechnologyIntroduction": "Introducción a la tecnología",
  "TechnologyIntroductionDescription1": "Esta aplicación fue creada modificando el <b>ChatVRM</b> de pixiv. El código fuente original se puede encontrar",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "Para mostrar y manipular modelos 3D,",
  "TechnologyIntroductionDescription4": "se utiliza. Para generar texto de conversación, se utilizan varios LLM como",
  "TechnologyIntroductionDescription5": "se utilizan. Para la síntesis de voz, se utilizan varios motores TTS como",
  "TechnologyIntroductionDescription6": "se utilizan. Para más detalles, consulte este",
  "TechnologyIntroductionDescription7": ".",
  "TechnologyIntroductionLink1": "aquí",
  "TechnologyIntroductionLink2": "artículo explicativo",
  "Temperature": "Temperatura",
  "TestVoice": "Probar voz",
  "Toasts": {
    "FirefoxNotSupported": "Esta función no está soportada en Firefox",
    "FunctionExecuting": "Ejecutando {{funcName}}",
    "FunctionExecutionFailed": "La ejecución de {{funcName}} falló",
    "PresetSwitching": "Se ha cambiado a {{presetName}}.",
    "SpeechRecognitionError": "Ocurrió un error de reconocimiento de voz",
    "WebSocketConnectionAttempt": "Intentando conexión WebSocket...",
    "WebSocketConnectionClosed": "Conexión WebSocket cerrada",
    "WebSocketConnectionError": "Error en la conexión WebSocket",
    "WebSocketConnectionSuccess": "Conexión WebSocket exitosa",
    "WhisperError": "Se produjo un error en el reconocimiento de voz por Whisper"
  },
  "UpdateRealtimeAPISettings": "Actualizar configuración de API en tiempo real",
  "UpdateRealtimeAPISettingsInfo": "Al actualizar la clave API, endpoint de Azure, tipo de voz, modelo o prompt del sistema, presione el botón de actualización para iniciar una nueva sesión WebSocket.",
  "UpdateSpeakerList": "Actualizar lista de hablantes",
  "UploadBackground": "Subir imagen de fondo",
  "UseVideoAsBackground": "Usar pantalla compartida o webcam como fondo",
  "UsingAivisSpeech": "AivisSpeech",
  "UsingAzureTTS": "Usando Azure OpenAI",
  "UsingElevenLabs": "ElevenLabs",
  "UsingGSVITTS": "GSVI TTS",
  "UsingGoogleTTS": "Usar Google Text-to-Speech",
  "UsingKoeiromap": "Koeiromap",
  "UsingNijiVoice": "NijiVoice",
  "UsingOpenAITTS": "Usando OpenAI",
  "UsingStyleBertVITS2": "Style-Bert-VITS2",
  "UsingVoiceVox": "VOICEVOX",
  "VoiceAdjustment": "Ajuste de voz",
  "VoiceEngineInstruction": "Seleccione el motor de síntesis de voz que desea usar.",
  "VoiceSettings": "Configuración de voz sintética",
  "VoiceVoxInfo": "Usando VOICEVOX. Solo admite japonés. Usa una API local, necesita descargar y ejecutar la aplicación que se adapte a su entorno desde el sitio de abajo.",
  "VoicevoxIntonation": "Entonación",
  "VoicevoxPitch": "Tono",
  "VoicevoxServerUrl": "URL del servidor VOICEVOX",
  "VoicevoxSpeed": "Velocidad",
  "WhisperAPIKeyInfo": "El modo Whisper requiere una clave API de OpenAI. Por favor, configura la clave API de OpenAI en la configuración de IA.",
  "WhisperSpeechRecognition": "Usar reconocimiento de voz OpenAI TTS",
  "WhisperTranscriptionModel": "Modelo de transcripción",
  "WhisperTranscriptionModelInfo": "Puedes seleccionar el modelo que se utilizará para el reconocimiento de voz. Cuanto más avanzado sea el modelo, mayor será la precisión del reconocimiento, pero los costos de la API pueden ser más altos.",
  "YoutubeAPIKey": "Clave API de YouTube",
  "YoutubeInfo": "El primer carácter del comentario es '#' y será ignorado.",
  "YoutubeLiveID": "ID en directo de YouTube",
  "YoutubeMode": "Modo YouTube",
  "YoutubeSettings": "Configuración de YouTube",
  "characterpresetInfo": "Al seleccionar un preajuste, cambia la indicación de caracteres.\nCmd + Mayús + 1~5 (Mac) / Ctrl + Mayús + 1~5 (Windows) para los atajos.\nSi se selecciona un preajuste mientras se mantiene pulsada la tecla Mayús, se guarda el carácter actual en el preajuste."
}
