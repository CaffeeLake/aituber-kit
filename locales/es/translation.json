{
  "AISettings": "Configuración de IA",
  "APIKeyInstruction": "Puede obtener la clave API desde el siguiente enlace. Por favor, introduzca la clave API obtenida en el formulario.",
  "APIKeyNotEntered": "No se ha introducido la clave API.",
  "AboutThisApplication": "Acerca de esta aplicación",
  "AboutThisApplicationDescription": "Disfrute de la conversación con personajes 3D en su navegador web, utilizando micrófono, entrada de texto y síntesis de voz. Puede cambiar el personaje (VRM), configurar su personalidad y ajustar la voz.<br />La configuración se puede cambiar desde el botón de menú en la esquina superior izquierda.",
  "AboutThisApplicationDescription2": "Con AITuberKit, puede disfrutar de conversaciones con personajes de IA directamente en su navegador web. Consulte cada elemento de configuración para cambiar el personaje, configurar su personalidad y ajustar la voz.",
  "AivisSpeechInfo": "Utilizando AivisSpeech. Solo compatible con japonés. Como se utiliza la API local, debe descargar e iniciar la aplicación adecuada para su entorno desde el siguiente sitio.",
  "AivisSpeechIntonation": "Entonación",
  "AivisSpeechPitch": "Tono",
  "AivisSpeechServerUrl": "URL del servidor AivisSpeech",
  "AivisSpeechSpeaker": "Hablante",
  "AivisSpeechSpeed": "Velocidad de habla",
  "AnswerGenerating": "Generando respuesta",
  "AnthropicAPIKeyLabel": "Clave API de Anthropic",
  "AudioMode": "Modo de audio",
  "AuthFileInstruction": "Se requiere una clave API o un archivo JSON de autenticación. Obténgalo del siguiente enlace y, en caso de archivo JSON, colóquelo en la carpeta raíz del repositorio con el nombre credentials.json.",
  "AzureAPIKeyLabel": "Clave API de Azure OpenAI",
  "AzureAPIURL": "URL de API de Azure OpenAI",
  "AzureEndpoint": "Azure Endpoint",
  "AzureTTSInfo": "Utilizando Azure OpenAI. Compatible con múltiples idiomas.",
  "BackgroundImage": "Imagen de fondo",
  "BackgroundSettings": "Configuración de fondo",
  "BackgroundSettingsDescription": "Puede subir y seleccionar una imagen de fondo para la aplicación.",
  "BasedSettings": "Configuración básica",
  "BrowserSpeechRecognition": "Usar reconocimiento de voz estándar del navegador",
  "CannotUseParameters": "Cuando el modo API en tiempo real o el modo de audio están habilitados, no se pueden especificar los parámetros Temperature y Max Tokens.",
  "CannotUseVoice": "Cuando el modo API en tiempo real o el modo de audio están habilitados,\nno es necesaria la configuración de voz sintética.",
  "ChangeBackgroundImage": "Cambiar imagen de fondo",
  "CharacterModelInfo": "Algunos modelos pueden tardar en cargarse inicialmente.",
  "CharacterModelLabel": "Modelo de personaje",
  "CharacterName": "Nombre del personaje",
  "CharacterSettings": "Configuración de personaje",
  "CharacterSettingsInfo": "Este valor se establecerá como prompt del sistema.\nConsultando el prompt inicial, puede controlar las expresiones y movimientos del personaje especificando etiquetas emocionales. Ejemplo: [neutral]¡Buenos días![happy]¡Gracias por tu esfuerzo hoy!",
  "CharacterSettingsPrompt": "Prompt del personaje",
  "Characterpreset1": "Preset 1",
  "Characterpreset2": "Preset 2",
  "Characterpreset3": "Preset 3",
  "Characterpreset4": "Preset 4",
  "Characterpreset5": "Preset 5",
  "CharacterpresetInfo": "Al seleccionar un preset, el prompt del personaje cambiará.\nPuede usar los atajos Cmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows).",
  "ChatLog": "Registro de conversación",
  "ClientID": "ID de cliente",
  "Close": "Cerrar",
  "CohereAPIKeyLabel": "Clave API de Cohere",
  "Contact": "Contacto",
  "ContactDescription": "Para consultas sobre esta aplicación, por favor contacte con la siguiente dirección de correo electrónico o cuenta de Twitter.",
  "ContinuousMic": "Entrada de micrófono continua",
  "ContinuousMicActive": "Entrada de micrófono continua activa",
  "ContinuousMicInfo": "Reinicia automáticamente la entrada de micrófono cuando finaliza el habla de la IA. Envía automáticamente después de transcurrido el tiempo de silencio configurado.\nSi el reconocimiento de voz no se realiza y se supera el tiempo configurado, la entrada de micrófono continua se desactivará automáticamente. Si desea mantenerla siempre activada, configure el tiempo de espera de reconocimiento de voz a 0 segundos.",
  "ContinuousMicModeOff": "Modo de entrada de micrófono continua desactivado",
  "ContinuousMicModeOn": "Modo de entrada de micrófono continua activado",
  "ConversationContinuityMode": "Modo de continuidad de conversación (beta)",
  "ConversationContinuityModeInfo": "Este es un modo donde la IA intenta continuar la conversación cuando no hay comentarios. Actualmente solo compatible con OpenAI, Anthropic Claude y Google Gemini.",
  "ConversationContinuityModeInfo2": "Tenga en cuenta que puede aumentar el costo de uso de API ya que se realizan múltiples llamadas a LLM en una sola respuesta.",
  "ConversationContinuityModeInfo3": "Funciona de manera relativamente estable con gpt-4o, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet.",
  "ConversationHistory": "Historial de conversación",
  "ConversationHistoryInfo": "Se conservarán los últimos {{count}} mensajes de conversación como memoria.",
  "ConversationHistoryReset": "Reiniciar historial de conversación",
  "Creator": "Información del creador",
  "CreatorDescription": "Creador: Nike",
  "CustomAPIBody": "Cuerpo personalizado",
  "CustomAPIBodyInfo": "Introduzca la información del cuerpo a incluir en la solicitud API en formato JSON. Los mensajes se incluirán automáticamente.",
  "CustomAPIDescription": "Nota: Los mensajes se incluyen automáticamente en el cuerpo de la solicitud. En modo streaming, el servidor debe devolver text/event-stream.",
  "CustomAPIEndpoint": "Punto final de API personalizado",
  "CustomAPIEndpointInfo": "Introduzca la URL del punto final de API al que enviar solicitudes POST.",
  "CustomAPIHeaders": "Encabezados personalizados",
  "CustomAPIHeadersInfo": "Introduzca la información de encabezado a incluir en la solicitud API en formato JSON.",
  "CustomAPIStream": "Modo streaming",
  "CustomAPIStreamForced": "Actualmente, el modo streaming está siempre habilitado.",
  "CustomVoiceTextPlaceholder": "Introduzca el texto que desea escuchar",
  "DeepSeekAPIKeyLabel": "Clave API de DeepSeek",
  "DefaultBackground": "Fondo predeterminado",
  "Description": "Acerca de la aplicación",
  "DifyAPIKeyLabel": "Clave API de Dify",
  "DifyInfo": "Dify solo es compatible con el tipo chatbot o agente.",
  "DifyInfo2": "La longitud del historial de conversación depende de la configuración del chatbot Dify.",
  "DifyInfo3": "Ejemplo: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "Si está utilizando Dify, este prompt del sistema no se utilizará. Por favor, configúrelo en el chatbot de Dify.",
  "Documentation": "Documentación",
  "DocumentationDescription": "Puede ver instrucciones detalladas y tutoriales de AITuberKit en la siguiente URL.",
  "DontShowIntroductionNextTime": "No mostrar este diálogo la próxima vez",
  "DragToReorder": "Arrastre para reordenar",
  "EditSlideScripts": "セリフ編集",
  "ElevenLabsApiKey": "Clave API de ElevenLabs",
  "ElevenLabsInfo": "Utilizando la API de ElevenLabs. Compatible con múltiples idiomas. Por favor, obtenga la clave API desde la siguiente URL.",
  "ElevenLabsVoiceId": "ID de voz de ElevenLabs",
  "ElevenLabsVoiceIdInfo": "Por favor, seleccione el ID de voz desde la siguiente URL.",
  "EnglishToJapanese": "Leer palabras en inglés en japonés",
  "EnterPresetQuestion": "Introduzca una pregunta",
  "EnterURL": "Introduzca URL",
  "EnterYourQuestion": "Escribe lo que quieras preguntar",
  "Errors": {
    "AIAPIError": "Se ha producido un error al ejecutar la API de IA",
    "AIInvalidProperty": "Los valores de configuración del servicio de IA no son correctos",
    "CustomAPIError": "Se ha producido un error en la API personalizada",
    "EmptyAPIKey": "No se ha configurado la clave API",
    "EmptyLocalLLMURL": "No se ha configurado la URL del LLM local",
    "InvalidAIService": "El servicio de IA seleccionado no es correcto",
    "InvalidJSON": "El formato JSON no es correcto",
    "LocalLLMAPIError": "Se ha producido un error en la API del LLM local",
    "LocalLLMConnectionError": "No se puede conectar al servidor LLM local",
    "LocalLLMError": "Se ha producido un error en el LLM local",
    "LocalLLMNotFound": "No se encontró el punto final del LLM local",
    "LocalLLMStreamError": "Se ha producido un error en el procesamiento de stream del LLM local",
    "MethodNotAllowed": "La solicitud no es apropiada",
    "TTSServiceError": "Se ha producido un error en el servicio TTS {{serviceName}}: {{message}}",
    "UnexpectedError": "Se ha producido un error desconocido"
  },
  "ExternalLinkageMode": "Modo de conexión externa (beta)",
  "FireworksAPIKeyLabel": "Clave API de Fireworks",
  "GSVITTSBatchSize": "Tamaño de lote GSVI TTS (1 ~ 100 cuanto mayor sea el valor, más rápida será la inferencia, pero si es demasiado grande puede agotar la memoria)",
  "GSVITTSInfo": "Configuración de GSVI TTS",
  "GSVITTSModelID": "ID del modelo GSVI TTS",
  "GSVITTSServerUrl": "URL del servidor GSVI TTS",
  "GSVITTSSpeechRate": "Velocidad de habla (0.5 ~ 2.0 cuanto mayor sea el valor, más rápido)",
  "GoogleAPIKeyLabel": "Clave API de Google Gemini",
  "GoogleTTSInfo": "Utilizando Google Cloud Text-to-Speech. Compatible con múltiples idiomas.",
  "GroqAPIKeyLabel": "Clave API de Groq",
  "GroqInfo": "La API de Groq se accede directamente desde el navegador.",
  "IncludeSystemMessages": "Incluir mensajes del sistema",
  "IncludeTimestampInUserMessage": "Incluir marca de tiempo en los mensajes del usuario",
  "IncludeTimestampInUserMessageInfo": "Incluir una marca de tiempo en los mensajes del usuario permite que la IA genere respuestas considerando el tiempo.\nPor favor, incluya el siguiente texto en el prompt del sistema:\n\n\"Las entradas del usuario pueden incluir [timestamp]. Esto representa la hora en zona horaria UTC en el momento de la solicitud, así que por favor genera una respuesta considerando esa hora.\"",
  "InitialSpeechTimeout": "Tiempo de espera de reconocimiento de voz",
  "InitialSpeechTimeoutInfo": "Establece el tiempo de espera después de iniciar el reconocimiento de voz hasta que se detecte la primera expresión. Si no se detecta ninguna expresión dentro de este tiempo, el reconocimiento de voz se detendrá automáticamente.\nSi se establece en 0 segundos, el tiempo de espera será ilimitado.",
  "InputAudio": "Voz",
  "InputText": "Texto",
  "KoeiromapInfo": "Utilizando la API Koeiromap de Koemotion. Solo compatible con japonés. Para más detalles, consulte lo siguiente.",
  "Language": "Configuración de idioma",
  "LanguageChoice": "Selección de idioma",
  "LanguageModelURL": "Por favor, seleccione el modelo de lenguaje en la siguiente URL.",
  "ListeningContinuously": "Esperando entrada de voz...",
  "Live2D": {
    "EmotionInfo": "Las emociones pueden especificarse múltiples veces separadas por comas. Si se especifican varias, se seleccionará una al azar.\nLos valores predeterminados corresponden a los modelos proporcionados con AITuberKit. Si utiliza un modelo original, introduzca valores adecuados para su modelo.\nDespués de completar la conversación, se mostrará la expresión \"normal\".",
    "Emotions": "Configuración de expresiones",
    "FileInfo": "Coloque la carpeta del modelo Live2D que desea utilizar en public/live2d. Debe existir un archivo model3.json directamente en esta carpeta.\nSi no aparece en las opciones, recargue la pantalla o verifique que la ruta de la carpeta sea correcta.",
    "Info": "Puede especificar emociones y movimientos.\nCada emoción se controla con el prompt. Para más detalles, consulte \"Configuración de IA => Configuración de personaje\".",
    "MotionGroups": "Configuración de grupos de movimiento",
    "MotionGroupsInfo": "Los movimientos se seleccionan aleatoriamente del grupo seleccionado.\nAl igual que con la configuración de expresiones, configúrelo según su modelo.\nEl \"Tiempo de espera\" es el movimiento que se muestra después de completar la conversación.",
    "SelectMotionGroup": "Seleccionar grupo de movimiento",
    "angryEmotions": "Enfadado",
    "angryMotionGroup": "Enfadado",
    "happyEmotions": "Feliz",
    "happyMotionGroup": "Feliz",
    "idleMotionGroup": "Tiempo de espera",
    "neutralEmotions": "Normal",
    "neutralMotionGroup": "Normal",
    "relaxedEmotions": "Relajado",
    "relaxedMotionGroup": "Relajado",
    "sadEmotions": "Triste",
    "sadMotionGroup": "Triste",
    "surprisedEmotions": "Sorprendido",
    "surprisedMotionGroup": "Sorprendido"
  },
  "LocalLLM": "LLM local",
  "LocalLLMInfo": "Es necesario iniciar el servidor LLM local.",
  "LocalLLMInfo2": "Introduzca la URL del LLM local (incluyendo el número de puerto) y el nombre del modelo.",
  "LocalStorageReset": "Reiniciar configuración",
  "LocalStorageResetButton": "Reiniciar configuración",
  "LocalStorageResetInfo": "Si se establecen variables de entorno, sus valores tendrán prioridad. La página se recargará.",
  "LogSettings": "Historial de conversación",
  "MaxPastMessages": "Número de mensajes pasados a retener",
  "MaxTokens": "Número máximo de tokens",
  "MaxTokensInfo": "El número máximo de tokens varía según el modelo de IA utilizado. Verifique las especificaciones de cada modelo.",
  "MessageReceiver": "Aceptar instrucciones externas",
  "MessageReceiverDescription": "Puede dar instrucciones para el habla del personaje de IA desde el exterior utilizando API.",
  "Milliseconds": "milisegundos",
  "MistralAIAPIKeyLabel": "Clave API de MistralAI",
  "NijiVoiceActorId": "ID del hablante",
  "NijiVoiceApiKey": "Clave API de NijiVoice",
  "NijiVoiceEmotionalLevel": "Nivel emocional",
  "NijiVoiceInfo": "Utilizando la API de NijiVoice. Solo compatible con japonés. Por favor, obtenga la clave API desde la siguiente URL.",
  "NijiVoiceSoundDuration": "Duración del sonido",
  "NijiVoiceSpeed": "Velocidad de habla",
  "NoSpeechTimeout": "Tiempo de espera de detección de silencio",
  "NoSpeechTimeoutInfo": "Establece el tiempo después del cual la entrada se terminará automáticamente cuando se continúe en silencio durante la entrada de voz.\nSi se establece en 0 segundos, se desactivará el envío automático por detección de silencio.",
  "NotConnectedToExternalAssistant": "No conectado a asistente externo.",
  "OpenAIAPIKeyLabel": "Clave API de OpenAI",
  "OpenAITTSInfo": "Utilizando OpenAI. Compatible con múltiples idiomas. Si ha seleccionado OpenAI como servicio de IA, no es necesario configurar la siguiente clave API.",
  "OpenAITTSModel": "Modelo",
  "OpenAITTSSpeed": "Velocidad de habla",
  "OpenAITTSVoice": "Tipo de voz",
  "OpenSendMessagePage": "Abrir página de envío de mensajes",
  "OpenVRM": "Abrir VRM",
  "OtherSettings": "Otros",
  "PdfConvertButton": "Convertir PDF a diapositivas",
  "PdfConvertDescription": "Convierte PDF a datos para el modo presentación. Solo disponible cuando el servicio de IA seleccionado es OpenAI, Anthropic Claude o Google Gemini.",
  "PdfConvertError": "Error en la conversión",
  "PdfConvertFileUpload": "Seleccionar archivo PDF",
  "PdfConvertFolderName": "Nombre de carpeta de guardado",
  "PdfConvertLabel": "Conversión de diapositivas PDF",
  "PdfConvertLoading": "Convirtiendo...",
  "PdfConvertModelSelect": "Seleccionar modelo",
  "PdfConvertSubmitError": "Por favor, verifique que el archivo PDF, el nombre de la carpeta y la clave API estén configurados",
  "PdfConvertSuccess": "Conversión completada",
  "PerplexityAPIKeyLabel": "Clave API de Perplexity",
  "PleaseSelectSlide": "スライドを選択してください",
  "PresetQuestions": "Preguntas preestablecidas",
  "PresetQuestionsInfo": "Puede crear y registrar previamente múltiples patrones de preguntas. Las preguntas registradas se mostrarán como botones en la interfaz de usuario, y al hacer clic se establecerán en el campo de entrada de chat.",
  "RealtimeAPIMode": "Modo API en tiempo real",
  "RealtimeAPIModeContentType": "Tipo de envío",
  "RealtimeAPIModeVoice": "Tipo de voz",
  "RepositoryURL": "URL del repositorio:",
  "SearchGrounding": "Utilizar función de búsqueda",
  "SearchGroundingDescription": "Cuando se utiliza la función multimodal, la función de búsqueda se desactiva automáticamente.",
  "Select": "Por favor seleccione",
  "SelectAIService": "Seleccionar servicio de IA",
  "SelectModel": "Seleccionar modelo",
  "SelectedSlideDocs": "Presentación a utilizar",
  "SendMessage": {
    "aiGenerateDescription": "La IA generará una respuesta a partir del mensaje enviado, y el personaje de IA hablará esa respuesta. Si envía varios, se procesarán en orden.\nSe utilizarán el modelo de IA y el modelo de voz seleccionados en la configuración de AITuberKit.\nPuede elegir entre utilizar el prompt del sistema de AITuberKit o un prompt del sistema personalizado.\nPara cargar el historial de conversaciones anteriores, incluya la cadena [conversation_history] en cualquier posición del prompt del sistema o mensaje del usuario.",
    "aiGenerateTitle": "Generar respuesta con IA y luego hacerla hablar",
    "directSendDescription": "Puede hacer que el personaje de IA hable directamente el mensaje enviado. Si envía varios, se procesarán en orden.\nSe utilizará el modelo de voz seleccionado en la configuración de AITuberKit.",
    "directSendTitle": "Hacer hablar directamente al personaje de IA",
    "title": "Adaptador externo de AITuberKit",
    "useCurrentSystemPrompt": "Utilizar el prompt del sistema de AITuberKit",
    "userInputDescription": "El mensaje enviado será procesado de la misma manera que si se introdujera desde el formulario de entrada de AITuberKit. Si envía varios, se procesarán en orden.\nSe utilizarán el modelo de IA y el modelo de voz seleccionados en la configuración de AITuberKit.\nSe utilizarán el prompt del sistema y el historial de conversación de AITuberKit.",
    "userInputTitle": "Enviar entrada de usuario"
  },
  "ShowAssistantText": "Mostrar la caja de respuesta",
  "ShowCharacterName": "Mostrar el nombre del personaje en la caja de respuesta",
  "ShowCharacterPresetMenu": "Mostrar botón de menú de presets de personaje",
  "ShowControlPanel": "Mostrar el panel de control",
  "ShowControlPanelInfo": "Puede mostrar la pantalla de configuración con Cmd + . (Mac) / Ctrl + . (Windows).\nSi utiliza un smartphone, también puede hacerlo manteniendo pulsada la esquina superior izquierda de la pantalla (aproximadamente 1 segundo).",
  "ShowSilenceProgressBar": "Mostrar barra de progreso de detección de silencio",
  "SlideMode": "Modo presentación",
  "SlideModeDescription": "Modo en el que la IA presenta automáticamente diapositivas. Solo válido cuando el servicio de IA seleccionado es OpenAI, Anthropic Claude o Google Gemini.",
  "SlideSettings": "Configuración de presentación",
  "SourceCodeDescription1": "El código fuente de esta aplicación está disponible en GitHub. Puede modificarlo libremente.",
  "SourceCodeDescription2": "Para el uso comercial, consulte el README en el mismo repositorio.",
  "SpeakerSelection": "Selección de tipo de voz",
  "SpeechInputSettings": "Configuración de entrada de voz",
  "SpeechRecognitionMode": "Modo de reconocimiento de voz",
  "SpeechRecognitionModeDisabledInfo": "Cuando el modo de audio está habilitado, solo se puede utilizar el reconocimiento de voz del navegador.\nAdemás, en el modo API en tiempo real, solo se puede utilizar el reconocimiento de voz del navegador y la función de tiempo de espera de reconocimiento de voz estará desactivada.",
  "SpeechRecognitionModeInfo": "Puede seleccionar el modo de reconocimiento de voz.\n\"Estándar del navegador\" utiliza el reconocimiento de voz incorporado en el navegador. \"OpenAI TTS\" utiliza la API Text to Speech de OpenAI.\nGeneralmente, se recomienda \"Estándar del navegador\" ya que tiene mayor precisión y velocidad de reconocimiento. Sin embargo, si utiliza un navegador que no es compatible con WebSpeech API como Firefox, seleccione \"OpenAI TTS\".",
  "StatusOff": "Estado: DESACTIVADO",
  "StatusOn": "Estado: ACTIVADO",
  "StyleBeatVITS2ApiKey": "Clave API",
  "StyleBeatVITS2Length": "Velocidad de habla",
  "StyleBeatVITS2ModelID": "ID del modelo",
  "StyleBeatVITS2SdpRatio": "Relación de mezcla SDP/DP",
  "StyleBeatVITS2ServerURL": "URL del servidor",
  "StyleBeatVITS2Style": "Estilo",
  "StyleBertVITS2Info": "Utilizando Style-Bert-VITS2. Solo compatible con japonés, inglés y chino. Si utiliza la API local, debe descargar e iniciar la aplicación adecuada para su entorno desde el siguiente sitio. Configure también la clave API si es necesario.",
  "SyntheticVoiceEngineChoice": "Selección de motor de voz sintética",
  "TechnologyIntroduction": "Introducción tecnológica",
  "TechnologyIntroductionDescription1": "Esta aplicación está creada modificando <b>ChatVRM</b> de pixiv Inc. Puede ver el código fuente original ",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "Para la visualización y manipulación de modelos 3D se utiliza",
  "TechnologyIntroductionDescription4": ", para la generación de texto conversacional",
  "TechnologyIntroductionDescription5": "y otros LLM, y para la síntesis de voz",
  "TechnologyIntroductionDescription6": "y otros TTS. Para más detalles, consulte este",
  "TechnologyIntroductionDescription7": ".",
  "TechnologyIntroductionLink1": "aquí",
  "TechnologyIntroductionLink2": "artículo explicativo",
  "Temperature": "Temperature",
  "TestSelectedVoice": "Reproducir",
  "TestVoice": "Probar la voz",
  "TestVoiceSettings": "Prueba de voz",
  "Toasts": {
    "FirefoxNotSupported": "Firefoxではこの機能はサポートされていません",
    "FunctionExecuting": "{{funcName}}を実行しています",
    "FunctionExecutionFailed": "{{funcName}}の実行に失敗しました",
    "NoSpeechDetected": "音声が検出されませんでした。",
    "PresetSwitching": "{{presetName}}に切り替わりました。",
    "SpeechRecognitionError": "音声認識エラーが発生しました",
    "UsingTool": "{{toolName}}を使用中",
    "WebSocketConnectionAttempt": "WebSocket接続を試みています...",
    "WebSocketConnectionClosed": "WebSocket接続が閉じられました",
    "WebSocketConnectionError": "WebSocket接続にエラーが発生しました",
    "WebSocketConnectionSuccess": "WebSocket接続に成功しました",
    "WhisperError": "Whisperによる音声認識でエラーが発生しました"
  },
  "UpdateRealtimeAPISettings": "Actualizar configuración de API en tiempo real",
  "UpdateRealtimeAPISettingsInfo": "Por favor, pulse el botón de actualización para iniciar una nueva sesión WebSocket cuando actualice la clave API, Azure Endpoint, tipo de voz, modelo o prompt del sistema.",
  "UpdateSpeakerList": "Actualizar lista de hablantes",
  "UploadBackground": "Subir imagen de fondo",
  "UseVideoAsBackground": "Usar pantalla compartida o cámara web como fondo",
  "UsingAivisSpeech": "Usar AivisSpeech",
  "UsingAzureTTS": "Usar Azure OpenAI",
  "UsingElevenLabs": "Usar ElevenLabs",
  "UsingGSVITTS": "Usar GSVI TTS",
  "UsingGoogleTTS": "Usar Google Text-to-Speech",
  "UsingKoeiromap": "Usar Koeiromap",
  "UsingNijiVoice": "Usar NijiVoice",
  "UsingOpenAITTS": "Usar OpenAI",
  "UsingStyleBertVITS2": "Usar Style-Bert-VITS2",
  "UsingVoiceVox": "Usar VOICEVOX",
  "VoiceAdjustment": "Ajuste de voz",
  "VoiceEngineInstruction": "Por favor, seleccione el motor de síntesis de voz a utilizar.",
  "VoiceSettings": "Configuración de voz sintética",
  "VoiceVoxInfo": "Utilizando VOICEVOX. Solo compatible con japonés. Como se utiliza la API local, debe descargar e iniciar la aplicación adecuada para su entorno desde el siguiente sitio.",
  "VoicevoxIntonation": "Entonación",
  "VoicevoxPitch": "Tono",
  "VoicevoxServerUrl": "URL del servidor VOICEVOX",
  "VoicevoxSpeed": "Velocidad de habla",
  "WhisperSpeechRecognition": "Usar reconocimiento de voz OpenAI TTS",
  "WhisperTranscriptionModel": "Modelo de transcripción",
  "WhisperTranscriptionModelInfo": "Puede seleccionar el modelo a utilizar para el reconocimiento de voz. Los modelos más avanzados ofrecen mayor precisión de reconocimiento, pero pueden tener un mayor costo de API.",
  "YoutubeAPIKey": "Clave API de YouTube",
  "YoutubeInfo": "Los comentarios que comienzan con '#' serán ignorados.",
  "YoutubeLiveID": "ID de YouTube Live",
  "YoutubeMode": "Modo YouTube",
  "YoutubeSettings": "Configuración de YouTube"
}
