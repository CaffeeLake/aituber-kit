{
  "AISettings": "AI Settings",
  "APIKeyInstruction": "API keys can be obtained from the links below. Enter the obtained API key in the form.",
  "APIKeyNotEntered": "API key has not been entered.",
  "AboutThisApplication": "About This Application",
  "AboutThisApplicationDescription": "You can enjoy conversations with 3D characters in a web browser using microphone, text input, and voice synthesis. You can change the character (VRM), personality settings, and voice adjustments.<br />Settings can be changed from the menu button in the top left.",
  "AboutThisApplicationDescription2": "With AITuberKit, you can enjoy conversations with AI characters in a web browser. Please check each setting item for changing characters, personality settings, and voice adjustments.",
  "AivisSpeechInfo": "Using AivisSpeech. Supports Japanese only. Since it uses a local API, you need to download and run the appropriate app for your environment from the site below.",
  "AivisSpeechIntonation": "Intonation",
  "AivisSpeechPitch": "Pitch",
  "AivisSpeechServerUrl": "AivisSpeech Server URL",
  "AivisSpeechSpeaker": "Speaker",
  "AivisSpeechSpeed": "Speaking Speed",
  "AnswerGenerating": "Generating answer",
  "AnthropicAPIKeyLabel": "Anthropic API Key",
  "AudioMode": "Audio mode",
  "AuthFileInstruction": "An API key or authentication JSON file is required. Obtain it from below, and if it's a JSON file, place it in the root folder of the repository as 'credentials.json'.",
  "AzureAPIKeyLabel": "Azure OpenAI API Key",
  "AzureAPIURL": "Azure OpenAI API URL",
  "AzureEndpoint": "Azure Endpoint",
  "AzureTTSInfo": "Using Azure OpenAI. Supports multiple languages.",
  "BackgroundImage": "Background Image",
  "BackgroundSettings": "Background Settings",
  "BackgroundSettingsDescription": "You can upload and select background images for the application.",
  "BasedSettings": "Basic Settings",
  "BrowserSpeechRecognition": "Use browser standard voice recognition",
  "CannotUseParameters": "If real-time API mode or audio mode is enabled, Temperature and Max Tokens parameters cannot be specified.",
  "CannotUseVoice": "If real-time API mode or audio mode is enabled,\nvoice synthesis settings are not necessary.",
  "ChangeBackgroundImage": "Change Background Image",
  "CharacterModelInfo": "Some models may take time to load during initial display.",
  "CharacterModelLabel": "Character Model",
  "CharacterName": "Character Name",
  "CharacterSettings": "Character Settings",
  "CharacterSettingsInfo": "This value is set as the system prompt.\nReferring to the initial prompt, you can control the character's expressions and motions by specifying emotion tags. Example: [neutral]Good morning![happy]Thank you for your hard work today!",
  "CharacterSettingsPrompt": "Character Prompt",
  "Characterpreset1": "Preset 1",
  "Characterpreset2": "Preset 2",
  "Characterpreset3": "Preset 3",
  "Characterpreset4": "Preset 4",
  "Characterpreset5": "Preset 5",
  "CharacterpresetInfo": "Selecting a preset will change the character prompt.\nShortcuts are available with Cmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows).",
  "ChatLog": "Conversation Log",
  "ClientID": "Client ID",
  "Close": "Close",
  "CohereAPIKeyLabel": "Cohere API Key",
  "Contact": "Contact",
  "ContactDescription": "For inquiries about this app, please contact the email address or Twitter account below.",
  "ContinuousMic": "Continuous microphone input",
  "ContinuousMicActive": "Continuous microphone input active",
  "ContinuousMicInfo": "The microphone input will automatically restart when the AI finishes speaking. It will automatically submit after the set silence time elapses.\nIf voice recognition does not occur and the set time is exceeded, continuous microphone input will automatically turn OFF, so if you want to keep it ON at all times, set the voice recognition timeout to 0 seconds.",
  "ContinuousMicModeOff": "Continuous microphone input mode is off",
  "ContinuousMicModeOn": "Continuous microphone input mode is on",
  "ConversationContinuityMode": "Conversation Continuity Mode (Beta)",
  "ConversationContinuityModeInfo": "This is a mode where AI tries to continue the conversation when there are no comments. Currently only supports OpenAI, Anthropic Claude, Google Gemini.",
  "ConversationContinuityModeInfo2": "Since LLM is called multiple times for a single response, API usage fees may increase. Please be aware of this.",
  "ConversationContinuityModeInfo3": "Relatively stable operation with gpt-4o, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet.",
  "ConversationHistory": "Conversation History",
  "ConversationHistoryInfo": "The most recent {{count}} conversation sentences are retained as memory.",
  "ConversationHistoryReset": "Reset Conversation History",
  "Creator": "Creator Information",
  "CreatorDescription": "Creator: Nike",
  "CustomAPIBody": "Custom body",
  "CustomAPIBodyInfo": "Enter body information to include in API requests in JSON format. messages will be automatically included.",
  "CustomAPIDescription": "Note: Messages are automatically included in the request body. In streaming mode, the server must return text/event-stream.",
  "CustomAPIEndpoint": "Custom API endpoint",
  "CustomAPIEndpointInfo": "Enter the URL of the API endpoint to send POST requests to.",
  "CustomAPIHeaders": "Custom headers",
  "CustomAPIHeadersInfo": "Enter header information to include in API requests in JSON format.",
  "CustomAPIStream": "Streaming mode",
  "CustomAPIStreamForced": "Currently, streaming mode is always enabled.",
  "CustomVoiceTextPlaceholder": "Enter text you want to hear",
  "DeepSeekAPIKeyLabel": "DeepSeek API Key",
  "DefaultBackground": "Default Background",
  "Description": "About the App",
  "DifyAPIKeyLabel": "Dify API Key",
  "DifyInfo": "For Dify, only chatbot or agent types are supported.",
  "DifyInfo2": "The length of conversation history depends on the Dify chatbot settings.",
  "DifyInfo3": "Example: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "If you are using Dify, this system prompt is not used. Please set it in the Dify chatbot.",
  "Documentation": "Documentation",
  "DocumentationDescription": "For detailed usage and tutorials of AITuberKit, please visit the URL below.",
  "DontShowIntroductionNextTime": "Don't show this dialog next time",
  "DragToReorder": "Drag to change order",
  "EditSlideScripts": "セリフ編集",
  "ElevenLabsApiKey": "ElevenLabs API Key",
  "ElevenLabsInfo": "Using ElevenLabs API. Supports multiple languages. Please get an API key from the URL below.",
  "ElevenLabsVoiceId": "ElevenLabs Voice ID",
  "ElevenLabsVoiceIdInfo": "Please select a Voice ID from the URL below.",
  "EnglishToJapanese": "Read English words in Japanese",
  "EnterPresetQuestion": "Please enter a question",
  "EnterURL": "Enter URL",
  "EnterYourQuestion": "Enter what you want to ask",
  "Errors": {
    "AIAPIError": "An error occurred during AI API execution",
    "AIInvalidProperty": "AI service setting value is incorrect",
    "CustomAPIError": "An error occurred in custom API",
    "EmptyAPIKey": "API key is not set",
    "EmptyLocalLLMURL": "Local LLM URL is not set",
    "InvalidAIService": "Selected AI service is incorrect",
    "InvalidJSON": "JSON format is incorrect",
    "LocalLLMAPIError": "An error occurred in local LLM API",
    "LocalLLMConnectionError": "Cannot connect to local LLM server",
    "LocalLLMError": "An error occurred in local LLM",
    "LocalLLMNotFound": "Local LLM endpoint not found",
    "LocalLLMStreamError": "An error occurred in local LLM stream processing",
    "MethodNotAllowed": "Request is not appropriate",
    "TTSServiceError": "An error occurred in {{serviceName}} TTS service: {{message}}",
    "UnexpectedError": "An unknown error occurred"
  },
  "ExternalLinkageMode": "External Connection Mode (Beta)",
  "FireworksAPIKeyLabel": "Fireworks API Key",
  "GSVITTSBatchSize": "GSVI TTS Batch Size (1 ~ 100 The larger the value, the faster the inference speed, but if it's too large, it may exhaust memory)",
  "GSVITTSInfo": "GSVI TTS Settings",
  "GSVITTSModelID": "GSVI TTS Model ID",
  "GSVITTSServerUrl": "GSVI TTS Server URL",
  "GSVITTSSpeechRate": "Speaking Speed (0.5 ~ 2.0 The larger the value, the faster)",
  "GoogleAPIKeyLabel": "Google Gemini API Key",
  "GoogleTTSInfo": "Using Google Cloud Text-to-Speech. Supports multiple languages.",
  "GroqAPIKeyLabel": "Groq API Key",
  "GroqInfo": "Groq API is accessed directly from the browser.",
  "IncludeSystemMessages": "Include System Messages",
  "IncludeTimestampInUserMessage": "Include timestamp in user messages",
  "IncludeTimestampInUserMessageInfo": "Including a timestamp in user messages allows the AI to generate responses considering the time.\nPlease include the following text in your system prompt:\n\n\"User input may be requested with a [timestamp], which represents the time in UTC timezone at the time of the request, so please generate a response considering that time.\"",
  "InitialSpeechTimeout": "Voice recognition timeout",
  "InitialSpeechTimeoutInfo": "Set the waiting time for the first utterance to be detected after voice recognition starts. If no utterance is detected within this time, voice recognition will automatically stop.\nIf set to 0 seconds, the waiting time is unlimited.",
  "InputAudio": "Audio",
  "InputText": "Text",
  "KoeiromapInfo": "Using Koeiromap API from Koemotion. Supports Japanese only. See below for details.",
  "Language": "Language Settings",
  "LanguageChoice": "Language Selection",
  "LanguageModelURL": "Please select a language model from the URL below.",
  "ListeningContinuously": "Waiting for voice input...",
  "Live2D": {
    "EmotionInfo": "Multiple emotions can be specified with commas. If multiple are specified, one will be randomly selected.\nThe default values correspond to the models prepared by AITuberKit. If you are using your original model, please enter values that match your model.\nAfter the conversation is completed, the 'neutral' expression will be displayed.",
    "Emotions": "Expression settings",
    "FileInfo": "Please place the Live2D model folder you want to use in public/live2d. A model3.json file must exist directly under this folder.\nIf it does not appear in the selection, please reload the screen or check if the folder path is correct.",
    "Info": "You can specify emotions and motions.\nEach emotion is controlled by the prompt. For details, please see 'AI Settings => Character Settings'.",
    "MotionGroups": "Motion group settings",
    "MotionGroupsInfo": "Motion groups are randomly selected from the selected group.\nLike the expression settings, please set according to your own model.\n'Idle' is the motion displayed after the conversation is completed.",
    "SelectMotionGroup": "Select motion group",
    "angryEmotions": "Angry",
    "angryMotionGroup": "Angry",
    "happyEmotions": "Happy",
    "happyMotionGroup": "Happy",
    "idleMotionGroup": "Idle",
    "neutralEmotions": "Neutral",
    "neutralMotionGroup": "Neutral",
    "relaxedEmotions": "Relaxed",
    "relaxedMotionGroup": "Relaxed",
    "sadEmotions": "Sad",
    "sadMotionGroup": "Sad",
    "surprisedEmotions": "Surprised",
    "surprisedMotionGroup": "Surprised"
  },
  "LocalLLM": "Local LLM",
  "LocalLLMInfo": "You need to have a local LLM server running.",
  "LocalLLMInfo2": "Please enter the URL of your local LLM (including port number) and the model name.",
  "LocalStorageReset": "Reset settings",
  "LocalStorageResetButton": "Reset Settings",
  "LocalStorageResetInfo": "If environment variables are set, those values take precedence. The page will be reloaded.",
  "LogSettings": "Conversation History",
  "MaxPastMessages": "Number of Past Messages to Keep",
  "MaxTokens": "Maximum tokens",
  "MaxTokensInfo": "The maximum number of tokens varies depending on the AI model being used. Please check the specifications of each model.",
  "MessageReceiver": "Accept instructions from external sources",
  "MessageReceiverDescription": "You can instruct the AI character's speech from external sources using API.",
  "Milliseconds": "milliseconds",
  "MistralAIAPIKeyLabel": "MistralAI API Key",
  "NijiVoiceActorId": "Speaker ID",
  "NijiVoiceApiKey": "NijiVoice API Key",
  "NijiVoiceEmotionalLevel": "Emotional Level",
  "NijiVoiceInfo": "Using NijiVoice API. Supports Japanese only. Please get an API key from the URL below.",
  "NijiVoiceSoundDuration": "Voice Duration",
  "NijiVoiceSpeed": "Speaking Speed",
  "NoSpeechTimeout": "Silence detection timeout",
  "NoSpeechTimeoutInfo": "Set the time to automatically end input when no sound is detected during voice input.\nIf set to 0 seconds, automatic submission by silence detection is disabled.",
  "NotConnectedToExternalAssistant": "Not connected to external assistant.",
  "OpenAIAPIKeyLabel": "OpenAI API Key",
  "OpenAITTSInfo": "Using OpenAI. Supports multiple languages. If you have selected OpenAI in the AI service, you do not need to set the API key below.",
  "OpenAITTSModel": "Model",
  "OpenAITTSSpeed": "Speaking speed",
  "OpenAITTSVoice": "Voice type",
  "OpenSendMessagePage": "Open message sending page",
  "OpenVRM": "Open VRM",
  "OtherSettings": "Other",
  "PdfConvertButton": "Convert PDF to slides",
  "PdfConvertDescription": "Convert PDF to data for slide mode. Only available when the selected AI service is OpenAI, Anthropic Claude, or Google Gemini.",
  "PdfConvertError": "Conversion failed",
  "PdfConvertFileUpload": "Select PDF file",
  "PdfConvertFolderName": "Save folder name",
  "PdfConvertLabel": "PDF Slide Conversion",
  "PdfConvertLoading": "Converting...",
  "PdfConvertModelSelect": "Select model",
  "PdfConvertSubmitError": "Please check that the PDF file, folder name, and API key are set",
  "PdfConvertSuccess": "Conversion complete",
  "PerplexityAPIKeyLabel": "Perplexity API Key",
  "PleaseSelectSlide": "スライドを選択してください",
  "PresetQuestions": "Preset questions",
  "PresetQuestionsInfo": "You can create and register multiple question patterns in advance. Registered questions will be displayed as buttons on the user UI, and clicking them will set them in the chat input field.",
  "RealtimeAPIMode": "Real-time API mode",
  "RealtimeAPIModeContentType": "Submission type",
  "RealtimeAPIModeVoice": "Voice type",
  "RepositoryURL": "Repository URL:",
  "SearchGrounding": "Use search function",
  "SearchGroundingDescription": "When using multimodal features, the search function is automatically disabled.",
  "Select": "Please select",
  "SelectAIService": "Select AI Service",
  "SelectModel": "Select Model",
  "SelectedSlideDocs": "Slides to use",
  "SendMessage": {
    "aiGenerateDescription": "AI generates a response from the sent message, and the AI character speaks that response. If multiple messages are sent, they will be processed in order.\nThe AI model and voice model selected in the AITuberKit settings will be used.\nYou can choose to use the AITuberKit system prompt or a custom system prompt.\nIf you want to load past conversation history, include the string [conversation_history] anywhere in the system prompt or user message.",
    "aiGenerateTitle": "Generate a response with AI and then make it speak",
    "directSendDescription": "You can make the AI character speak the sent message directly. If multiple messages are sent, they will be processed in order.\nThe voice model selected in the AITuberKit settings will be used.",
    "directSendTitle": "Make AI character speak directly",
    "title": "AITuberKit External Adapter",
    "useCurrentSystemPrompt": "Use AITuberKit's system prompt",
    "userInputDescription": "The sent message will be processed the same as if it were entered from the AITuberKit input form. If multiple messages are sent, they will be processed in order.\nThe AI model and voice model selected in the AITuberKit settings will be used.\nThe system prompt and conversation history from AITuberKit will be used.",
    "userInputTitle": "Send user input"
  },
  "ShowAssistantText": "Show answer field",
  "ShowCharacterName": "Show character name in answer field",
  "ShowCharacterPresetMenu": "Show character preset menu button",
  "ShowControlPanel": "Show control panel",
  "ShowControlPanelInfo": "The settings screen can be displayed with Cmd + . (Mac) / Ctrl + . (Windows).\nIf you are using a smartphone, you can also long press (about 1 second) the top left of the screen.",
  "ShowSilenceProgressBar": "Show silence detection progress bar",
  "SlideMode": "Slide Mode",
  "SlideModeDescription": "This is a mode where AI automatically presents slides. Only valid when the selected AI service is OpenAI, Anthropic Claude, or Google Gemini.",
  "SlideSettings": "Slide Settings",
  "SourceCodeDescription1": "The source code of this app is available on GitHub. You can freely modify and alter it.",
  "SourceCodeDescription2": "For commercial use, please refer to the README in the same repository.",
  "SpeakerSelection": "Voice Type Selection",
  "SpeechInputSettings": "Voice Input Settings",
  "SpeechRecognitionMode": "Voice recognition mode",
  "SpeechRecognitionModeDisabledInfo": "If audio mode is enabled, only browser voice recognition can be used.\nAlso, in real-time API mode, only browser voice recognition can be used, and the voice recognition timeout function is disabled.",
  "SpeechRecognitionModeInfo": "You can select the voice recognition mode.\n'Browser standard' uses the browser's built-in voice recognition. 'OpenAI TTS' uses OpenAI's Text to Speech API.\nGenerally, 'Browser standard' is recommended as it has higher accuracy and faster recognition speed. However, if you are using a browser that does not support WebSpeech API, such as Firefox, please select 'OpenAI TTS'.",
  "StatusOff": "Status: OFF",
  "StatusOn": "Status: ON",
  "StyleBeatVITS2ApiKey": "API Key",
  "StyleBeatVITS2Length": "Speaking Speed",
  "StyleBeatVITS2ModelID": "Model ID",
  "StyleBeatVITS2SdpRatio": "SDP/DP Mix Ratio",
  "StyleBeatVITS2ServerURL": "Server URL",
  "StyleBeatVITS2Style": "Style",
  "StyleBertVITS2Info": "Using Style-Bert-VITS2. Supports Japanese, English, and Chinese only. If using a local API, you need to download and run the appropriate app for your environment from the site below. Set up the API key if necessary.",
  "SyntheticVoiceEngineChoice": "Select Voice Synthesis Engine",
  "TechnologyIntroduction": "Technology Introduction",
  "TechnologyIntroductionDescription1": "This app is created by modifying pixiv's <b>ChatVRM</b>. The original source code is",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "For 3D model display and operation,",
  "TechnologyIntroductionDescription4": ", for conversation generation,",
  "TechnologyIntroductionDescription5": "and various LLMs, for voice synthesis,",
  "TechnologyIntroductionDescription6": "and various TTS services are used. For details, please see this",
  "TechnologyIntroductionDescription7": ".",
  "TechnologyIntroductionLink1": "here",
  "TechnologyIntroductionLink2": "explanatory article",
  "Temperature": "Temperature",
  "TestSelectedVoice": "Play",
  "TestVoice": "Test Voice",
  "TestVoiceSettings": "Voice Test",
  "Toasts": {
    "FirefoxNotSupported": "Firefoxではこの機能はサポートされていません",
    "FunctionExecuting": "{{funcName}}を実行しています",
    "FunctionExecutionFailed": "{{funcName}}の実行に失敗しました",
    "NoSpeechDetected": "音声が検出されませんでした。",
    "PresetSwitching": "{{presetName}}に切り替わりました。",
    "SpeechRecognitionError": "音声認識エラーが発生しました",
    "UsingTool": "{{toolName}}を使用中",
    "WebSocketConnectionAttempt": "WebSocket接続を試みています...",
    "WebSocketConnectionClosed": "WebSocket接続が閉じられました",
    "WebSocketConnectionError": "WebSocket接続にエラーが発生しました",
    "WebSocketConnectionSuccess": "WebSocket接続に成功しました",
    "WhisperError": "Whisperによる音声認識でエラーが発生しました"
  },
  "UpdateRealtimeAPISettings": "Update real-time API settings",
  "UpdateRealtimeAPISettingsInfo": "When you update the API key, Azure Endpoint, voice type, model, or system prompt, press the update button to start a new WebSocket session.",
  "UpdateSpeakerList": "Update Speaker List",
  "UploadBackground": "Upload Background Image",
  "UseVideoAsBackground": "Use shared screen or webcam as background",
  "UsingAivisSpeech": "Use AivisSpeech",
  "UsingAzureTTS": "Use Azure OpenAI",
  "UsingElevenLabs": "Use ElevenLabs",
  "UsingGSVITTS": "Use GSVI TTS",
  "UsingGoogleTTS": "Use Google Text-to-Speech",
  "UsingKoeiromap": "Use Koeiromap",
  "UsingNijiVoice": "Use NijiVoice",
  "UsingOpenAITTS": "Use OpenAI",
  "UsingStyleBertVITS2": "Use Style-Bert-VITS2",
  "UsingVoiceVox": "Use VOICEVOX",
  "VoiceAdjustment": "Voice Adjustment",
  "VoiceEngineInstruction": "Please select the voice synthesis engine to use.",
  "VoiceSettings": "Voice Synthesis Settings",
  "VoiceVoxInfo": "Using VOICEVOX. Supports Japanese only. Since it uses a local API, you need to download and run the appropriate app for your environment from the site below.",
  "VoicevoxIntonation": "Intonation",
  "VoicevoxPitch": "Pitch",
  "VoicevoxServerUrl": "VOICEVOX Server URL",
  "VoicevoxSpeed": "Speaking Speed",
  "WhisperSpeechRecognition": "Use OpenAI TTS voice recognition",
  "WhisperTranscriptionModel": "Transcription model",
  "WhisperTranscriptionModelInfo": "You can select the model to use for voice recognition. More advanced models can recognize with higher accuracy, but may incur higher API costs.",
  "YoutubeAPIKey": "YouTube API Key",
  "YoutubeInfo": "Comments starting with '#' are ignored.",
  "YoutubeLiveID": "YouTube Live ID",
  "YoutubeMode": "YouTube Mode",
  "YoutubeSettings": "YouTube Settings"
}
