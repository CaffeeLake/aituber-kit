{
  "AISettings": "Ustawienia AI",
  "APIKeyInstruction": "Klucz API można uzyskać za pomocą poniższego linku. Wprowadź uzyskany klucz API do formularza.",
  "APIKeyNotEntered": "Klucz API nie został wprowadzony.",
  "AboutThisApplication": "O tej aplikacji",
  "AboutThisApplicationDescription": "Dzięki tej aplikacji możesz rozmawiać z 3D postacią wyłącznie za pomocą przeglądarki internetowej, korzystając z mikrofonu, wprowadzania tekstu i syntezy mowy. Możesz również zmienić postać (VRM), ustawić jej osobowość oraz dostosować głos. <br /> Ustawienia można zmienić poprzez przycisk menu w lewym górnym rogu.",
  "AboutThisApplicationDescription2": "AITuberKit umożliwia rozmowę z postacią AI wyłącznie za pomocą przeglądarki. Aby zmienić postać, ustawić jej osobowość lub dostosować głos, sprawdź odpowiednie ustawienia.",
  "AivisSpeechInfo": "Używa AivisSpeech. Obsługuje tylko język japoński. Ponieważ korzysta z lokalnego API, musisz pobrać aplikację odpowiednią dla Twojego środowiska ze strony poniżej i ją uruchomić.",
  "AivisSpeechIntonation": "Intonacja",
  "AivisSpeechPitch": "Wysokość dźwięku",
  "AivisSpeechServerUrl": "URL serwera AivisSpeech",
  "AivisSpeechSpeaker": "Lektor",
  "AivisSpeechSpeed": "Szybkość mówienia",
  "AnswerGenerating": "Generowanie odpowiedzi",
  "AnthropicAPIKeyLabel": "Klucz API Anthropic",
  "AudioMode": "Tryb audio",
  "AuthFileInstruction": "Wymagany jest klucz API lub plik JSON do autoryzacji. Pobierz go z poniższego linku i, w przypadku pliku JSON, umieść go w katalogu głównym repozytorium jako credentials.json.",
  "AzureAPIKeyLabel": "Klucz API Azure OpenAI",
  "AzureAPIURL": "URL Azure OpenAI API",
  "AzureEndpoint": "Azure Endpoint",
  "AzureTTSInfo": "Używa Azure OpenAI. Obsługuje wiele języków.",
  "BackgroundImage": "Obraz tła",
  "BackgroundSettings": "Ustawienia tła",
  "BackgroundSettingsDescription": "You can translate the Japanese text to Polish as follows:\n\n\"Możesz przesłać i wybrać obraz tła aplikacji.",
  "BasedSettings": "Ustawienia podstawowe",
  "BrowserSpeechRecognition": "Użyj standardowego rozpoznawania mowy w przeglądarce",
  "CannotUseParameters": "W przypadku włączonego trybu API w czasie rzeczywistym lub trybu audio, parametry Temperature i Max Tokens nie mogą być określone.",
  "CannotUseVoice": "W przypadku włączonego trybu API w czasie rzeczywistym lub trybu audio,\nustawienia syntezatora mowy są zbędne.",
  "ChangeBackgroundImage": "Zmień obraz tła",
  "CharacterModelInfo": "W zależności od modelu, ładowanie przy pierwszym wyświetleniu może zająć trochę czasu.",
  "CharacterModelLabel": "Model postaci",
  "CharacterName": "Nazwa postaci",
  "CharacterSettings": "Ustawienia postaci",
  "CharacterSettingsInfo": "Ta wartość jest ustawiana jako systemowy prompt.\nBazując na początkowym promptcie, możesz określić tagi emocji, aby kontrolować wyraz twarzy i ruchy postaci. Przykład: [neutral] Dzień dobry! [happy] Miłego dnia!",
  "CharacterSettingsPrompt": "Prompt postaci",
  "Characterpreset1": "Preset 1",
  "Characterpreset2": "Preset 2",
  "Characterpreset3": "Preset 3",
  "Characterpreset4": "Preset 4",
  "Characterpreset5": "Preset 5",
  "CharacterpresetInfo": "Wybierając preset, zmieniasz prompt postaci.\nCmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows) umożliwia skróty.",
  "ChatLog": "Log rozmów",
  "ClientID": "ID klienta",
  "Close": "Zamknij",
  "CohereAPIKeyLabel": "Klucz API Cohere",
  "Contact": "Kontakt",
  "ContactDescription": "W przypadku pytań dotyczących tej aplikacji proszę kontaktować się za pomocą poniższego adresu e-mail lub konta na Twitterze.",
  "ContinuousMic": "Ciągłe wejście mikrofonowe",
  "ContinuousMicActive": "Ciągłe wejście mikrofonowe aktywne",
  "ContinuousMicInfo": "Mikrofon automatycznie wznowi wejście, gdy AI zakończy wypowiedź. Po upływie ustawionego czasu ciszy automatycznie wyśle.\nJeśli czas przekroczy ustawiony czas bez rozpoznawania mowy, ciągłe wejście mikrofonowe automatycznie wyłączy się, dlatego jeśli chcesz, aby było zawsze włączone, ustaw limit czasu rozpoznawania mowy na 0 sekund.",
  "ContinuousMicModeOff": "Tryb ciągłego wejścia mikrofonowego jest wyłączony",
  "ContinuousMicModeOn": "Tryb ciągłego wejścia mikrofonowego jest włączony",
  "ConversationContinuityMode": "Tryb kontynuacji rozmowy (beta)",
  "ConversationContinuityModeInfo": "Tryb, w którym AI automatycznie kontynuuje rozmowę, gdy brak komentarzy. Obecnie obsługiwane są tylko: OpenAI, Anthropic Claude, Google Gemini.",
  "ConversationContinuityModeInfo2": "Ponieważ w jednej odpowiedzi wywoływane są wielokrotnie LLM, może to zwiększyć koszty API. Proszę uważać.",
  "ConversationContinuityModeInfo3": "Działa stosunkowo stabilnie z modelami gpt-4o, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet.",
  "ConversationHistory": "Historia rozmów",
  "ConversationHistoryInfo": "Ostatnie {{count}} rozmów będą przechowywane jako pamięć.",
  "ConversationHistoryReset": "Resetuj historię rozmów",
  "Creator": "Informacje o twórcy",
  "CreatorDescription": "Twórca: Nike",
  "CustomAPIBody": "Niestandardowe ciało",
  "CustomAPIBodyInfo": "Proszę wpisać informacje o ciele w formacie JSON, które mają być dołączone do żądania API. messages będą automatycznie dołączone.",
  "CustomAPIDescription": "Uwaga: Wiadomości są automatycznie dołączane do ciała żądania. W trybie strumieniowym serwer musi zwrócić text/event-stream.",
  "CustomAPIEndpoint": "Niestandardowy punkt końcowy API",
  "CustomAPIEndpointInfo": "Proszę wpisać URL punktu końcowego API, do którego wysyłane są żądania POST.",
  "CustomAPIHeaders": "Niestandardowe nagłówki",
  "CustomAPIHeadersInfo": "Proszę wpisać informacje nagłówkowe w formacie JSON, które mają być dołączone do żądania API.",
  "CustomAPIStream": "Tryb strumieniowy",
  "CustomAPIStreamForced": "Obecnie tryb strumieniowy jest zawsze włączony.",
  "DeepSeekAPIKeyLabel": "Klucz API DeepSeek",
  "DefaultBackground": "Domyślne tło",
  "Description": "O aplikacji",
  "DifyAPIKeyLabel": "Klucz API Dify",
  "DifyInfo": "W Dify obsługiwane są tylko chatboty lub typy agentów.",
  "DifyInfo2": "Długość historii rozmów zależy od ustawień chatbota Dify.",
  "DifyInfo3": "Przykład: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "Jeśli korzystasz z Dify, ten systemowy prompt nie będzie używany. Ustaw go w chatbotie Dify.",
  "DocumentationDescription": "Szczegółowe instrukcje i samouczki dotyczące AITuberKit można znaleźć pod poniższym adresem URL.",
  "DontShowIntroductionNextTime": "Nie pokazuj tego dialogu przy następnym uruchomieniu",
  "DragToReorder": "Przeciągnij, aby zmienić kolejność",
  "ElevenLabsApiKey": "Klucz API ElevenLabs",
  "ElevenLabsInfo": "Używa API ElevenLabs. Obsługuje wiele języków. Uzyskaj klucz API z poniższego URL.",
  "ElevenLabsVoiceId": "ID głosu ElevenLabs",
  "ElevenLabsVoiceIdInfo": "Wybierz ID głosu z poniższego URL.",
  "EnglishToJapanese": "Czytaj angielskie słowa po japońsku",
  "EnterPresetQuestion": "Proszę wpisać pytanie",
  "EnterURL": "Wprowadź URL",
  "EnterYourQuestion": "Wpisz swoje pytanie",
  "Errors": {
    "AIAPIError": "Wystąpił błąd podczas wykonywania API AI",
    "AIInvalidProperty": "Nieprawidłowe wartości ustawień usługi AI",
    "CustomAPIError": "Wystąpił błąd w niestandardowym API",
    "EmptyAPIKey": "Nie ustawiono klucza API",
    "EmptyLocalLLMURL": "URL lokalnego LLM nie jest ustawiony",
    "InvalidAIService": "Wybrana usługa AI jest nieprawidłowa",
    "InvalidJSON": "Format JSON jest nieprawidłowy",
    "LocalLLMAPIError": "Wystąpił błąd w API lokalnego LLM",
    "LocalLLMConnectionError": "Nie można połączyć się z serwerem lokalnego LLM",
    "LocalLLMError": "Wystąpił błąd w lokalnym LLM",
    "LocalLLMNotFound": "Nie znaleziono punktu końcowego lokalnego LLM",
    "LocalLLMStreamError": "Wystąpił błąd podczas przetwarzania strumienia lokalnego LLM",
    "MethodNotAllowed": "Żądanie jest nieprawidłowe",
    "TTSServiceError": "W usłudze TTS {{serviceName}} wystąpił błąd: {{message}}",
    "UnexpectedError": "Wystąpił nieznany błąd"
  },
  "ExternalLinkageMode": "Tryb integracji zewnętrznej (wersja beta)",
  "FireworksAPIKeyLabel": "Klucz API Fireworks",
  "GSVITTSBatchSize": "Rozmiar partii GSVI TTS (1 ~ 100; większa wartość przyspiesza inferencję, ale zbyt duża może spowodować wyczerpanie pamięci)",
  "GSVITTSInfo": "Ustawienia GSVI TTS",
  "GSVITTSModelID": "ID modelu GSVI TTS",
  "GSVITTSServerUrl": "URL serwera GSVI TTS",
  "GSVITTSSpeechRate": "Szybkość mówienia (0.5 ~ 2.0; większa wartość oznacza szybsze tempo)",
  "GoogleAPIKeyLabel": "Klucz API Google Gemini",
  "GoogleTTSInfo": "Używa Google Cloud Text-to-Speech. Obsługuje wiele języków.",
  "GroqAPIKeyLabel": "Klucz API Groq",
  "GroqInfo": "Groq API jest dostępne bezpośrednio przez przeglądarkę.",
  "IncludeTimestampInUserMessage": "Dołącz znacznik czasu do wypowiedzi użytkownika",
  "IncludeTimestampInUserMessageInfo": "Dołączenie znacznika czasu do wypowiedzi użytkownika umożliwia AI uwzględnienie czasu przy generowaniu odpowiedzi.\nProszę dołączyć następujący tekst do systemowego prompta:\n\n„W niektórych przypadkach wejście użytkownika będzie zawierać [timestamp]. Oznacza to, że podany czas reprezentuje czas UTC w momencie żądania, więc wygeneruj odpowiedź, uwzględniając ten czas.”",
  "InitialSpeechTimeout": "Limit czasu rozpoznawania mowy",
  "InitialSpeechTimeoutInfo": "Ustawia czas oczekiwania na wykrycie pierwszej wypowiedzi po rozpoczęciu rozpoznawania mowy. Jeśli w tym czasie nie zostanie wykryta wypowiedź, rozpoznawanie mowy automatycznie się zatrzyma.\nUstawienie na 0 sekund spowoduje, że czas oczekiwania będzie nieograniczony.",
  "InputAudio": "Audio",
  "InputText": "Tekst",
  "KoeiromapInfo": "Używa API Koeiromap firmy Koemotion. Obsługuje tylko język japoński. Szczegóły znajdziesz poniżej.",
  "Language": "Ustawienia języka",
  "LanguageChoice": "Wybór języka",
  "LanguageModelURL": "Wybierz model językowy z poniższego URL.",
  "ListeningContinuously": "Oczekiwanie na wejście głosowe...",
  "Live2D": {
    "EmotionInfo": "Emocje można określić jako wiele, oddzielonych przecinkami. Jeśli podasz wiele, będą wybierane losowo.\nWartości początkowe odpowiadają modelom dostarczonym przez AITuberKit. Jeśli używasz własnego modelu, wprowadź odpowiednie wartości.\nPo zakończeniu rozmowy wyświetlany będzie wyraz „normalny”.",
    "Emotions": "Ustawienia wyrazu twarzy",
    "FileInfo": "Umieść folder z modelem Live2D, którego chcesz użyć, w katalogu public/live2d. W katalogu tym musi znajdować się plik model3.json.\nJeśli nie pojawi się w opcjach, odśwież stronę lub upewnij się, że ścieżka do folderu jest poprawna.",
    "Info": "Możesz określić emocje i ruchy.\nKażda emocja jest kontrolowana przez prompt. Szczegóły znajdziesz w „Ustawieniach AI => Ustawienia postaci”.",
    "MotionGroups": "Ustawienia grup ruchów",
    "MotionGroupsInfo": "Grupy ruchów będą wybierane losowo z wybranej grupy.\nPodobnie jak ustawienia wyrazu twarzy, dostosuj je do swojego modelu.\n„Podczas bezczynności” to ruch wyświetlany po zakończeniu rozmowy.",
    "SelectMotionGroup": "Wybierz grupę ruchów",
    "angryEmotions": "Zły",
    "angryMotionGroup": "Zły",
    "happyEmotions": "Szczęśliwy",
    "happyMotionGroup": "Szczęśliwy",
    "idleMotionGroup": "Podczas bezczynności",
    "neutralEmotions": "Normalny",
    "neutralMotionGroup": "Normalny",
    "relaxedEmotions": "Zrelaksowany",
    "relaxedMotionGroup": "Zrelaksowany",
    "sadEmotions": "Smutny",
    "sadMotionGroup": "Smutny",
    "surprisedEmotions": "Zaskoczenie",
    "surprisedMotionGroup": "Zaskoczenie"
  },
  "LocalLLM": "Lokalny LLM",
  "LocalLLMInfo": "Należy uruchomić serwer lokalnego LLM.",
  "LocalLLMInfo2": "Wprowadź URL lokalnego LLM (wraz z numerem portu) oraz nazwę modelu.",
  "LocalStorageReset": "Resetuj ustawienia",
  "LocalStorageResetButton": "Resetuj ustawienia",
  "LocalStorageResetInfo": "Jeśli zmienne środowiskowe są ustawione, mają pierwszeństwo. Strona zostanie przeładowana.",
  "LogSettings": "Historia rozmów",
  "MaxPastMessages": "Liczba przechowywanych poprzednich wiadomości",
  "MaxTokens": "Maksymalna liczba tokenów",
  "MaxTokensInfo": "Maksymalna liczba tokenów różni się w zależności od używanego modelu AI. Sprawdź specyfikacje każdego modelu.",
  "MessageReceiver": "Przyjmowanie poleceń z zewnątrz",
  "MessageReceiverDescription": "Za pomocą API można sterować wypowiedziami postaci AI z zewnątrz.",
  "Milliseconds": "Milisekundy",
  "MistralAIAPIKeyLabel": "Klucz API MistralAI",
  "NijiVoiceActorId": "ID mówcy",
  "NijiVoiceApiKey": "Klucz API NijiVoice",
  "NijiVoiceEmotionalLevel": "Poziom emocji",
  "NijiVoiceInfo": "Używa API NijiVoice. Obsługuje tylko język japoński. Uzyskaj klucz API z poniższego URL.",
  "NijiVoiceSoundDuration": "Długość dźwięku",
  "NijiVoiceSpeed": "Szybkość mówienia",
  "NotConnectedToExternalAssistant": "Nie połączono z zewnętrznym asystentem.",
  "OpenAIAPIKeyLabel": "Klucz API OpenAI",
  "OpenAITTSInfo": "Używa OpenAI. Obsługuje wiele języków. Jeśli wybrano OpenAI jako usługę AI, nie ma potrzeby ustawiania klucza API poniżej.",
  "OpenAITTSModel": "Model",
  "OpenAITTSSpeed": "Szybkość mówienia",
  "OpenAITTSVoice": "Typ głosu",
  "OpenSendMessagePage": "Otwórz stronę wysyłania wiadomości",
  "OpenVRM": "Otwórz VRM",
  "OtherSettings": "Inne",
  "PdfConvertButton": "Konwertuj PDF do slajdów",
  "PdfConvertDescription": "Konwertuje PDF do danych używanych w trybie slajdów. Dostępne tylko, gdy wybrana usługa AI to OpenAI, Anthropic Claude lub Google Gemini.",
  "PdfConvertError": "Konwersja nie powiodła się",
  "PdfConvertFileUpload": "Wybierz plik PDF",
  "PdfConvertFolderName": "Nazwa folderu do zapisu",
  "PdfConvertLabel": "Konwersja PDF do slajdów",
  "PdfConvertLoading": "Konwertowanie...",
  "PdfConvertModelSelect": "Wybierz model",
  "PdfConvertSubmitError": "Sprawdź, czy plik PDF, nazwa folderu i klucz API zostały ustawione.",
  "PdfConvertSuccess": "Konwersja zakończona pomyślnie",
  "PerplexityAPIKeyLabel": "Klucz API Perplexity",
  "PresetQuestions": "Wstępnie ustawione pytania",
  "PresetQuestionsInfo": "Możesz wcześniej stworzyć i zarejestrować wiele wzorców pytań. Zarejestrowane pytania będą wyświetlane w formie przycisków na interfejsie użytkownika, a po kliknięciu zostaną ustawione w polu wejściowym czatu.",
  "RealtimeAPIMode": "Tryb API w czasie rzeczywistym",
  "RealtimeAPIModeContentType": "Typ wysyłki",
  "RealtimeAPIModeVoice": "Typ głosu",
  "RepositoryURL": "URL repozytorium:",
  "SearchGrounding": "Użyj funkcji wyszukiwania",
  "SearchGroundingDescription": "Gdy korzystasz z funkcji multimodalnych, funkcja wyszukiwania zostaje automatycznie wyłączona.",
  "Select": "Proszę wybrać",
  "SelectAIService": "Wybierz usługę AI",
  "SelectModel": "Wybierz model",
  "SelectedSlideDocs": "Wybrane slajdy",
  "SendMessage": {
    "aiGenerateDescription": "AI wygeneruje odpowiedź na podstawie wysłanej wiadomości, a następnie postać AI ją wypowie. W przypadku wielu wiadomości będą przetwarzane kolejno.\nUżywane są modele AI i głosu wybrane w ustawieniach AITuberKit.\nMożesz wybrać, czy używać systemowego prompta AITuberKit, czy niestandardowego prompta.\nJeśli chcesz załadować historię rozmów, dołącz do systemowego prompta lub dowolnej pozycji wiadomości użytkownika ciąg znaków [conversation_history].",
    "aiGenerateTitle": "Pozwól AI wygenerować odpowiedź, a następnie wypowiedzieć ją",
    "directSendDescription": "Wysłane wiadomości zostaną bezpośrednio wypowiedziane przez postać AI. W przypadku wielu wiadomości będą przetwarzane kolejno.\nUżywany jest model głosu wybrany w ustawieniach AITuberKit.",
    "directSendTitle": "Pozwól postaci AI mówić bezpośrednio",
    "title": "Adapter zewnętrzny AITuberKit",
    "useCurrentSystemPrompt": "Użyj systemowego prompta AITuberKit",
    "userInputDescription": "Wysłane wiadomości są przetwarzane tak samo, jak gdyby zostały wprowadzone w formularzu AITuberKit. W przypadku wielu wiadomości będą przetwarzane kolejno.\nUżywane są modele AI i głosu wybrane w ustawieniach AITuberKit.\nSystemowy prompt oraz historia rozmów są ustawiane zgodnie z wartościami AITuberKit.",
    "userInputTitle": "Wyślij dane wejściowe użytkownika"
  },
  "ShowAssistantText": "Pokaż pole odpowiedzi",
  "ShowCharacterName": "Pokaż nazwę postaci w polu odpowiedzi",
  "ShowCharacterPresetMenu": "Wyświetl przycisk menu presetów postaci",
  "ShowControlPanel": "Pokaż panel sterowania",
  "ShowControlPanelInfo": "Ekran ustawień można wyświetlić za pomocą Cmd + . (Mac) / Ctrl + . (Windows).\nW przypadku korzystania z telefonu komórkowego można to również zrobić, przytrzymując lewy górny róg ekranu przez około 1 sekundę.",
  "ShowSilenceProgressBar": "Wyświetl pasek postępu wykrywania ciszy",
  "SlideMode": "Tryb slajdów",
  "SlideModeDescription": "Tryb, w którym AI automatycznie prezentuje slajdy. Aktywny tylko, gdy wybrana usługa AI to OpenAI, Anthropic Claude lub Google Gemini.",
  "SlideSettings": "Ustawienia slajdów",
  "SourceCodeDescription1": "Kod źródłowy tej aplikacji jest udostępniony na GitHubie. Można go dowolnie modyfikować i zmieniać.",
  "SourceCodeDescription2": "W sprawach komercyjnego wykorzystania, proszę zapoznać się z README w tym repozytorium.",
  "SpeakerSelection": "Wybór typu głosu",
  "SpeechInputSettings": "Ustawienia wejścia głosowego",
  "SpeechRecognitionMode": "Tryb rozpoznawania mowy",
  "SpeechRecognitionModeDisabledInfo": "Gdy tryb audio jest włączony, dostępne jest tylko rozpoznawanie mowy w przeglądarce.\nPonadto w trybie API w czasie rzeczywistym dostępne jest tylko rozpoznawanie mowy w przeglądarce, a funkcja limitu czasu rozpoznawania mowy jest wyłączona.",
  "SpeechRecognitionModeInfo": "Możesz wybrać tryb rozpoznawania mowy.\n\"Standard przeglądarki\" używa wbudowanego rozpoznawania mowy w przeglądarce. \"OpenAI TTS\" używa API Text to Speech OpenAI.\nOgólnie rzecz biorąc, \"Standard przeglądarki\" ma wyższą dokładność i szybszą prędkość rozpoznawania, dlatego jest zalecany. Jeśli jednak korzystasz z przeglądarki, która nie obsługuje WebSpeech API, takiej jak Firefox, wybierz \"OpenAI TTS\".",
  "StatusOff": "Stan: WYŁĄCZONY",
  "StatusOn": "Stan: ON",
  "StyleBeatVITS2ApiKey": "Klucz API",
  "StyleBeatVITS2Length": "Prędkość mówienia",
  "StyleBeatVITS2ModelID": "ID modelu",
  "StyleBeatVITS2SdpRatio": "Stosunek SDP/DP",
  "StyleBeatVITS2ServerURL": "URL serwera",
  "StyleBeatVITS2Style": "Styl",
  "StyleBertVITS2Info": "Używa Style-Bert-VITS2. Obsługuje tylko japoński, angielski i chiński. Jeśli korzystasz z lokalnego API, musisz pobrać i uruchomić aplikację odpowiednią dla Twojego środowiska ze strony poniżej. W razie potrzeby ustaw także klucz API.",
  "SyntheticVoiceEngineChoice": "Wybór silnika syntezatora mowy",
  "TechnologyIntroduction": "Wprowadzenie do technologii",
  "TechnologyIntroductionDescription1": "Ta aplikacja została stworzona na podstawie zmodyfikowanej wersji <b>ChatVRM</b> firmy pixiv. Oryginalny kod źródłowy jest dostępny",
  "TechnologyIntroductionDescription2": "proszę zapoznać się z nim.",
  "TechnologyIntroductionDescription3": "Do wyświetlania i obsługi modeli 3D używane są",
  "TechnologyIntroductionDescription4": ", a do generowania treści rozmów używane są",
  "TechnologyIntroductionDescription5": "różne modele LLM, a do syntezy mowy",
  "TechnologyIntroductionDescription6": "wykorzystuje się różne systemy TTS. Szczegóły znajdziesz w",
  "TechnologyIntroductionDescription7": "zapoznaj się z nim.",
  "TechnologyIntroductionLink1": "tutaj",
  "TechnologyIntroductionLink2": "artykule wyjaśniającym",
  "Temperature": "Temperatura",
  "TestVoice": "Przetestuj głos",
  "Toasts": {
    "FirefoxNotSupported": "Ta funkcja nie jest obsługiwana w Firefoxie",
    "FunctionExecuting": "Wykonywanie {{funcName}}.",
    "FunctionExecutionFailed": "Wykonanie {{funcName}} nie powiodło się.",
    "PresetSwitching": "Przełączono na {{presetName}}.",
    "SpeechRecognitionError": "Wystąpił błąd rozpoznawania mowy",
    "WebSocketConnectionAttempt": "Próba połączenia WebSocket...",
    "WebSocketConnectionClosed": "Połączenie WebSocket zostało zamknięte",
    "WebSocketConnectionError": "Wystąpił błąd połączenia WebSocket.",
    "WebSocketConnectionSuccess": "Połączenie WebSocket zakończone sukcesem.",
    "WhisperError": "Wystąpił błąd w rozpoznawaniu mowy przez Whisper"
  },
  "UpdateRealtimeAPISettings": "Aktualizuj ustawienia API w czasie rzeczywistym",
  "UpdateRealtimeAPISettingsInfo": "Po zaktualizowaniu klucza API, Azure Endpoint, typu głosu, modelu lub systemowego prompta, naciśnij przycisk aktualizacji, aby rozpocząć nową sesję WebSocket.",
  "UpdateSpeakerList": "Aktualizuj listę mówców",
  "UploadBackground": "Prześlij obraz tła",
  "UseVideoAsBackground": "Użyj ekranu udostępniania lub kamery internetowej jako tła",
  "UsingAivisSpeech": "Użyj AivisSpeech",
  "UsingAzureTTS": "Użyj Azure OpenAI",
  "UsingElevenLabs": "Użyj ElevenLabs",
  "UsingGSVITTS": "Użyj GSVI TTS",
  "UsingGoogleTTS": "Użyj Google Text-to-Speech",
  "UsingKoeiromap": "Użyj Koeiromap",
  "UsingNijiVoice": "Użyj NijiVoice",
  "UsingOpenAITTS": "Użyj OpenAI",
  "UsingStyleBertVITS2": "Użyj Style-Bert-VITS2",
  "UsingVoiceVox": "Użyj VOICEVOX",
  "VoiceAdjustment": "Dostosowanie głosu",
  "VoiceEngineInstruction": "Wybierz silnik syntezatora mowy, którego chcesz używać.",
  "VoiceSettings": "Ustawienia syntezatora mowy",
  "VoiceVoxInfo": "Używa VOICEVOX. Obsługuje tylko język japoński. Ponieważ korzysta z lokalnego API, musisz pobrać aplikację odpowiednią dla Twojego środowiska ze strony poniżej i ją uruchomić.",
  "VoicevoxIntonation": "Intonacja",
  "VoicevoxPitch": "Wysokość dźwięku",
  "VoicevoxServerUrl": "URL serwera VOICEVOX",
  "VoicevoxSpeed": "Szybkość mówienia",
  "WhisperAPIKeyInfo": "Tryb Whisper wymaga klucza API OpenAI. Proszę skonfigurować klucz API OpenAI w ustawieniach AI.",
  "WhisperSpeechRecognition": "Użyj rozpoznawania mowy OpenAI TTS",
  "WhisperTranscriptionModel": "Model transkrypcji",
  "WhisperTranscriptionModelInfo": "Możesz wybrać model używany do rozpoznawania mowy. Modele o wyższej wydajności są bardziej dokładne, ale mogą wiązać się z wyższymi kosztami API.",
  "YoutubeAPIKey": "Klucz API YouTube",
  "YoutubeInfo": "Komentarze zaczynające się od „#” są ignorowane.",
  "YoutubeLiveID": "ID YouTube Live",
  "YoutubeMode": "Tryb YouTube",
  "YoutubeSettings": "Ustawienia YouTube",
  "characterpresetInfo": "Wybranie ustawienia wstępnego powoduje zmianę podpowiedzi znaków.\nCmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows) dla skrótów.\nWybranie ustawienia wstępnego przy jednoczesnym przytrzymaniu klawisza Shift powoduje zapisanie bieżącego znaku zachęty w ustawieniu wstępnym."
}
