{
  "AISettings": "Configurações de IA",
  "APIKeyInstruction": "Você pode obter a chave API abaixo. Insira a chave API recebida no formulário.",
  "APIKeyNotEntered": "Chave API não inserida.",
  "AboutThisApplication": "Sobre este aplicativo",
  "AboutThisApplicationDescription": "Experimente conversas com personagens 3D diretamente no navegador através de microfone ou texto e síntese de voz. Você pode alterar o personagem (VRM), ajustar a personalidade e a voz.\nAs configurações podem ser alteradas através do botão de menu no canto superior esquerdo.",
  "AboutThisApplicationDescription2": "Se quiser alterar o personagem, por favor veja a aba \"Configurações de personagem\".",
  "AivisSpeechInfo": "Usa AivisSpeech. Suporta apenas japonês. Usa API local, você precisa baixar e executar o aplicativo adequado ao seu sistema.",
  "AivisSpeechIntonation": "Entonação",
  "AivisSpeechPitch": "Tom",
  "AivisSpeechServerUrl": "URL do servidor AivisSpeech",
  "AivisSpeechSpeaker": "Falante",
  "AivisSpeechSpeed": "Velocidade",
  "AnswerGenerating": "Gerando resposta",
  "AnthropicAPIKeyLabel": "Chave API Anthropic",
  "AudioMode": "Modo de áudio",
  "AuthFileInstruction": "Chave API ou arquivo de autenticação necessário. Obtenha da URL abaixo e coloque no diretório raiz se for arquivo JSON.",
  "AzureAPIKeyLabel": "Chave API Azure OpenAI",
  "AzureAPIURL": "URL API Azure OpenAI",
  "AzureEndpoint": "Endpoint Azure",
  "AzureTTSInfo": "Usando Azure OpenAI. Suporta múltiplos idiomas.",
  "BackgroundImage": "Imagem de fundo",
  "BackgroundSettings": "Configuração de fundo",
  "BackgroundSettingsDescription": "Texto em pt: \"Você pode fazer upload e selecionar a imagem de fundo do aplicativo.",
  "BasedSettings": "Configurações básicas",
  "BrowserSpeechRecognition": "Usar reconhecimento de voz padrão do navegador",
  "CannotUseParameters": "Se o modo API em tempo real ou o modo de áudio estiver ativado, os parâmetros Temperature e Max Tokens não podem ser especificados.",
  "CannotUseVoice": "Se o modo de API em tempo real ou o modo de áudio estiver ativado,\n as configurações de voz sintetizada não são necessárias.",
  "ChangeBackgroundImage": "Alterar imagem de fundo",
  "CharacterModelInfo": "O modelo pode levar tempo para carregar na primeira exibição.",
  "CharacterModelLabel": "Modelo de personagem",
  "CharacterName": "Nome do personagem",
  "CharacterSettings": "Configurações de personagem",
  "CharacterSettingsInfo": "Este valor é definido como prompt do sistema.\nConsulte o prompt inicial e especifique tags de emoção para controlar expressões e movimentos do personagem. Exemplo: [neutral]Bom dia![happy]Hoje também será um dia ocupado!",
  "CharacterSettingsPrompt": "Prompt do personagem",
  "Characterpreset1": "Preset 1",
  "Characterpreset2": "Preset 2",
  "Characterpreset3": "Preset 3",
  "Characterpreset4": "Preset 4",
  "Characterpreset5": "Preset 5",
  "CharacterpresetInfo": "Ao selecionar um preset, o prompt do personagem será alterado.\nCmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows) para atalhos.",
  "ChatLog": "Registro de chat",
  "ClientID": "ID do cliente",
  "Close": "FECHAR",
  "CohereAPIKeyLabel": "Chave API Cohere",
  "Contact": "Contato",
  "ContactDescription": "Por favor, entre em contato através do e-mail ou conta do Twitter abaixo sobre este aplicativo.",
  "ContinuousMic": "Entrada de microfone contínua",
  "ContinuousMicActive": "Entrada de microfone contínua ativa",
  "ContinuousMicInfo": "O microfone será reiniciado automaticamente assim que a fala da IA terminar. Ele será enviado automaticamente após o tempo de silêncio configurado.\nSe o tempo configurado for ultrapassado sem reconhecimento de voz, a entrada de microfone contínua será desligada automaticamente, portanto, se você quiser mantê-la sempre ligada, defina o tempo limite de reconhecimento de voz para 0 segundos.",
  "ContinuousMicModeOff": "O modo de entrada de microfone contínua está desativado",
  "ContinuousMicModeOn": "O modo de entrada de microfone contínua está ativado",
  "ConversationContinuityMode": "Modo de continuidade de conversa (Beta)",
  "ConversationContinuityModeInfo": "Quando não há comentários, a IA tenta continuar a conversa. Atualmente suportado apenas por OpenAI, Anthropic Claude, Google Gemini.",
  "ConversationContinuityModeInfo2": "Uma resposta requer várias chamadas LLM, então o uso da API pode aumentar. Por favor, esteja ciente disso.",
  "ConversationContinuityModeInfo3": "gpt-4, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet funcionam relativamente estáveis.",
  "ConversationHistory": "Histórico de conversas",
  "ConversationHistoryInfo": "As últimas {{count}} conversas serão mantidas como memória.",
  "ConversationHistoryReset": "Redefinir histórico de conversas",
  "Creator": "Criador",
  "CreatorDescription": "Criador: Tegan",
  "CustomAPIBody": "Corpo personalizado",
  "CustomAPIBodyInfo": "Insira as informações do corpo a serem incluídas na solicitação da API em formato JSON. messages serão incluídos automaticamente.",
  "CustomAPIDescription": "Nota: As mensagens serão incluídas automaticamente no corpo da solicitação. No modo de streaming, o servidor deve retornar text/event-stream.",
  "CustomAPIEndpoint": "Endpoint da API personalizada",
  "CustomAPIEndpointInfo": "Insira a URL do endpoint da API para enviar solicitações POST.",
  "CustomAPIHeaders": "Cabeçalhos personalizados",
  "CustomAPIHeadersInfo": "Insira as informações do cabeçalho a serem incluídas na solicitação da API em formato JSON.",
  "CustomAPIStream": "Modo de streaming",
  "CustomAPIStreamForced": "Atualmente, o modo de streaming está sempre ativado.",
  "DeepSeekAPIKeyLabel": "Chave API DeepSeek",
  "DefaultBackground": "Fundo padrão",
  "Description": "Sobre o aplicativo",
  "DifyAPIKeyLabel": "Chave API Dify",
  "DifyInfo": "Dify suporta apenas tipos chatbot e agente.",
  "DifyInfo2": "O comprimento do histórico de conversas depende das especificações do Dify.",
  "DifyInfo3": "Exemplo: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "Se usar Dify, o prompt do sistema não será usado. Configure o chatbot Dify.",
  "DocumentationDescription": "Para detalhes sobre como usar o AITuberKit e tutoriais, consulte o URL abaixo.",
  "DontShowIntroductionNextTime": "Não mostrar esta caixa de diálogo na próxima vez",
  "DragToReorder": "Arraste para reordenar",
  "ElevenLabsApiKey": "Chave API ElevenLabs",
  "ElevenLabsInfo": "Usa API ElevenLabs. Suporta múltiplos idiomas. A chave API pode ser obtida da URL abaixo.",
  "ElevenLabsVoiceId": "ID de voz ElevenLabs",
  "ElevenLabsVoiceIdInfo": "ID de voz pode ser selecionado da URL abaixo.",
  "EnterPresetQuestion": "Por favor, insira a pergunta",
  "EnterURL": "URL",
  "EnterYourQuestion": "Digite sua pergunta aqui",
  "Errors": {
    "AIAPIError": "Erro ao executar API de IA",
    "AIInvalidProperty": "Configuração do serviço de IA não está correta",
    "CustomAPIError": "Ocorreu um erro na API personalizada",
    "EmptyAPIKey": "Chave API não configurada",
    "EmptyLocalLLMURL": "A URL do LLM local não está configurada",
    "InvalidAIService": "Serviço de IA selecionado é inválido",
    "InvalidJSON": "O formato JSON está incorreto",
    "LocalLLMAPIError": "Erro API LLM local",
    "LocalLLMConnectionError": "Erro de conexão com servidor LLM local",
    "LocalLLMError": "Erro LLM local",
    "LocalLLMNotFound": "Endpoint LLM local não encontrado",
    "LocalLLMStreamError": "Erro de stream LLM local",
    "MethodNotAllowed": "Requisição não é apropriada",
    "TTSServiceError": "Erro no serviço TTS {{serviceName}}: {{message}}",
    "UnexpectedError": "Ocorreu um erro inesperado"
  },
  "ExternalLinkageMode": "Modo de integração externa (versão beta)",
  "FireworksAPIKeyLabel": "Chave API Fireworks",
  "GSVITTSBatchSize": "Tamanho do lote GSVI TTS (1 ~ 100 Quanto maior o valor, mais rápida a inferência, mas muito grande pode esgotar a memória)",
  "GSVITTSInfo": "Configurações GSVI TTS",
  "GSVITTSModelID": "ID do modelo GSVI TTS",
  "GSVITTSServerUrl": "Endpoint API GSVI TTS",
  "GSVITTSSpeechRate": "Velocidade de fala (0.5 ~ 2.0 Quanto maior o valor, mais rápido)",
  "GoogleAPIKeyLabel": "Chave API Google Gemini",
  "GoogleTTSInfo": "Usa Google Cloud Text-to-Speech. Suporta múltiplos idiomas.",
  "GroqAPIKeyLabel": "Chave API Groq",
  "GroqInfo": "A API Groq é acessada diretamente do navegador.",
  "IncludeTimestampInUserMessage": "Incluir timestamp nas mensagens do usuário",
  "IncludeTimestampInUserMessageInfo": "Incluir o timestamp ajuda a IA a gerar respostas considerando o horário da transmissão.\nPor favor, inclua a seguinte string no prompt do sistema:\n\n\"A entrada do usuário pode conter [timestamp]. Este é o horário UTC no momento do envio da mensagem. Por favor, considere o horário ao responder.\"",
  "InitialSpeechTimeout": "Tempo limite de reconhecimento de voz",
  "InitialSpeechTimeoutInfo": "Define o tempo de espera até que a primeira fala seja detectada após o início do reconhecimento de voz. Se nenhuma fala for detectada dentro desse tempo, o reconhecimento de voz será interrompido automaticamente.\nSe definido para 0 segundos, o tempo de espera será ilimitado.",
  "InputAudio": "Áudio",
  "InputText": "Texto",
  "KoeiromapInfo": "Usa a API Koeiromap do Koemotion. Suporta apenas japonês. Veja o link abaixo para detalhes.",
  "Language": "Idioma",
  "LanguageChoice": "Escolha do idioma",
  "LanguageModelURL": "Selecione o modelo de linguagem da URL abaixo.",
  "ListeningContinuously": "Aguardando entrada de voz...",
  "Live2D": {
    "EmotionInfo": "As emoções podem ser especificadas em formato separado por vírgulas. Se várias emoções forem especificadas, elas são selecionadas aleatoriamente.\nO valor inicial é para o modelo fornecido pelo AITuberKit. Se estiver usando um modelo original, insira o valor de acordo com seu modelo.\nApós a conclusão da conversa, a emoção \"Neutro\" é exibida.",
    "Emotions": "Configurações de emoções",
    "FileInfo": "Coloque o modelo Live2D que deseja usar na pasta public/live2d. O arquivo model3.json deve existir na raiz desta pasta.\nSe não aparecer na seleção, por favor recarregue a tela ou verifique se o caminho da pasta está correto.",
    "Info": "Você pode especificar emoções e movimentos.\nCada emoção é controlada pelo prompt. Para mais detalhes, veja \"Configurações de IA => Configurações de personagem\".",
    "MotionGroups": "Configurações de grupos de movimento",
    "MotionGroupsInfo": "Os grupos de movimento são selecionados aleatoriamente do grupo selecionado.\nComo nas configurações de emoções, configure de acordo com seu modelo.\n\"Idle\" é o movimento exibido após a conclusão da conversa.",
    "SelectMotionGroup": "Selecionar grupo de movimento",
    "angryEmotions": "Bravo",
    "angryMotionGroup": "Bravo",
    "happyEmotions": "Feliz",
    "happyMotionGroup": "Feliz",
    "idleMotionGroup": "Inativo",
    "neutralEmotions": "Neutro",
    "neutralMotionGroup": "Neutro",
    "relaxedEmotions": "Relaxado",
    "relaxedMotionGroup": "Relaxado",
    "sadEmotions": "Triste",
    "sadMotionGroup": "Triste",
    "surprisedEmotions": "Surpresa",
    "surprisedMotionGroup": "Surpresa"
  },
  "LocalLLM": "LLM local",
  "LocalLLMInfo": "O servidor LLM local deve estar em execução. A configuração é a seguinte.",
  "LocalLLMInfo2": "Insira a URL do servidor LLM local (incluindo número da porta) e o nome do modelo.",
  "LocalStorageReset": "Redefinir configurações",
  "LocalStorageResetButton": "Redefinir configurações",
  "LocalStorageResetInfo": "As variáveis de ambiente têm prioridade quando definidas. A página será recarregada.",
  "LogSettings": "Histórico de conversas",
  "MaxPastMessages": "Número de mensagens anteriores para manter",
  "MaxTokens": "Número máximo de tokens",
  "MaxTokensInfo": "O número máximo de tokens varia de acordo com o modelo de IA em uso. Verifique as especificações de cada modelo.",
  "MessageReceiver": "Receber instruções do exterior",
  "MessageReceiverDescription": "Você pode usar a API para fazer personagens IA falarem do exterior.",
  "Milliseconds": "Milissegundos",
  "MistralAIAPIKeyLabel": "Chave API MistralAI",
  "NijiVoiceActorId": "ID do falante",
  "NijiVoiceApiKey": "Chave API NijiVoice",
  "NijiVoiceEmotionalLevel": "Nível emocional",
  "NijiVoiceInfo": "Usa API NijiVoice. Suporta apenas japonês. A chave API pode ser obtida na URL abaixo.",
  "NijiVoiceSoundDuration": "Duração do som",
  "NijiVoiceSpeed": "Velocidade de fala",
  "NotConnectedToExternalAssistant": "Não conectado ao assistente externo.",
  "OpenAIAPIKeyLabel": "Chave API OpenAI",
  "OpenAITTSInfo": "Usando OpenAI. Suporta múltiplos idiomas. Se você selecionar OpenAI como serviço de IA, não precisa configurar a chave API abaixo.",
  "OpenAITTSModel": "Modelo",
  "OpenAITTSSpeed": "Velocidade",
  "OpenAITTSVoice": "Tipo de voz",
  "OpenSendMessagePage": "Abrir página de mensagem",
  "OpenVRM": "Abrir VRM",
  "OtherSettings": "Outros",
  "PdfConvertButton": "Converter PDF em apresentação",
  "PdfConvertDescription": "Converte PDF em dados de modo apresentação. Disponível apenas quando o serviço de IA selecionado é OpenAI, Anthropic Claude ou Google Gemini.",
  "PdfConvertError": "Falha na conversão",
  "PdfConvertFileUpload": "Selecionar arquivo PDF",
  "PdfConvertFolderName": "Nome da pasta de salvamento",
  "PdfConvertLabel": "Conversão de PDF para apresentação",
  "PdfConvertLoading": "Convertendo...",
  "PdfConvertModelSelect": "Selecionar modelo",
  "PdfConvertSubmitError": "Por favor, certifique-se de que o arquivo PDF, nome da pasta e chave API estão configurados.",
  "PdfConvertSuccess": "Conversão concluída",
  "PerplexityAPIKeyLabel": "Chave API Perplexity",
  "PresetQuestions": "Pré-configuração de perguntas",
  "PresetQuestionsInfo": "Você pode criar e registrar vários padrões de perguntas com antecedência. As perguntas registradas serão exibidas na interface do usuário como botões e, ao clicar, serão definidas na caixa de entrada de chat.",
  "RealtimeAPIMode": "Modo API em tempo real",
  "RealtimeAPIModeContentType": "Tipo de transmissão",
  "RealtimeAPIModeVoice": "Tipo de voz",
  "RepositoryURL": "URL do repositório:",
  "SearchGrounding": "Usar pesquisa contextual",
  "SearchGroundingDescription": "Ao usar a função multimodal, a função de pesquisa é automaticamente desativada.",
  "Select": "Selecionar",
  "SelectAIService": "Selecionar serviço de IA",
  "SelectModel": "Selecionar modelo",
  "SelectedSlideDocs": "Documentos de apresentação selecionados",
  "SendMessage": {
    "aiGenerateDescription": "A IA gera uma resposta da mensagem enviada e depois a pronuncia. Se várias mensagens forem enviadas, elas são processadas em ordem. O modelo de IA e o modelo de voz são os selecionados nas configurações do AITuberKit. O prompt do sistema pode ser selecionado para usar o prompt do sistema do AITuberKit ou um prompt do sistema personalizado. Se você quiser carregar o histórico de conversas anterior, inclua a string [conversation_history] no prompt do sistema ou na mensagem do usuário.",
    "aiGenerateTitle": "Gerar resposta IA e depois falar",
    "directSendDescription": "Você pode enviar a mensagem diretamente para o personagem IA. Se várias mensagens forem enviadas, elas são processadas em ordem. O modelo de voz é o selecionado nas configurações do AITuberKit.",
    "directSendTitle": "Falar diretamente com o personagem IA",
    "title": "Adaptador externo AITuberKit",
    "useCurrentSystemPrompt": "Usar prompt do sistema AITuberKit",
    "userInputDescription": "A mensagem enviada é processada como quando inserida pelo formulário de entrada do AITuberKit. Se várias mensagens forem enviadas, elas são processadas em ordem. O modelo de IA e o modelo de voz são os selecionados nas configurações do AITuberKit. O prompt do sistema e o histórico de conversas são os valores configurados no AITuberKit.",
    "userInputTitle": "Enviar entrada do usuário"
  },
  "ShowAssistantText": "Mostrar caixa de resposta",
  "ShowCharacterName": "Mostrar nome do personagem na caixa de resposta",
  "ShowCharacterPresetMenu": "Mostrar botão do menu de predefinições de personagem",
  "ShowControlPanel": "Mostrar botão de configurações",
  "ShowControlPanelInfo": "A tela de configurações pode ser exibida pressionando Cmd + . (Mac) / Ctrl + . (Windows).\nSe você estiver usando um smartphone, também pode pressionar e segurar o canto superior esquerdo da tela (por cerca de 1 segundo).",
  "ShowSilenceProgressBar": "Mostrar barra de progresso de detecção de silêncio",
  "SlideMode": "Modo apresentação",
  "SlideModeDescription": "Este é um modo onde a IA apresenta slides automaticamente. Disponível apenas quando o serviço de IA selecionado é OpenAI, Anthropic Claude ou Google Gemini.",
  "SlideSettings": "Configurações de slide",
  "SourceCodeDescription1": "O código-fonte deste aplicativo é compartilhado no GitHub. Você pode modificá-lo livremente.",
  "SourceCodeDescription2": "Para uso comercial, por favor veja o README do repositório.",
  "SpeakerSelection": "Seleção de falante",
  "SpeechInputSettings": "Configurações de entrada de voz",
  "SpeechRecognitionMode": "Modo de reconhecimento de voz",
  "SpeechRecognitionModeDisabledInfo": "Se o modo de áudio estiver ativado, apenas o reconhecimento de voz do navegador estará disponível.\nAlém disso, no modo de API em tempo real, apenas o reconhecimento de voz do navegador estará disponível e a função de tempo limite de reconhecimento de voz será desativada.",
  "SpeechRecognitionModeInfo": "Você pode escolher o modo de reconhecimento de voz.\n\"Padrão do navegador\" usa o reconhecimento de voz embutido no navegador. \"OpenAI TTS\" usa a API de Texto para Fala da OpenAI.\nGeralmente, o \"Padrão do navegador\" é mais preciso e rápido, portanto, é recomendado. No entanto, se você estiver usando um navegador que não suporta a API WebSpeech, como o Firefox, escolha \"OpenAI TTS\".",
  "StatusOff": "Status: DESLIGADO",
  "StatusOn": "Status: LIGADO",
  "StyleBeatVITS2ApiKey": "Chave API",
  "StyleBeatVITS2Length": "Velocidade de fala",
  "StyleBeatVITS2ModelID": "ID do modelo",
  "StyleBeatVITS2SdpRatio": "Taxa de mistura SDP/DP",
  "StyleBeatVITS2ServerURL": "URL do servidor",
  "StyleBeatVITS2Style": "Estilo",
  "StyleBertVITS2Info": "Usa Style-Bert-VITS2. Suporta apenas japonês, inglês e chinês. Para API local, você precisa baixar e executar o aplicativo adequado. Configure uma chave API se necessário.",
  "SyntheticVoiceEngineChoice": "Escolher motor de síntese de voz",
  "TechnologyIntroduction": "Introdução à tecnologia",
  "TechnologyIntroductionDescription1": "Este aplicativo é baseado no projeto <b>ChatVRM</b> da pixiv. O código-fonte original está disponível",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "Para exibição e manipulação de modelos 3D,",
  "TechnologyIntroductionDescription4": "é usado. Para geração de conversas, vários LLMs como",
  "TechnologyIntroductionDescription5": "são aplicados. Para síntese de voz, vários motores TTS como",
  "TechnologyIntroductionDescription6": "são usados. Veja mais detalhes neste",
  "TechnologyIntroductionDescription7": ".",
  "TechnologyIntroductionLink1": "aqui",
  "TechnologyIntroductionLink2": "artigo explicativo",
  "Temperature": "Temperatura",
  "TestVoice": "Testar voz",
  "Toasts": {
    "FirefoxNotSupported": "Esta função não é suportada no Firefox",
    "FunctionExecuting": "Executando {{funcName}}",
    "FunctionExecutionFailed": "Falha na execução de {{funcName}}",
    "PresetSwitching": "Mudou para {{presetName}}.",
    "SpeechRecognitionError": "Ocorreu um erro de reconhecimento de fala",
    "WebSocketConnectionAttempt": "Tentativa de conexão WebSocket...",
    "WebSocketConnectionClosed": "Conexão WebSocket fechada",
    "WebSocketConnectionError": "Erro de conexão WebSocket",
    "WebSocketConnectionSuccess": "Conexão WebSocket bem-sucedida",
    "WhisperError": "Ocorreu um erro no reconhecimento de voz com Whisper"
  },
  "UpdateRealtimeAPISettings": "Atualizar configurações API em tempo real",
  "UpdateRealtimeAPISettingsInfo": "Quando atualizar chave API, endpoint Azure, tipo de voz, modelo ou prompt do sistema, pressione o botão de atualização para iniciar uma nova sessão WebSocket.",
  "UpdateSpeakerList": "Atualizar lista de falantes",
  "UploadBackground": "Texto em pt: \"Carregar imagem de fundo",
  "UseVideoAsBackground": "Usar tela compartilhada ou webcam como fundo",
  "UsingAivisSpeech": "AivisSpeech",
  "UsingAzureTTS": "Usando Azure OpenAI",
  "UsingElevenLabs": "ElevenLabs",
  "UsingGSVITTS": "GSVI TTS",
  "UsingGoogleTTS": "Usar Google Text-to-Speech",
  "UsingKoeiromap": "Koeiromap",
  "UsingNijiVoice": "NijiVoice",
  "UsingOpenAITTS": "Usando OpenAI",
  "UsingStyleBertVITS2": "Style-Bert-VITS2",
  "UsingVoiceVox": "VOICEVOX",
  "VoiceAdjustment": "Ajuste de voz",
  "VoiceEngineInstruction": "Selecione o motor de síntese de voz que deseja usar.",
  "VoiceSettings": "Configurações de voz sintetizada",
  "VoiceVoxInfo": "Usa VOICEVOX. Suporta apenas japonês. Usa API local, você precisa baixar e executar o aplicativo adequado ao seu sistema.",
  "VoicevoxIntonation": "Entonação",
  "VoicevoxPitch": "Tom",
  "VoicevoxServerUrl": "URL do servidor VOICEVOX",
  "VoicevoxSpeed": "Velocidade",
  "WhisperAPIKeyInfo": "O modo Whisper requer uma chave de API da OpenAI. Por favor, configure a chave de API da OpenAI nas configurações de IA.",
  "WhisperSpeechRecognition": "Usar reconhecimento de voz OpenAI TTS",
  "WhisperTranscriptionModel": "Modelo de transcrição",
  "WhisperTranscriptionModelInfo": "Você pode escolher o modelo a ser usado para reconhecimento de voz. Modelos de maior desempenho podem ter maior precisão, mas os custos da API podem ser mais altos.",
  "YoutubeAPIKey": "Chave API do YouTube",
  "YoutubeInfo": "O primeiro caractere do comentário é '#' e será ignorado.",
  "YoutubeLiveID": "ID da transmissão ao vivo do YouTube",
  "YoutubeMode": "Modo YouTube",
  "YoutubeSettings": "Configurações do YouTube",
  "characterpresetInfo": "A seleção de uma predefinição altera o prompt de caracteres.\nCmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows) para atalhos.\nSelecionar uma predefinição mantendo premida a tecla Shift guarda o prompt de caracteres atual na predefinição."
}
