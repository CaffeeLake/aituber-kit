{
  "AISettings": "إعدادات الذكاء الاصطناعي",
  "APIKeyInstruction": "يمكنك الحصول على مفتاح API أدناه. أدخل مفتاح API الذي حصلت عليه في النموذج.",
  "APIKeyNotEntered": "لم يتم إدخال مفتاح API.",
  "AboutThisApplication": "حول هذا التطبيق",
  "AboutThisApplicationDescription": "استمتع بالمحادثات مع شخصية ثلاثية الأبعاد مباشرة في متصفحك، باستخدام الميكروفون أو إدخال النص وتوليف الصوت. يمكنك أيضاً تغيير الشخصية (VRM)، وضبط شخصيتها، وتعديل صوتها.<br />يمكن تغيير الإعدادات من زر القائمة في الأعلى اليسار.",
  "AboutThisApplicationDescription2": "إذا كنت تريد تغيير الشخصية، يرجى الرجوع إلى علامة تبويب \"إعدادات الشخصية\".",
  "AivisSpeechInfo": "استخدام AivisSpeech. يدعم اللغة اليابانية فقط. يستخدم API محلي، تحتاج إلى تنزيل وتشغيل التطبيق المناسب لبيئتك من الموقع أدناه.",
  "AivisSpeechIntonation": "نبرة الصوت",
  "AivisSpeechPitch": "درجة الصوت",
  "AivisSpeechServerUrl": "عنوان خادم AivisSpeech",
  "AivisSpeechSpeaker": "المتحدث",
  "AivisSpeechSpeed": "السرعة",
  "AnswerGenerating": "جاري إنشاء الإجابة",
  "AnthropicAPIKeyLabel": "مفتاح API Anthropic",
  "AudioMode": "وضع الصوت",
  "AuthFileInstruction": "مفتاح API أو ملف المصادقة مطلوب. احصل عليه من الرابط أدناه وضعه في المجلد الجذر للمستودع إذا كان ملف JSON.",
  "AzureAPIKeyLabel": "مفتاح API Azure OpenAI",
  "AzureAPIURL": "رابط API Azure OpenAI",
  "AzureEndpoint": "نقطة نهاية Azure",
  "AzureTTSInfo": "استخدام Azure OpenAI. يدعم لغات متعددة.",
  "BackgroundImage": "صورة الخلفية",
  "BackgroundSettings": "إعدادات الخلفية",
  "BackgroundSettingsDescription": "يمكنك تحميل وتحديد صورة الخلفية للتطبيق.",
  "BasedSettings": "الإعدادات الأساسية",
  "BrowserSpeechRecognition": "استخدام التعرف على الصوت المعياري في المتصفح",
  "CannotUseParameters": "إذا كان وضع API في الوقت الحقيقي أو وضع الصوت مفعلًا، فلا يمكن تحديد معلمات Temperature و Max Tokens.",
  "CannotUseVoice": "إذا كان وضع واجهة برمجة التطبيقات في الوقت الحقيقي أو وضع الصوت مفعلًا،\nفإن إعدادات الصوت الاصطناعي ليست ضرورية.",
  "ChangeBackgroundImage": "تغيير صورة الخلفية",
  "CharacterModelInfo": "قد يستغرق تحميل النموذج وقتاً عند عرضه لأول مرة.",
  "CharacterModelLabel": "نموذج الشخصية",
  "CharacterName": "اسم الشخصية",
  "CharacterSettings": "إعدادات الشخصية",
  "CharacterSettingsInfo": "يتم تعيين هذه القيمة كنص تمهيدي للنظام.\nيرجى الرجوع إلى النص التمهيدي الأولي وتحديد علامات المشاعر للتحكم في تعبيرات وحركات الشخصية. مثال: [neutral]صباح الخير![happy]اليوم أيضاً يوم صعب!",
  "CharacterSettingsPrompt": "نص الشخصية",
  "Characterpreset1": "الإعداد المسبق 1",
  "Characterpreset2": "الإعداد المسبق 2",
  "Characterpreset3": "الإعداد المسبق 3",
  "Characterpreset4": "الإعداد المسبق 4",
  "Characterpreset5": "الإعداد المسبق 5",
  "CharacterpresetInfo": "عند اختيار الإعداد المسبق، سيتم تغيير موجه الشخصية.\nيمكن استخدام الاختصارات Cmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows).",
  "ChatLog": "سجل المحادثة",
  "ClientID": "معرف العميل",
  "Close": "إغلاق",
  "CohereAPIKeyLabel": "مفتاح API Cohere",
  "Contact": "اتصل بنا",
  "ContactDescription": "يرجى الاتصال بي عبر عنوان البريد الإلكتروني أو حساب تويتر أدناه بخصوص هذا التطبيق.",
  "ContinuousMic": "إدخال ميكروفون مستمر",
  "ContinuousMicActive": "إدخال ميكروفون مستمر نشط",
  "ContinuousMicInfo": "سيتم استئناف إدخال الميكروفون تلقائيًا عند انتهاء حديث الذكاء الاصطناعي. سيتم الإرسال تلقائيًا بعد مرور الوقت المحدد للصمت.\nإذا تجاوز الوقت المحدد دون التعرف على الصوت، سيتم إيقاف إدخال الميكروفون المستمر تلقائيًا، لذا إذا كنت ترغب في إبقائه مفعلًا دائمًا، يرجى تعيين مهلة التعرف على الصوت إلى 0 ثانية.",
  "ContinuousMicModeOff": "وضع إدخال الميكروفون المستمر معطل",
  "ContinuousMicModeOn": "وضع إدخال الميكروفون المستمر مفعل",
  "ConversationContinuityMode": "وضع استمرارية المحادثة (تجريبي)",
  "ConversationContinuityModeInfo": "عندما لا يكون هناك تعليق، يحاول الذكاء الاصطناعي مواصلة المحادثة. حالياً يدعم فقط OpenAI وAnthropicClaude وGoogle Gemini.",
  "ConversationContinuityModeInfo2": "كل إجابة تستدعي LLM عدة مرات، لذا قد يزيد استخدام API. يرجى الانتباه لذلك.",
  "ConversationContinuityModeInfo3": "gpt-4o وgpt-4-turbo وclaude-3-opus وclaude-3.5-sonnet تعمل بشكل مستقر نسبياً.",
  "ConversationHistory": "سجل المحادثات",
  "ConversationHistoryInfo": "سيتم الاحتفاظ بأحدث {{count}} محادثات كذاكرة.",
  "ConversationHistoryReset": "إعادة تعيين سجل المحادثات",
  "Creator": "المنشئ",
  "CreatorDescription": "المنشئ: Tegan",
  "CustomAPIBody": "جسم مخصص",
  "CustomAPIBodyInfo": "يرجى إدخال معلومات الجسم التي يجب تضمينها في طلب واجهة برمجة التطبيقات بتنسيق JSON. سيتم تضمين الرسائل تلقائيًا.",
  "CustomAPIDescription": "ملاحظة: سيتم تضمين الرسائل تلقائيًا في جسم الطلب. في وضع البث، يجب على الخادم إرجاع text/event-stream.",
  "CustomAPIEndpoint": "نقطة نهاية واجهة برمجة التطبيقات المخصصة",
  "CustomAPIEndpointInfo": "يرجى إدخال عنوان URL لنقطة نهاية واجهة برمجة التطبيقات التي سترسل طلب POST إليها.",
  "CustomAPIHeaders": "رؤوس مخصصة",
  "CustomAPIHeadersInfo": "يرجى إدخال معلومات الرأس التي يجب تضمينها في طلب واجهة برمجة التطبيقات بتنسيق JSON.",
  "CustomAPIStream": "وضع البث",
  "CustomAPIStreamForced": "حاليًا، وضع البث مفعل دائمًا.",
  "DeepSeekAPIKeyLabel": "مفتاح API DeepSeek",
  "DefaultBackground": "النص الياباني: \"デフォルト背景\"\n\nالترجمة إلى العربية: \"الخلفية الافتراضية",
  "Description": "حول التطبيق",
  "DifyAPIKeyLabel": "مفتاح API Dify",
  "DifyInfo": "Dify يدعم فقط نوع chatbot وagent.",
  "DifyInfo2": "طول سجل المحادثة يعتمد على مواصفات Dify.",
  "DifyInfo3": "مثال: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "إذا كنت تستخدم Dify، لن يتم استخدام النص التمهيدي للنظام. يرجى إعداد chatbot Dify.",
  "DocumentationDescription": "يمكنك الاطلاع على كيفية استخدام AITuberKit والدروس التعليمية التفصيلية من خلال الرابط أدناه.",
  "DontShowIntroductionNextTime": "لا تظهر هذا الحوار في المرة القادمة",
  "DragToReorder": "اسحب لتغيير الترتيب",
  "ElevenLabsApiKey": "مفتاح API ElevenLabs",
  "ElevenLabsInfo": "يتم استخدام ElevenLabs API. يدعم لغات متعددة. يمكن الحصول على مفتاح API من الرابط أدناه.",
  "ElevenLabsVoiceId": "معرف صوت ElevenLabs",
  "ElevenLabsVoiceIdInfo": "يمكن اختيار معرف الصوت من الرابط أدناه.",
  "EnterPresetQuestion": "يرجى إدخال السؤال",
  "EnterURL": "URL",
  "EnterYourQuestion": "أدخل سؤالك هنا",
  "Errors": {
    "AIAPIError": "حدث خطأ أثناء تنفيذ API الذكاء الاصطناعي",
    "AIInvalidProperty": "إعدادات خدمة الذكاء الاصطناعي غير صحيحة",
    "CustomAPIError": "حدث خطأ في واجهة برمجة التطبيقات المخصصة",
    "EmptyAPIKey": "لم يتم تعيين مفتاح API",
    "EmptyLocalLLMURL": "لم يتم تعيين عنوان URL لـ LLM المحلي",
    "InvalidAIService": "خدمة الذكاء الاصطناعي المحددة غير صالحة",
    "InvalidJSON": "تنسيق JSON غير صحيح",
    "LocalLLMAPIError": "خطأ في API LLM المحلي",
    "LocalLLMConnectionError": "خطأ في الاتصال بخادم LLM المحلي",
    "LocalLLMError": "خطأ في LLM المحلي",
    "LocalLLMNotFound": "لم يتم العثور على نقطة نهاية LLM المحلي",
    "LocalLLMStreamError": "خطأ في تدفق LLM المحلي",
    "MethodNotAllowed": "الطلب غير مناسب",
    "TTSServiceError": "حدث خطأ في خدمة {{serviceName}} TTS: {{message}}",
    "UnexpectedError": "حدث خطأ غير متوقع"
  },
  "ExternalLinkageMode": "وضع الربط الخارجي (نسخة تجريبية)",
  "FireworksAPIKeyLabel": "مفتاح API Fireworks",
  "GSVITTSBatchSize": "حجم الدفعة GSVI TTS (1 ~ 100 كلما كانت القيمة أكبر، كانت سرعة الاستدلال أسرع، ولكن قد تستنفد الذاكرة إذا كانت كبيرة جداً.)",
  "GSVITTSInfo": "إعدادات GSVI TTS",
  "GSVITTSModelID": "معرف نموذج GSVI TTS",
  "GSVITTSServerUrl": "نقطة نهاية API GSVI TTS",
  "GSVITTSSpeechRate": "معدل الكلام (0.5 ~ 2.0 كلما كانت القيمة أكبر، كان أسرع.)",
  "GoogleAPIKeyLabel": "مفتاح API Google Gemini",
  "GoogleTTSInfo": "استخدام Google Cloud Text-to-Speech. يدعم لغات متعددة.",
  "GroqAPIKeyLabel": "مفتاح API Groq",
  "GroqInfo": "يتم الوصول إلى Groq API مباشرة من المتصفح.",
  "IncludeTimestampInUserMessage": "تضمين الطابع الزمني في رسالة المستخدم",
  "IncludeTimestampInUserMessageInfo": "من خلال تضمين الطوابع الزمنية في رسائل المستخدم، يمكن للذكاء الاصطناعي إنشاء ردود مع مراعاة الوقت.\nيرجى تضمين النص التالي في النص التمهيدي للنظام:\n\n\"قد يتضمن إدخال المستخدم [timestamp]. هذا يمثل وقت UTC في لحظة الطلب، لذا يرجى إنشاء ردود مع مراعاة هذا الطابع الزمني.\"",
  "InitialSpeechTimeout": "مهلة التعرف على الصوت",
  "InitialSpeechTimeoutInfo": "قم بتعيين وقت الانتظار حتى يتم اكتشاف أول حديث بعد بدء التعرف على الصوت. إذا لم يتم اكتشاف حديث خلال هذا الوقت، سيتوقف التعرف على الصوت تلقائيًا.\nإذا تم تعيينه على 0 ثانية، سيكون وقت الانتظار غير محدود.",
  "InputAudio": "الصوت",
  "InputText": "النص",
  "KoeiromapInfo": "استخدام Koeiromap API من Koemotion. يدعم اللغة اليابانية فقط. لمزيد من التفاصيل، يرجى الرجوع إلى الرابط أدناه.",
  "Language": "اللغة",
  "LanguageChoice": "اختيار اللغة",
  "LanguageModelURL": "اختر نموذج اللغة من الرابط أدناه.",
  "ListeningContinuously": "في انتظار إدخال الصوت...",
  "Live2D": {
    "EmotionInfo": "يمكن تحديد المشاعر بتنسيق مفصول بفواصل. إذا تم تحديد مشاعر متعددة، يتم اختيارها عشوائياً.\nالقيمة الأولية هي للنموذج المقدم من AITuberKit. إذا كنت تستخدم نموذجاً أصلياً، يرجى إدخال القيمة وفقاً لنموذجك.\nبعد اكتمال المحادثة، يتم عرض عاطفة \"محايد\".",
    "Emotions": "إعدادات المشاعر",
    "FileInfo": "ضع نموذج Live2D الذي تريد استخدامه في مجلد public/live2d. يجب أن يوجد ملف model3.json في جذر هذا المجلد.\nإذا لم يتم عرضه في الاختيار، يرجى إعادة تحميل الشاشة أو التحقق من صحة مسار المجلد.",
    "Info": "يمكنك تحديد المشاعر والحركات.\nيتم التحكم في كل عاطفة من خلال النص التمهيدي. لمزيد من التفاصيل، يرجى الرجوع إلى \"إعدادات الذكاء الاصطناعي => إعدادات الشخصية\".",
    "MotionGroups": "إعدادات مجموعة الحركة",
    "MotionGroupsInfo": "يتم اختيار مجموعات الحركة عشوائياً من المجموعة المحددة.\nمثل إعدادات المشاعر، يرجى تعيينها وفقاً لنموذجك.\n\"خامل\" هي الحركة المعروضة بعد اكتمال المحادثة.",
    "SelectMotionGroup": "اختيار مجموعة الحركة",
    "angryEmotions": "غاضب",
    "angryMotionGroup": "غاضب",
    "happyEmotions": "سعيد",
    "happyMotionGroup": "سعيد",
    "idleMotionGroup": "خامل",
    "neutralEmotions": "محايد",
    "neutralMotionGroup": "محايد",
    "relaxedEmotions": "مسترخي",
    "relaxedMotionGroup": "مسترخي",
    "sadEmotions": "حزين",
    "sadMotionGroup": "حزين",
    "surprisedEmotions": "دهشة",
    "surprisedMotionGroup": "دهشة"
  },
  "LocalLLM": "LLM محلي",
  "LocalLLMInfo": "يجب أن يكون خادم LLM المحلي قيد التشغيل. الإعداد كما يلي.",
  "LocalLLMInfo2": "الرجاء إدخال عنوان URL لخادم LLM المحلي (متضمناً رقم المنفذ) واسم النموذج.",
  "LocalStorageReset": "إعادة تعيين الإعدادات",
  "LocalStorageResetButton": "إعادة تعيين الإعدادات",
  "LocalStorageResetInfo": "تكون متغيرات البيئة لها الأولوية إذا تم تعيينها. سيتم إعادة تحميل الصفحة.",
  "LogSettings": "سجل المحادثات",
  "MaxPastMessages": "عدد الرسائل السابقة للاحتفاظ بها",
  "MaxTokens": "أقصى عدد من الرموز",
  "MaxTokensInfo": "يختلف أقصى عدد من الرموز حسب نموذج الذكاء الاصطناعي المستخدم. يرجى التحقق من مواصفات كل نموذج.",
  "MessageReceiver": "تلقي التعليمات من الخارج",
  "MessageReceiverDescription": "يمكنك استخدام API لتوجيه شخصيات الذكاء الاصطناعي للتحدث من الخارج.",
  "Milliseconds": "ميلي ثانية",
  "MistralAIAPIKeyLabel": "مفتاح API MistralAI",
  "NijiVoiceActorId": "معرف الممثل",
  "NijiVoiceApiKey": "مفتاح API NijiVoice",
  "NijiVoiceEmotionalLevel": "مستوى العاطفة",
  "NijiVoiceInfo": "يتم استخدام NijiVoice API. يدعم اللغة اليابانية فقط. يمكن الحصول على مفتاح API من الرابط أدناه.",
  "NijiVoiceSoundDuration": "مدة الصوت",
  "NijiVoiceSpeed": "سرعة الكلام",
  "NotConnectedToExternalAssistant": "غير متصل بمساعد خارجي.",
  "OpenAIAPIKeyLabel": "مفتاح API OpenAI",
  "OpenAITTSInfo": "استخدام OpenAI. يدعم لغات متعددة. إذا اخترت OpenAI كخدمة ذكاء اصطناعي، فلا تحتاج إلى تعيين مفتاح API أدناه.",
  "OpenAITTSModel": "النموذج",
  "OpenAITTSSpeed": "السرعة",
  "OpenAITTSVoice": "نوع الصوت",
  "OpenSendMessagePage": "فتح صفحة إرسال الرسائل",
  "OpenVRM": "فتح VRM",
  "OtherSettings": "أخرى",
  "PdfConvertButton": "تحويل PDF إلى عرض تقديمي",
  "PdfConvertDescription": "تحويل PDF إلى بيانات وضع العرض التقديمي. متاح فقط عندما تكون خدمة الذكاء الاصطناعي المحددة هي OpenAI أو Anthropic Claude أو Google Gemini.",
  "PdfConvertError": "فشل التحويل",
  "PdfConvertFileUpload": "اختيار ملف PDF",
  "PdfConvertFolderName": "اسم مجلد الحفظ",
  "PdfConvertLabel": "تحويل PDF إلى عرض تقديمي",
  "PdfConvertLoading": "جاري التحويل...",
  "PdfConvertModelSelect": "اختيار النموذج",
  "PdfConvertSubmitError": "يرجى التأكد من تعيين ملف PDF واسم المجلد ومفتاح API.",
  "PdfConvertSuccess": "اكتمل التحويل",
  "PerplexityAPIKeyLabel": "مفتاح API Perplexity",
  "PresetQuestions": "إعدادات مسبقة للأسئلة",
  "PresetQuestionsInfo": "يمكنك إنشاء وتسجيل أنماط متعددة من الأسئلة مسبقًا. ستظهر الأسئلة المسجلة على واجهة المستخدم الخاصة بالمستخدم في شكل أزرار، وعند النقر عليها، سيتم تعيينها في حقل إدخال الدردشة.",
  "RealtimeAPIMode": "وضع API في الوقت الفعلي",
  "RealtimeAPIModeContentType": "نوع الإرسال",
  "RealtimeAPIModeVoice": "نوع الصوت",
  "RepositoryURL": "رابط المستودع:",
  "SearchGrounding": "استخدام البحث الأرضي",
  "SearchGroundingDescription": "عند استخدام ميزة متعددة الوسائط، يتم تعطيل وظيفة البحث تلقائياً.",
  "Select": "اختيار",
  "SelectAIService": "اختيار خدمة الذكاء الاصطناعي",
  "SelectModel": "اختيار النموذج",
  "SelectedSlideDocs": "مستندات العرض المحددة",
  "SendMessage": {
    "aiGenerateDescription": "يولد الذكاء الاصطناعي رداً من الرسالة المرسلة ثم يتحدث به. إذا تم إرسال رسائل متعددة، تتم معالجتها بالترتيب. نموذج الذكاء الاصطناعي ونموذج الصوت هما المحددان في إعدادات AITuberKit. يمكن اختيار النص التمهيدي للنظام لاستخدام النص التمهيدي لنظام AITuberKit أو نص تمهيدي مخصص. إذا كنت تريد تحميل سجل المحادثة السابق، قم بتضمين السلسلة [conversation_history] في النص التمهيدي للنظام أو رسالة المستخدم.",
    "aiGenerateTitle": "توليد رد الذكاء الاصطناعي ثم التحدث",
    "directSendDescription": "يمكنك إرسال الرسالة مباشرة إلى شخصية الذكاء الاصطناعي. إذا تم إرسال رسائل متعددة، تتم معالجتها بالترتيب. نموذج الصوت هو المحدد في إعدادات AITuberKit.",
    "directSendTitle": "التحدث مباشرة إلى شخصية الذكاء الاصطناعي",
    "title": "محول AITuberKit الخارجي",
    "useCurrentSystemPrompt": "استخدام النص التمهيدي لنظام AITuberKit",
    "userInputDescription": "تتم معالجة الرسالة المرسلة بنفس طريقة الإدخال من نموذج إدخال AITuberKit. إذا تم إرسال رسائل متعددة، تتم معالجتها بالترتيب. نموذج الذكاء الاصطناعي ونموذج الصوت هما المحددان في إعدادات AITuberKit. النص التمهيدي للنظام وسجل المحادثة هما القيم المعينة في AITuberKit.",
    "userInputTitle": "إرسال إدخال المستخدم"
  },
  "ShowAssistantText": "إظهار مربع الإجابة",
  "ShowCharacterName": "إظهار اسم الشخصية في مربع الإجابة",
  "ShowCharacterPresetMenu": "عرض زر قائمة إعدادات الشخصية",
  "ShowControlPanel": "إظهار زر الإعدادات",
  "ShowControlPanelInfo": "يمكن عرض شاشة الإعدادات باستخدام Cmd + . (ماك) / Ctrl + . (ويندوز).\nإذا كنت تستخدم هاتفًا ذكيًا، يمكنك الضغط لفترة طويلة على الزاوية العلوية اليسرى من الشاشة (حوالي 1 ثانية).",
  "ShowSilenceProgressBar": "عرض شريط تقدم اكتشاف الصمت",
  "SlideMode": "وضع العرض التقديمي",
  "SlideModeDescription": "هذا وضع حيث يقدم الذكاء الاصطناعي العروض التقديمية تلقائياً. متاح فقط عندما تكون خدمة الذكاء الاصطناعي المحددة هي OpenAI أو Anthropic Claude أو Google Gemini.",
  "SlideSettings": "إعدادات الشريحة",
  "SourceCodeDescription1": "الكود المصدري لهذا التطبيق متاح للعموم على GitHub. لا تتردد في تعديله وتكييفه كما تريد.",
  "SourceCodeDescription2": "للاستخدام التجاري، يرجى الرجوع إلى ملف README في نفس المستودع.",
  "SpeakerSelection": "اختيار المتحدث",
  "SpeechInputSettings": "إعدادات إدخال الصوت",
  "SpeechRecognitionMode": "وضع التعرف على الصوت",
  "SpeechRecognitionModeDisabledInfo": "إذا كان وضع الصوت مفعلًا، فإن التعرف على الصوت في المتصفح هو الخيار الوحيد المتاح.\nأيضًا، في وضع واجهة برمجة التطبيقات في الوقت الحقيقي، يكون التعرف على الصوت في المتصفح هو الخيار الوحيد المتاح، وستكون ميزة مهلة التعرف على الصوت غير مفعلة.",
  "SpeechRecognitionModeInfo": "يمكنك اختيار وضع التعرف على الصوت.\n\"المعيار في المتصفح\" يستخدم التعرف على الصوت المدمج في المتصفح. \"OpenAI TTS\" يستخدم واجهة برمجة التطبيقات لتحويل النص إلى كلام من OpenAI.\nبشكل عام، يُفضل استخدام \"المعيار في المتصفح\" لأنه أكثر دقة وسرعة في التعرف. ومع ذلك، إذا كنت تستخدم متصفحًا لا يدعم واجهة برمجة تطبيقات WebSpeech مثل Firefox، يرجى اختيار \"OpenAI TTS\".",
  "StatusOff": "الحالة: إيقاف",
  "StatusOn": "الحالة: تشغيل",
  "StyleBeatVITS2ApiKey": "مفتاح API",
  "StyleBeatVITS2Length": "معدل الكلام",
  "StyleBeatVITS2ModelID": "معرف النموذج",
  "StyleBeatVITS2SdpRatio": "نسبة خلط SDP/DP",
  "StyleBeatVITS2ServerURL": "عنوان الخادم",
  "StyleBeatVITS2Style": "النمط",
  "StyleBertVITS2Info": "استخدام Style-Bert-VITS2. يدعم اللغة اليابانية والإنجليزية والصينية فقط. إذا كنت تستخدم API محلي، تحتاج إلى تنزيل وتشغيل التطبيق المناسب لبيئتك من الموقع أدناه. يرجى أيضاً إعداد مفتاح API إذا لزم الأمر.",
  "SyntheticVoiceEngineChoice": "اختيار محرك الصوت الاصطناعي",
  "TechnologyIntroduction": "مقدمة التقنية",
  "TechnologyIntroductionDescription1": "تم إنشاء هذا التطبيق عن طريق تعديل <b>ChatVRM</b> من pixiv. يمكن العثور على الكود المصدري الأصلي",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "لعرض ومعالجة النماذج ثلاثية الأبعاد،",
  "TechnologyIntroductionDescription4": "يتم استخدام. لتوليد نص المحادثة، يتم استخدام نماذج LLM مختلفة مثل",
  "TechnologyIntroductionDescription5": "يتم استخدام. لتوليف الكلام، يتم استخدام محركات TTS مختلفة مثل",
  "TechnologyIntroductionDescription6": "يتم استخدام. لمزيد من التفاصيل، يرجى الاطلاع على هذا",
  "TechnologyIntroductionDescription7": ".",
  "TechnologyIntroductionLink1": "هنا",
  "TechnologyIntroductionLink2": "المقال التوضيحي",
  "Temperature": "درجة الحرارة",
  "TestVoice": "اختبار الصوت",
  "Toasts": {
    "FirefoxNotSupported": "هذه الميزة غير مدعومة على Firefox",
    "FunctionExecuting": "جاري تنفيذ {{funcName}}",
    "FunctionExecutionFailed": "فشل تنفيذ {{funcName}}",
    "PresetSwitching": "تم التبديل إلى {{presetName}}.",
    "SpeechRecognitionError": "حدث خطأ في التعرف على الكلام",
    "WebSocketConnectionAttempt": "محاولة اتصال WebSocket...",
    "WebSocketConnectionClosed": "تم إغلاق اتصال WebSocket",
    "WebSocketConnectionError": "حدث خطأ في اتصال WebSocket",
    "WebSocketConnectionSuccess": "نجح اتصال WebSocket",
    "WhisperError": "حدث خطأ في التعرف على الصوت بواسطة Whisper"
  },
  "UpdateRealtimeAPISettings": "تحديث إعدادات API في الوقت الفعلي",
  "UpdateRealtimeAPISettingsInfo": "عند تحديث مفتاح API، نقطة نهاية Azure، نوع الصوت، النموذج، أو النص التمهيدي للنظام، يرجى الضغط على زر التحديث لبدء جلسة WebSocket جديدة.",
  "UpdateSpeakerList": "تحديث قائمة المتحدثين",
  "UploadBackground": "تحميل صورة الخلفية",
  "UseVideoAsBackground": "استخدام الشاشة المشتركة أو كاميرا الويب كخلفية",
  "UsingAivisSpeech": "AivisSpeech",
  "UsingAzureTTS": "استخدام Azure OpenAI",
  "UsingElevenLabs": "ElevenLabs",
  "UsingGSVITTS": "GSVI TTS",
  "UsingGoogleTTS": "استخدام Google Text-to-Speech",
  "UsingKoeiromap": "Koeiromap",
  "UsingNijiVoice": "NijiVoice",
  "UsingOpenAITTS": "استخدام OpenAI",
  "UsingStyleBertVITS2": "Style-Bert-VITS2",
  "UsingVoiceVox": "VOICEVOX",
  "VoiceAdjustment": "ضبط الصوت",
  "VoiceEngineInstruction": "اختر محرك الصوت الاصطناعي الذي تريد استخدامه.",
  "VoiceSettings": "إعدادات الصوت الاصطناعي",
  "VoiceVoxInfo": "استخدام VOICEVOX. يدعم اللغة اليابانية فقط. يستخدم API محلي، تحتاج إلى تنزيل وتشغيل التطبيق المناسب لبيئتك من الموقع أدناه.",
  "VoicevoxIntonation": "نبرة الصوت",
  "VoicevoxPitch": "درجة الصوت",
  "VoicevoxServerUrl": "عنوان خادم VOICEVOX",
  "VoicevoxSpeed": "السرعة",
  "WhisperAPIKeyInfo": "وضع Whisper يتطلب مفتاح API من OpenAI. يرجى إعداد مفتاح API الخاص بـ OpenAI في إعدادات الذكاء الاصطناعي.",
  "WhisperSpeechRecognition": "استخدام التعرف على الصوت من OpenAI TTS",
  "WhisperTranscriptionModel": "نموذج النسخ",
  "WhisperTranscriptionModelInfo": "يمكنك اختيار النموذج المستخدم في التعرف على الصوت. كلما كان النموذج أكثر كفاءة، كانت دقته أعلى، ولكن قد تكون تكاليف واجهة برمجة التطبيقات أعلى.",
  "YoutubeAPIKey": "مفتاح API يوتيوب",
  "YoutubeInfo": "إذا كان الحرف الأول من التعليق هو '#'، يتم تجاهله.",
  "YoutubeLiveID": "معرف البث المباشر على يوتيوب",
  "YoutubeMode": "وضع يوتيوب",
  "YoutubeSettings": "إعدادات يوتيوب",
  "characterpresetInfo": " يؤدي تحديد إعداد مسبق إلى تغيير موجه الأحرف.\nCmd + Shift + 1~5 (ماك) / Ctrl + Shift + 1~5 (ويندوز) للاختصارات.\n يؤدي تحديد إعداد مسبق أثناء الضغط باستمرار على مفتاح Shift إلى حفظ مطالبة الحرف الحالي في الإعداد المسبق."
}
