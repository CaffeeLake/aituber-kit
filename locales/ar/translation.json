{
  "AISettings": "إعدادات الذكاء الاصطناعي",
  "APIKeyInstruction": "يمكنك الحصول على مفتاح واجهة البرمجة من الرابط أدناه. يرجى إدخال مفتاح واجهة البرمجة الذي حصلت عليه في النموذج.",
  "APIKeyNotEntered": "لم يتم إدخال مفتاح واجهة البرمجة.",
  "AboutThisApplication": "حول هذا التطبيق",
  "AboutThisApplicationDescription": "يمكنك الاستمتاع بالمحادثة مع شخصية ثلاثية الأبعاد باستخدام الميكروفون أو إدخال النص أو توليف الصوت في متصفح الويب فقط. يمكنك أيضًا تغيير الشخصية (VRM) وإعدادات الشخصية وضبط الصوت.<br />يمكنك تغيير الإعدادات من زر القائمة في الزاوية العلوية اليسرى.",
  "AboutThisApplicationDescription2": "مع AITuberKit، يمكنك الاستمتاع بالمحادثة مع شخصية الذكاء الاصطناعي في متصفح الويب فقط. يرجى الرجوع إلى كل عنصر إعداد لتغيير الشخصية وإعدادات الشخصية وضبط الصوت.",
  "AivisSpeechInfo": "نحن نستخدم AivisSpeech. تدعم اللغة اليابانية فقط. نظرًا لأننا نستخدم واجهة برمجة محلية، تحتاج إلى تنزيل وتشغيل التطبيق المناسب لبيئتك من الموقع أدناه.",
  "AivisSpeechIntonation": "نبرة الصوت",
  "AivisSpeechPitch": "طبقة الصوت",
  "AivisSpeechServerUrl": "عنوان URL لخادم AivisSpeech",
  "AivisSpeechSpeaker": "المتحدث",
  "AivisSpeechSpeed": "سرعة الكلام",
  "AnswerGenerating": "جاري إنشاء الإجابة",
  "AnthropicAPIKeyLabel": "مفتاح واجهة برمجة Anthropic",
  "AudioMode": "وضع الصوت",
  "AuthFileInstruction": "تحتاج إلى مفتاح واجهة برمجة أو ملف JSON للمصادقة. الحصول عليه من أدناه، وإذا كان ملف JSON، فضعه في المجلد الجذر للمستودع باسم credentials.json.",
  "AzureAPIKeyLabel": "مفتاح واجهة برمجة Azure OpenAI",
  "AzureAPIURL": "رابط واجهة برمجة Azure OpenAI",
  "AzureEndpoint": "نقطة نهاية Azure",
  "AzureTTSInfo": "نحن نستخدم Azure OpenAI. يدعم لغات متعددة.",
  "BackgroundImage": "صورة الخلفية",
  "BackgroundSettings": "إعدادات الخلفية",
  "BackgroundSettingsDescription": "يمكنك تحميل واختيار صورة خلفية للتطبيق.",
  "BasedSettings": "الإعدادات الأساسية",
  "BrowserSpeechRecognition": "استخدام التعرف على الكلام القياسي للمتصفح",
  "CannotUseParameters": "عند تنشيط وضع واجهة البرمجة في الوقت الفعلي أو وضع الصوت، لا يمكن تحديد معلمات درجة الحرارة والحد الأقصى للرموز.",
  "CannotUseVoice": "عند تنشيط وضع واجهة البرمجة في الوقت الفعلي أو وضع الصوت،\nلا حاجة لإعدادات الصوت الاصطناعي.",
  "ChangeBackgroundImage": "تغيير صورة الخلفية",
  "CharacterModelInfo": "قد يستغرق بعض الوقت لتحميل بعض النماذج عند العرض الأولي.",
  "CharacterModelLabel": "نموذج الشخصية",
  "CharacterName": "اسم الشخصية",
  "CharacterSettings": "إعدادات الشخصية",
  "CharacterSettingsInfo": "سيتم تعيين هذه القيمة كموجه نظام.\nيمكنك التحكم في تعبيرات وحركات الشخصية باستخدام علامات المشاعر بالإشارة إلى الموجه الأولي. مثال: [neutral]صباح الخير![happy]أتمنى لك يومًا رائعًا!",
  "CharacterSettingsPrompt": "موجه شخصية",
  "Characterpreset1": "الإعداد المسبق 1",
  "Characterpreset2": "الإعداد المسبق 2",
  "Characterpreset3": "الإعداد المسبق 3",
  "Characterpreset4": "الإعداد المسبق 4",
  "Characterpreset5": "الإعداد المسبق 5",
  "CharacterpresetInfo": "سيؤدي تحديد إعداد مسبق إلى تغيير موجه الشخصية.\nيمكنك استخدام الاختصارات Cmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows).",
  "ChatLog": "سجل الدردشة",
  "ClientID": "معرف العميل",
  "Close": "إغلاق",
  "CohereAPIKeyLabel": "مفتاح واجهة برمجة Cohere",
  "Contact": "اتصل بنا",
  "ContactDescription": "للاستفسارات حول هذا التطبيق، يرجى الاتصال بعنوان البريد الإلكتروني أو حساب تويتر أدناه.",
  "ContinuousMic": "إدخال الميكروفون المستمر",
  "ContinuousMicActive": "إدخال الميكروفون المستمر نشط",
  "ContinuousMicInfo": "سيتم إعادة تشغيل إدخال الميكروفون تلقائيًا بعد انتهاء الذكاء الاصطناعي من التحدث. سيتم إرسال الإدخال تلقائيًا بعد انقضاء وقت الصمت المحدد.\nإذا تجاوز الوقت المحدد دون التعرف على الكلام، سيتم إيقاف إدخال الميكروفون المستمر تلقائيًا. إذا كنت تريد إبقاءه قيد التشغيل دائمًا، فيرجى تعيين مهلة التعرف على الكلام إلى 0 ثانية.",
  "ContinuousMicModeOff": "وضع إدخال الميكروفون المستمر متوقف",
  "ContinuousMicModeOn": "وضع إدخال الميكروفون المستمر قيد التشغيل",
  "ConversationContinuityMode": "وضع استمرارية المحادثة (نسخة تجريبية)",
  "ConversationContinuityModeInfo": "هذا وضع يحاول فيه الذكاء الاصطناعي مواصلة المحادثة عندما لا تكون هناك تعليقات. يدعم حاليًا OpenAI و Anthropic Claude و Google Gemini فقط.",
  "ConversationContinuityModeInfo2": "يرجى ملاحظة أنه نظرًا لاستدعاء نماذج اللغة الكبيرة عدة مرات في إجابة واحدة، قد تزيد رسوم استخدام واجهة البرمجة.",
  "ConversationContinuityModeInfo3": "يعمل بشكل مستقر نسبيًا مع gpt-4o و gpt-4-turbo و claude-3-opus و claude-3.5-sonnet.",
  "ConversationHistory": "سجل المحادثة",
  "ConversationHistoryInfo": "سيتم الاحتفاظ بآخر {{count}} محادثة كذاكرة.",
  "ConversationHistoryReset": "إعادة تعيين سجل المحادثة",
  "Creator": "معلومات المنشئ",
  "CreatorDescription": "المنشئ: نيكي",
  "CustomAPIBody": "هيكل مخصص",
  "CustomAPIBodyInfo": "أدخل معلومات الهيكل التي سيتم تضمينها في طلب واجهة البرمجة بتنسيق JSON. سيتم تضمين الرسائل تلقائيًا.",
  "CustomAPIDescription": "ملاحظة: سيتم تضمين الرسائل تلقائيًا في جسم الطلب. في وضع التدفق، يجب أن يعيد الخادم text/event-stream.",
  "CustomAPIEndpoint": "نقطة نهاية واجهة البرمجة المخصصة",
  "CustomAPIEndpointInfo": "أدخل عنوان URL لنقطة نهاية واجهة البرمجة التي سيتم إرسال طلبات POST إليها.",
  "CustomAPIHeaders": "رؤوس مخصصة",
  "CustomAPIHeadersInfo": "أدخل معلومات الرؤوس التي سيتم تضمينها في طلب واجهة البرمجة بتنسيق JSON.",
  "CustomAPIStream": "وضع التدفق",
  "CustomAPIStreamForced": "حاليًا، وضع التدفق مفعل دائمًا.",
  "CustomVoiceTextPlaceholder": "أدخل النص الذي تريد سماعه",
  "DeepSeekAPIKeyLabel": "مفتاح واجهة برمجة DeepSeek",
  "DefaultBackground": "الخلفية الافتراضية",
  "Description": "حول التطبيق",
  "DifyAPIKeyLabel": "مفتاح واجهة برمجة Dify",
  "DifyInfo": "في Dify، نحن ندعم فقط أنواع روبوتات الدردشة أو الوكلاء.",
  "DifyInfo2": "يعتمد طول سجل المحادثة على إعدادات روبوت دردشة Dify.",
  "DifyInfo3": "مثال: https://api.dify.ai/v1، http://localhost:80/v1",
  "DifyInstruction": "عند استخدام Dify، لا يتم استخدام موجه النظام هذا. يرجى تكوينه في روبوت دردشة Dify.",
  "Documentation": "التوثيق",
  "DocumentationDescription": "يمكنك العثور على دليل مفصل وبرامج تعليمية لـ AITuberKit على URL أدناه.",
  "DontShowIntroductionNextTime": "عدم عرض هذا الحوار في المرة القادمة",
  "DragToReorder": "اسحب لإعادة الترتيب",
  "EditSlideScripts": "セリフ編集",
  "ElevenLabsApiKey": "مفتاح واجهة برمجة ElevenLabs",
  "ElevenLabsInfo": "نحن نستخدم واجهة برمجة ElevenLabs. يدعم لغات متعددة. يرجى الحصول على مفتاح واجهة البرمجة من URL أدناه.",
  "ElevenLabsVoiceId": "معرف صوت ElevenLabs",
  "ElevenLabsVoiceIdInfo": "يرجى اختيار معرف الصوت من URL أدناه.",
  "EnglishToJapanese": "نطق الكلمات الإنجليزية باليابانية",
  "EnterPresetQuestion": "أدخل سؤالاً",
  "EnterURL": "أدخل URL",
  "EnterYourQuestion": "أدخل سؤالك هنا",
  "Errors": {
    "AIAPIError": "حدث خطأ أثناء تنفيذ واجهة برمجة الذكاء الاصطناعي",
    "AIInvalidProperty": "قيمة إعداد خدمة الذكاء الاصطناعي غير صحيحة",
    "CustomAPIError": "حدث خطأ في واجهة البرمجة المخصصة",
    "EmptyAPIKey": "لم يتم تعيين مفتاح واجهة البرمجة",
    "EmptyLocalLLMURL": "لم يتم تعيين URL لنموذج اللغة المحلي",
    "InvalidAIService": "خدمة الذكاء الاصطناعي المحددة غير صحيحة",
    "InvalidJSON": "تنسيق JSON غير صحيح",
    "LocalLLMAPIError": "حدث خطأ في واجهة برمجة نموذج اللغة المحلي",
    "LocalLLMConnectionError": "لا يمكن الاتصال بخادم نموذج اللغة المحلي",
    "LocalLLMError": "حدث خطأ في نموذج اللغة المحلي",
    "LocalLLMNotFound": "لم يتم العثور على نقطة نهاية نموذج اللغة المحلي",
    "LocalLLMStreamError": "حدث خطأ في معالجة تدفق نموذج اللغة المحلي",
    "MethodNotAllowed": "الطلب غير مناسب",
    "TTSServiceError": "حدث خطأ في خدمة {{serviceName}} TTS: {{message}}",
    "UnexpectedError": "حدث خطأ غير متوقع"
  },
  "ExternalLinkageMode": "وضع الربط الخارجي (نسخة تجريبية)",
  "FireworksAPIKeyLabel": "مفتاح واجهة برمجة Fireworks",
  "GSVITTSBatchSize": "حجم الدفعة GSVI TTS (1 ~ 100 كلما كانت القيمة أكبر، كان الاستدلال أسرع، ولكن إذا كانت كبيرة جدًا، فقد تنفد الذاكرة)",
  "GSVITTSInfo": "إعدادات GSVI TTS",
  "GSVITTSModelID": "معرف نموذج GSVI TTS",
  "GSVITTSServerUrl": "عنوان URL لخادم GSVI TTS",
  "GSVITTSSpeechRate": "معدل الكلام (0.5 ~ 2.0 كلما كانت القيمة أكبر، كان أسرع)",
  "GoogleAPIKeyLabel": "مفتاح واجهة برمجة Google Gemini",
  "GoogleTTSInfo": "نحن نستخدم Google Cloud Text-to-Speech. يدعم لغات متعددة.",
  "GroqAPIKeyLabel": "مفتاح واجهة برمجة Groq",
  "GroqInfo": "تستخدم واجهة برمجة Groq الوصول المباشر من المتصفح.",
  "IncludeSystemMessages": "تضمين الرسائل النظامية",
  "IncludeTimestampInUserMessage": "تضمين الطابع الزمني في رسالة المستخدم",
  "IncludeTimestampInUserMessageInfo": "بتضمين الطابع الزمني في رسالة المستخدم، يمكن للذكاء الاصطناعي إنشاء استجابات تأخذ الوقت بعين الاعتبار.\nيرجى تضمين الجملة التالية في موجه النظام الخاص بك:\n\n\"قد يتم تقديم إدخال المستخدم مع [timestamp]. هذا يمثل الوقت بتوقيت UTC في وقت الطلب، لذا يرجى إنشاء إجابتك مع مراعاة هذا الوقت.\"",
  "InitialSpeechTimeout": "مهلة التعرف على الكلام",
  "InitialSpeechTimeoutInfo": "يحدد هذا وقت الانتظار بعد بدء التعرف على الكلام حتى يتم اكتشاف الكلام الأول. إذا لم يتم اكتشاف الكلام خلال هذا الوقت، سيتوقف التعرف على الكلام تلقائيًا.\nإذا تم تعيينه إلى 0 ثانية، سيكون وقت الانتظار غير محدود.",
  "InputAudio": "صوت",
  "InputText": "نص",
  "KoeiromapInfo": "نحن نستخدم واجهة برمجة Koeiromap من Koemotion. تدعم اللغة اليابانية فقط. للمزيد من المعلومات، يرجى الاطلاع على الرابط أدناه.",
  "Language": "إعدادات اللغة",
  "LanguageChoice": "اختيار اللغة",
  "LanguageModelURL": "يرجى اختيار نموذج اللغة من URL أدناه.",
  "ListeningContinuously": "في انتظار إدخال الصوت...",
  "Live2D": {
    "EmotionInfo": "يمكن تحديد المشاعر مفصولة بفواصل. إذا تم تحديد عدة مشاعر، سيتم اختيار واحدة عشوائيًا.\nالقيم الافتراضية متوافقة مع النماذج المتوفرة في AITuberKit. إذا كنت تستخدم نموذجًا أصليًا، يرجى إدخال القيم المناسبة لنموذجك.\nبعد اكتمال المحادثة، سيتم عرض تعبير \"عادي\".",
    "Emotions": "إعدادات التعبير",
    "FileInfo": "يرجى وضع مجلد نموذج Live2D الذي ترغب في استخدامه في public/live2d. يجب أن يكون ملف model3.json موجودًا مباشرة داخل هذا المجلد.\nإذا لم يظهر في القائمة، يرجى إعادة تحميل الصفحة أو التحقق من صحة مسار المجلد.",
    "Info": "يمكنك تحديد المشاعر والحركات.\nتتم إدارة كل مشاعر من خلال الموجه. لمزيد من التفاصيل، يرجى الاطلاع على \"إعدادات الذكاء الاصطناعي => إعدادات الشخصية\".",
    "MotionGroups": "إعدادات مجموعة الحركة",
    "MotionGroupsInfo": "سيتم اختيار حركة عشوائية من مجموعة الحركة المحددة.\nكما هو الحال مع إعدادات التعبير، يرجى تكوينها وفقًا لنموذجك.\n\"وضع الخمول\" هو الحركة التي تظهر بعد اكتمال المحادثة.",
    "SelectMotionGroup": "اختر مجموعة الحركة",
    "angryEmotions": "غاضب",
    "angryMotionGroup": "غاضب",
    "happyEmotions": "سعيد",
    "happyMotionGroup": "سعيد",
    "idleMotionGroup": "وضع الخمول",
    "neutralEmotions": "عادي",
    "neutralMotionGroup": "عادي",
    "relaxedEmotions": "مسترخي",
    "relaxedMotionGroup": "مسترخي",
    "sadEmotions": "حزين",
    "sadMotionGroup": "حزين",
    "surprisedEmotions": "متفاجئ",
    "surprisedMotionGroup": "متفاجئ"
  },
  "LocalLLM": "نموذج لغوي محلي",
  "LocalLLMInfo": "يجب تشغيل خادم نموذج اللغة المحلي.",
  "LocalLLMInfo2": "يرجى إدخال عنوان URL للنموذج اللغوي المحلي (مع رقم المنفذ) واسم النموذج.",
  "LocalStorageReset": "إعادة تعيين الإعدادات",
  "LocalStorageResetButton": "إعادة تعيين الإعدادات",
  "LocalStorageResetInfo": "ستكون الأولوية للقيم المحددة في متغيرات البيئة إذا تم تعيينها. ستتم إعادة تحميل الصفحة.",
  "LogSettings": "سجل المحادثات",
  "MaxPastMessages": "عدد الرسائل السابقة المحتفظ بها",
  "MaxTokens": "الحد الأقصى للرموز",
  "MaxTokensInfo": "يختلف الحد الأقصى للرموز حسب نموذج الذكاء الاصطناعي المستخدم. يرجى التحقق من مواصفات كل نموذج.",
  "MessageReceiver": "قبول التعليمات من الخارج",
  "MessageReceiverDescription": "يمكنك توجيه تعليق شخصية الذكاء الاصطناعي من الخارج باستخدام واجهة البرمجة.",
  "Milliseconds": "مللي ثانية",
  "MistralAIAPIKeyLabel": "مفتاح واجهة برمجة MistralAI",
  "NijiVoiceActorId": "معرف المتحدث",
  "NijiVoiceApiKey": "مفتاح واجهة برمجة NijiVoice",
  "NijiVoiceEmotionalLevel": "مستوى العاطفة",
  "NijiVoiceInfo": "نحن نستخدم واجهة برمجة NijiVoice. تدعم اللغة اليابانية فقط. يرجى الحصول على مفتاح واجهة البرمجة من URL أدناه.",
  "NijiVoiceSoundDuration": "مدة الصوت",
  "NijiVoiceSpeed": "سرعة الكلام",
  "NoSpeechTimeout": "مهلة اكتشاف الصمت",
  "NoSpeechTimeoutInfo": "يحدد هذا الوقت الذي سيتم بعده إنهاء الإدخال تلقائيًا عندما يستمر الصمت أثناء إدخال الصوت.\nإذا تم تعيينه إلى 0 ثانية، سيتم تعطيل الإرسال التلقائي بواسطة اكتشاف الصمت.",
  "NotConnectedToExternalAssistant": "غير متصل بمساعد خارجي.",
  "OpenAIAPIKeyLabel": "مفتاح واجهة برمجة OpenAI",
  "OpenAITTSInfo": "نحن نستخدم OpenAI. يدعم لغات متعددة. إذا كنت قد اخترت OpenAI كخدمة ذكاء اصطناعي، فلا داعي لتعيين مفتاح واجهة البرمجة أدناه.",
  "OpenAITTSModel": "النموذج",
  "OpenAITTSSpeed": "سرعة الكلام",
  "OpenAITTSVoice": "نوع الصوت",
  "OpenSendMessagePage": "فتح صفحة إرسال الرسائل",
  "OpenVRM": "فتح VRM",
  "OtherSettings": "إعدادات أخرى",
  "PdfConvertButton": "تحويل PDF إلى شرائح",
  "PdfConvertDescription": "تحويل ملفات PDF إلى بيانات لوضع العرض التقديمي. متاح فقط عند اختيار OpenAI أو Anthropic Claude أو Google Gemini كخدمة ذكاء اصطناعي.",
  "PdfConvertError": "فشل التحويل",
  "PdfConvertFileUpload": "اختر ملف PDF",
  "PdfConvertFolderName": "اسم مجلد الحفظ",
  "PdfConvertLabel": "تحويل شرائح PDF",
  "PdfConvertLoading": "جاري التحويل...",
  "PdfConvertModelSelect": "اختر النموذج",
  "PdfConvertSubmitError": "يرجى التأكد من تكوين ملف PDF واسم المجلد ومفتاح واجهة البرمجة",
  "PdfConvertSuccess": "اكتمل التحويل",
  "PerplexityAPIKeyLabel": "مفتاح واجهة برمجة Perplexity",
  "PleaseSelectSlide": "スライドを選択してください",
  "PresetQuestions": "أسئلة معدة مسبقًا",
  "PresetQuestionsInfo": "يمكنك إنشاء وتسجيل أنماط أسئلة متعددة مسبقًا. ستظهر الأسئلة المسجلة كأزرار في واجهة المستخدم، وعند النقر عليها ستوضع في مربع إدخال الدردشة.",
  "RealtimeAPIMode": "وضع واجهة البرمجة في الوقت الفعلي",
  "RealtimeAPIModeContentType": "نوع الإرسال",
  "RealtimeAPIModeVoice": "نوع الصوت",
  "RepositoryURL": "عنوان URL للمستودع:",
  "SearchGrounding": "استخدام ميزة البحث",
  "SearchGroundingDescription": "عند استخدام ميزة متعددة الوسائط، سيتم تعطيل ميزة البحث تلقائيًا.",
  "Select": "الرجاء الاختيار",
  "SelectAIService": "اختر خدمة الذكاء الاصطناعي",
  "SelectModel": "اختر النموذج",
  "SelectedSlideDocs": "الشرائح المستخدمة",
  "SendMessage": {
    "aiGenerateDescription": "سيقوم الذكاء الاصطناعي بتوليد إجابة من الرسالة التي أرسلتها، ثم جعل شخصية الذكاء الاصطناعي تنطق بتلك الإجابة. إذا أرسلت عدة رسائل، فستتم معالجتها بالترتيب.\nسيتم استخدام نموذج الذكاء الاصطناعي ونموذج الصوت المحددين في إعدادات AITuberKit.\nيمكنك اختيار استخدام موجه النظام من AITuberKit أو موجه نظام مخصص.\nإذا كنت ترغب في تحميل سجل المحادثة السابق، يرجى تضمين السلسلة [conversation_history] في أي مكان في موجه النظام أو رسالة المستخدم.",
    "aiGenerateTitle": "توليد إجابة بالذكاء الاصطناعي ثم نطقها",
    "directSendDescription": "يمكنك جعل شخصية الذكاء الاصطناعي تتحدث بالرسالة التي أرسلتها مباشرة. إذا أرسلت عدة رسائل، فستتم معالجتها بالترتيب.\nسيتم استخدام نموذج الصوت المحدد في إعدادات AITuberKit.",
    "directSendTitle": "جعل شخصية الذكاء الاصطناعي تتحدث مباشرة",
    "title": "محول خارجي لـ AITuberKit",
    "useCurrentSystemPrompt": "استخدام موجه النظام من AITuberKit",
    "userInputDescription": "ستتم معالجة الرسالة التي أرسلتها بنفس طريقة معالجة الإدخال من نموذج الإدخال في AITuberKit. إذا أرسلت عدة رسائل، فستتم معالجتها بالترتيب.\nسيتم استخدام نموذج الذكاء الاصطناعي ونموذج الصوت المحددين في إعدادات AITuberKit.\nسيتم استخدام موجه النظام وسجل المحادثة من AITuberKit.",
    "userInputTitle": "إرسال إدخال المستخدم"
  },
  "ShowAssistantText": "عرض مربع الإجابة",
  "ShowCharacterName": "عرض اسم الشخصية في مربع الإجابة",
  "ShowCharacterPresetMenu": "عرض زر قائمة الإعدادات المسبقة للشخصية",
  "ShowControlPanel": "عرض لوحة التحكم",
  "ShowControlPanelInfo": "يمكنك عرض شاشة الإعدادات باستخدام Cmd + . (Mac) / Ctrl + . (Windows).\nإذا كنت تستخدم هاتفًا ذكيًا، يمكنك أيضًا الضغط لفترة طويلة (حوالي ثانية واحدة) في الزاوية العلوية اليسرى من الشاشة.",
  "ShowSilenceProgressBar": "عرض شريط تقدم اكتشاف الصمت",
  "SlideMode": "وضع العرض التقديمي",
  "SlideModeDescription": "هذا هو الوضع الذي يعرض فيه الذكاء الاصطناعي الشرائح تلقائيًا. متاح فقط عند اختيار OpenAI أو Anthropic Claude أو Google Gemini كخدمة ذكاء اصطناعي.",
  "SlideSettings": "إعدادات العرض التقديمي",
  "SourceCodeDescription1": "رمز المصدر لهذا التطبيق متاح على GitHub. يمكنك تعديله وتغييره بحرية.",
  "SourceCodeDescription2": "فيما يتعلق بالاستخدام التجاري، يرجى الرجوع إلى ملف README في نفس المستودع.",
  "SpeakerSelection": "اختيار نوع الصوت",
  "SpeechInputSettings": "إعدادات إدخال الصوت",
  "SpeechRecognitionMode": "وضع التعرف على الكلام",
  "SpeechRecognitionModeDisabledInfo": "عندما يكون وضع الصوت نشطًا، يكون التعرف على كلام المتصفح فقط متاحًا.\nأيضًا، في وضع واجهة برمجة التطبيقات في الوقت الفعلي، يكون التعرف على كلام المتصفح فقط متاحًا وتكون ميزة مهلة التعرف على الكلام معطلة.",
  "SpeechRecognitionModeInfo": "يمكنك اختيار وضع التعرف على الكلام.\n\"قياسي المتصفح\" يستخدم التعرف على الكلام المدمج في المتصفح. \"OpenAI TTS\" يستخدم واجهة برمجة تحويل النص إلى كلام من OpenAI.\nبشكل عام، \"قياسي المتصفح\" هو الخيار الموصى به لأنه أكثر دقة وأسرع في التعرف. ومع ذلك، إذا كنت تستخدم متصفحًا لا يدعم واجهة برمجة WebSpeech مثل Firefox، فيرجى اختيار \"OpenAI TTS\".",
  "StatusOff": "الحالة: إيقاف",
  "StatusOn": "الحالة: تشغيل",
  "StyleBeatVITS2ApiKey": "مفتاح واجهة البرمجة",
  "StyleBeatVITS2Length": "سرعة الكلام",
  "StyleBeatVITS2ModelID": "معرف النموذج",
  "StyleBeatVITS2SdpRatio": "نسبة خلط SDP/DP",
  "StyleBeatVITS2ServerURL": "عنوان URL للخادم",
  "StyleBeatVITS2Style": "الأسلوب",
  "StyleBertVITS2Info": "نحن نستخدم Style-Bert-VITS2. يدعم اليابانية والإنجليزية والصينية فقط. إذا كنت تستخدم واجهة برمجة محلية، فستحتاج إلى تنزيل وتشغيل التطبيق المناسب لبيئتك من الموقع أدناه. قم أيضًا بتكوين مفتاح واجهة البرمجة إذا لزم الأمر.",
  "SyntheticVoiceEngineChoice": "اختيار محرك الصوت الاصطناعي",
  "TechnologyIntroduction": "مقدمة تقنية",
  "TechnologyIntroductionDescription1": "تم إنشاء هذا التطبيق عن طريق تعديل <b>ChatVRM</b> من شركة pixiv. يمكنك العثور على الكود المصدري الأصلي",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "نحن نستخدم",
  "TechnologyIntroductionDescription4": " لعرض ومعالجة النماذج ثلاثية الأبعاد، و",
  "TechnologyIntroductionDescription5": " ومختلف نماذج اللغة الكبيرة لإنشاء نص المحادثة، و",
  "TechnologyIntroductionDescription6": " ومختلف تقنيات تحويل النص إلى كلام لتوليف الصوت. للحصول على مزيد من التفاصيل، يرجى الاطلاع على",
  "TechnologyIntroductionDescription7": ".",
  "TechnologyIntroductionLink1": "هنا",
  "TechnologyIntroductionLink2": "مقالة توضيحية",
  "Temperature": "درجة الحرارة",
  "TestSelectedVoice": "تشغيل",
  "TestVoice": "اختبار الصوت",
  "TestVoiceSettings": "اختبار الصوت",
  "Toasts": {
    "FirefoxNotSupported": "Firefoxではこの機能はサポートされていません",
    "FunctionExecuting": "{{funcName}}を実行しています",
    "FunctionExecutionFailed": "{{funcName}}の実行に失敗しました",
    "NoSpeechDetected": "音声が検出されませんでした。",
    "PresetSwitching": "{{presetName}}に切り替わりました。",
    "SpeechRecognitionError": "音声認識エラーが発生しました",
    "UsingTool": "{{toolName}}を使用中",
    "WebSocketConnectionAttempt": "WebSocket接続を試みています...",
    "WebSocketConnectionClosed": "WebSocket接続が閉じられました",
    "WebSocketConnectionError": "WebSocket接続にエラーが発生しました",
    "WebSocketConnectionSuccess": "WebSocket接続に成功しました",
    "WhisperError": "Whisperによる音声認識でエラーが発生しました"
  },
  "UpdateRealtimeAPISettings": "تحديث إعدادات واجهة البرمجة في الوقت الفعلي",
  "UpdateRealtimeAPISettingsInfo": "عند تحديث مفتاح واجهة البرمجة أو نقطة نهاية Azure أو نوع الصوت أو النموذج أو موجه النظام، يرجى الضغط على زر التحديث لبدء جلسة WebSocket جديدة.",
  "UpdateSpeakerList": "تحديث قائمة المتحدثين",
  "UploadBackground": "تحميل صورة خلفية",
  "UseVideoAsBackground": "استخدم شاشة مشتركة أو كاميرا الويب كخلفية",
  "UsingAivisSpeech": "استخدام AivisSpeech",
  "UsingAzureTTS": "استخدام Azure OpenAI",
  "UsingElevenLabs": "استخدام ElevenLabs",
  "UsingGSVITTS": "استخدام GSVI TTS",
  "UsingGoogleTTS": "استخدام Google Text-to-Speech",
  "UsingKoeiromap": "استخدام Koeiromap",
  "UsingNijiVoice": "استخدام NijiVoice",
  "UsingOpenAITTS": "استخدام OpenAI",
  "UsingStyleBertVITS2": "استخدام Style-Bert-VITS2",
  "UsingVoiceVox": "استخدام VOICEVOX",
  "VoiceAdjustment": "ضبط الصوت",
  "VoiceEngineInstruction": "يرجى اختيار محرك الصوت الاصطناعي الذي تريد استخدامه.",
  "VoiceSettings": "إعدادات الصوت الاصطناعي",
  "VoiceVoxInfo": "نحن نستخدم VOICEVOX. تدعم اللغة اليابانية فقط. نظرًا لأننا نستخدم واجهة برمجة محلية، تحتاج إلى تنزيل وتشغيل التطبيق المناسب لبيئتك من الموقع أدناه.",
  "VoicevoxIntonation": "نبرة الصوت",
  "VoicevoxPitch": "طبقة الصوت",
  "VoicevoxServerUrl": "عنوان URL لخادم VOICEVOX",
  "VoicevoxSpeed": "سرعة الكلام",
  "WhisperSpeechRecognition": "استخدام التعرف على كلام OpenAI TTS",
  "WhisperTranscriptionModel": "نموذج النسخ",
  "WhisperTranscriptionModelInfo": "يمكنك اختيار النموذج المستخدم للتعرف على الكلام. النماذج الأكثر تقدمًا تقدم تعرفًا أكثر دقة ولكن قد تكون أعلى تكلفة من حيث واجهة البرمجة.",
  "YoutubeAPIKey": "مفتاح واجهة برمجة يوتيوب",
  "YoutubeInfo": "سيتم تجاهل التعليقات التي تبدأ بـ \"#\".",
  "YoutubeLiveID": "معرف بث يوتيوب المباشر",
  "YoutubeMode": "وضع يوتيوب",
  "YoutubeSettings": "إعدادات يوتيوب"
}
