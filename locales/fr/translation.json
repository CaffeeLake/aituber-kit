{
  "AISettings": "Paramètres de l'IA",
  "APIKeyInstruction": "Vous pouvez obtenir la clé API ci-dessous. Entrez la clé API obtenue dans le formulaire.",
  "APIKeyNotEntered": "La clé API n'est pas saisie.",
  "AboutThisApplication": "À propos de cette application",
  "AboutThisApplicationDescription": "Profitez de conversations avec un personnage 3D directement dans votre navigateur web, en utilisant le microphone ou la saisie de texte et la synthèse vocale. Vous pouvez également changer le personnage (VRM), ajuster sa personnalité et modifier sa voix.<br />Les paramètres peuvent être modifiés depuis le bouton menu en haut à gauche.",
  "AboutThisApplicationDescription2": "Si vous souhaitez changer le personnage, veuillez consulter l'onglet \"Paramètres de personnage\".",
  "AivisSpeechInfo": "Utilisation d'AivisSpeech. Ne prend en charge que le japonais. Utilise une API locale, vous devez télécharger et lancer l'application qui convient à votre environnement depuis le site ci-dessous.",
  "AivisSpeechIntonation": "Intonation",
  "AivisSpeechPitch": "Hauteur",
  "AivisSpeechServerUrl": "URL du serveur AivisSpeech",
  "AivisSpeechSpeaker": "Locuteur",
  "AivisSpeechSpeed": "Vitesse",
  "AnswerGenerating": "Génération de la réponse",
  "AnthropicAPIKeyLabel": "Clé API Anthropic",
  "AudioMode": "Mode audio",
  "AuthFileInstruction": "Une clé API ou un fichier d'authentification est requis. Obtenez-le depuis l'URL ci-dessous et placez-le dans le dossier racine du dépôt s'il s'agit d'un fichier JSON.",
  "AzureAPIKeyLabel": "Clé API Azure OpenAI",
  "AzureAPIURL": "URL API Azure OpenAI",
  "AzureEndpoint": "Point de terminaison Azure",
  "AzureTTSInfo": "Utilisation d'Azure OpenAI. Prend en charge plusieurs langues.",
  "BackgroundImage": "Image de fond",
  "BackgroundSettings": "Paramètres d'arrière-plan",
  "BackgroundSettingsDescription": "Vous pouvez télécharger et sélectionner l'image de fond de l'application.",
  "BasedSettings": "Paramètres de base",
  "BrowserSpeechRecognition": "Utiliser la reconnaissance vocale standard du navigateur",
  "CannotUseParameters": "Si le mode API en temps réel ou le mode audio est activé, les paramètres Temperature et Max Tokens ne peuvent pas être spécifiés.",
  "CannotUseVoice": "En mode API en temps réel ou en mode audio,\nles paramètres de synthèse vocale ne sont pas nécessaires.",
  "ChangeBackgroundImage": "Changer l'image de fond",
  "CharacterModelInfo": "Le modèle peut prendre du temps à charger lors du premier affichage.",
  "CharacterModelLabel": "Modèle de personnage",
  "CharacterName": "Nom du personnage",
  "CharacterSettings": "Paramètres du personnage",
  "CharacterSettingsInfo": "Cette valeur est définie comme l'invite système.\nVeuillez vous référer à l'invite initiale et spécifier les balises d'émotion pour contrôler les expressions et les mouvements du personnage. Exemple : [neutral]Bonjour![happy]Aujourd'hui est aussi une journée difficile!",
  "CharacterSettingsPrompt": "Invite de personnage",
  "Characterpreset1": "Préréglage 1",
  "Characterpreset2": "Préréglage 2",
  "Characterpreset3": "Préréglage 3",
  "Characterpreset4": "Préréglage 4",
  "Characterpreset5": "Préréglage 5",
  "CharacterpresetInfo": "En sélectionnant un préréglage, l'invite de personnage sera modifiée.\nCmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows) pour les raccourcis.",
  "ChatLog": "Journal des conversations",
  "ClientID": "ID client",
  "Close": "FERMER",
  "CohereAPIKeyLabel": "Clé API Cohere",
  "Contact": "Contact",
  "ContactDescription": "Veuillez me contacter via l'adresse e-mail ou le compte Twitter ci-dessous concernant cette application.",
  "ContinuousMic": "Entrée microphone continue",
  "ContinuousMicActive": "Entrée microphone continue active",
  "ContinuousMicInfo": "Le microphone se réactivera automatiquement lorsque la parole de l'IA sera terminée. Il sera automatiquement envoyé après le temps de silence défini.\nSi le temps défini est dépassé sans détection de parole, l'entrée microphone continue sera automatiquement désactivée. Si vous souhaitez qu'elle reste toujours activée, définissez le délai d'expiration de la reconnaissance vocale à 0 secondes.",
  "ContinuousMicModeOff": "Le mode d'entrée microphone continue est désactivé",
  "ContinuousMicModeOn": "Le mode d'entrée microphone continue est activé",
  "ConversationContinuityMode": "Mode de continuité de conversation (Beta)",
  "ConversationContinuityModeInfo": "Quand il n'y a pas de commentaire, l'IA essaie de continuer la conversation. Actuellement uniquement OpenAI, Anthropic Claude, Google Gemini sont supportés.",
  "ConversationContinuityModeInfo2": "Une réponse appelle LLM plusieurs fois, donc l'utilisation de l'API peut augmenter. Veuillez en tenir compte.",
  "ConversationContinuityModeInfo3": "gpt-4, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet fonctionnent relativement stablement.",
  "ConversationHistory": "Historique des conversations",
  "ConversationHistoryInfo": "Les {{count}} dernières conversations seront conservées en mémoire.",
  "ConversationHistoryReset": "Réinitialiser l'historique des conversations",
  "Creator": "Créateur",
  "CreatorDescription": "Créateur : Tegan",
  "CustomAPIBody": "Corps personnalisé",
  "CustomAPIBodyInfo": "Veuillez entrer les informations du corps à inclure dans la requête API au format JSON. Les messages seront automatiquement inclus.",
  "CustomAPIDescription": "Remarque : les messages sont automatiquement inclus dans le corps de la requête. En mode streaming, le serveur doit renvoyer text/event-stream.",
  "CustomAPIEndpoint": "Point de terminaison API personnalisé",
  "CustomAPIEndpointInfo": "Veuillez entrer l'URL du point de terminaison API où envoyer la requête POST.",
  "CustomAPIHeaders": "En-têtes personnalisés",
  "CustomAPIHeadersInfo": "Veuillez entrer les informations d'en-tête à inclure dans la requête API au format JSON.",
  "CustomAPIStream": "Mode de streaming",
  "CustomAPIStreamForced": "Actuellement, le mode de streaming est toujours activé.",
  "DeepSeekAPIKeyLabel": "Clé API DeepSeek",
  "DefaultBackground": "Arrière-plan par défaut",
  "Description": "À propos de l'application",
  "DifyAPIKeyLabel": "Clé API Dify",
  "DifyInfo": "Dify ne prend en charge que les types chatbot et agent.",
  "DifyInfo2": "La longueur de l'historique des conversations dépend des spécifications de Dify.",
  "DifyInfo3": "Exemple : https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "Si vous utilisez Dify, l'invite système ne sera pas utilisée. Veuillez configurer le chatbot Dify.",
  "DocumentationDescription": "Vous pouvez consulter des instructions détaillées et des tutoriels sur AITuberKit à l'URL ci-dessous.",
  "DontShowIntroductionNextTime": "Ne plus afficher cette boîte de dialogue",
  "DragToReorder": "Faites glisser pour réorganiser",
  "ElevenLabsApiKey": "Clé API ElevenLabs",
  "ElevenLabsInfo": "L'API ElevenLabs est utilisée. Elle prend en charge plusieurs langues. La clé API peut être obtenue depuis l'URL ci-dessous.",
  "ElevenLabsVoiceId": "ID de voix ElevenLabs",
  "ElevenLabsVoiceIdInfo": "L'ID de voix peut être sélectionné depuis l'URL ci-dessous.",
  "EnterPresetQuestion": "Veuillez entrer une question",
  "EnterURL": "URL",
  "EnterYourQuestion": "Entrez votre question ici",
  "Errors": {
    "AIAPIError": "Une erreur s'est produite lors de l'exécution de l'API IA",
    "AIInvalidProperty": "Les paramètres du service IA sont incorrects",
    "CustomAPIError": "Une erreur s'est produite avec l'API personnalisée",
    "EmptyAPIKey": "La clé API n'est pas définie",
    "EmptyLocalLLMURL": "L'URL du LLM local n'est pas définie",
    "InvalidAIService": "Le service IA sélectionné n'est pas valide",
    "InvalidJSON": "Le format JSON n'est pas correct",
    "LocalLLMAPIError": "Erreur API LLM locale",
    "LocalLLMConnectionError": "Erreur de connexion au serveur LLM local",
    "LocalLLMError": "Erreur LLM locale",
    "LocalLLMNotFound": "Point de terminaison LLM local non trouvé",
    "LocalLLMStreamError": "Erreur de flux LLM local",
    "MethodNotAllowed": "La requête n'est pas appropriée",
    "TTSServiceError": "Une erreur s'est produite dans le service TTS {{serviceName}} : {{message}}",
    "UnexpectedError": "Une erreur inattendue s'est produite"
  },
  "ExternalLinkageMode": "Mode de liaison externe (version bêta)",
  "FireworksAPIKeyLabel": "Clé API Fireworks",
  "GSVITTSBatchSize": "Taille du lot GSVI TTS (1 ~ 100 Plus la valeur est grande, plus la vitesse d'inférence est rapide, mais cela peut épuiser la mémoire si trop grand.)",
  "GSVITTSInfo": "Paramètres GSVI TTS",
  "GSVITTSModelID": "ID du modèle GSVI TTS",
  "GSVITTSServerUrl": "API endpoint GSVI TTS",
  "GSVITTSSpeechRate": "Débit de parole (0.5 ~ 2.0 Plus la valeur est grande, plus c'est rapide.)",
  "GoogleAPIKeyLabel": "Clé API Google Gemini",
  "GoogleTTSInfo": "Utilisation de Google Cloud Text-to-Speech. Prend en charge plusieurs langues.",
  "GroqAPIKeyLabel": "Clé API Groq",
  "GroqInfo": "L'API Groq est accessible directement depuis le navigateur.",
  "IncludeTimestampInUserMessage": "Inclure l'horodatage dans le message utilisateur",
  "IncludeTimestampInUserMessageInfo": "En incluant des horodatages dans les messages utilisateur, l'IA peut générer des réponses en tenant compte du temps.\nVeuillez inclure le texte suivant dans votre invite système :\n\n\"Les entrées utilisateur peuvent inclure [timestamp]. Cela représente l'heure UTC au moment de la requête, veuillez donc générer des réponses en tenant compte de cet horodatage.\"",
  "InitialSpeechTimeout": "Délai d'expiration de la reconnaissance vocale",
  "InitialSpeechTimeoutInfo": "Définissez le temps d'attente jusqu'à ce que la première parole soit détectée après le début de la reconnaissance vocale. Si aucune parole n'est détectée dans ce délai, la reconnaissance vocale s'arrête automatiquement.\nSi vous le définissez à 0 secondes, le temps d'attente sera illimité.",
  "InputAudio": "Audio",
  "InputText": "Texte",
  "KoeiromapInfo": "Utilisation de l'API Koeiromap de Koemotion. Ne prend en charge que le japonais. Pour plus de détails, veuillez consulter le lien ci-dessous.",
  "Language": "Langue",
  "LanguageChoice": "Choix de la langue",
  "LanguageModelURL": "Sélectionnez le modèle de langue depuis l'URL ci-dessous.",
  "ListeningContinuously": "En attente d'entrée vocale...",
  "Live2D": {
    "EmotionInfo": "Les émotions peuvent être spécifiées au format séparé par des virgules. Si plusieurs émotions sont spécifiées, elles sont sélectionnées aléatoirement.\nLa valeur initiale est pour le modèle fourni par AITuberKit. Si vous utilisez un modèle original, veuillez entrer la valeur selon votre modèle.\nAprès la fin de la conversation, l'émotion \"Neutre\" est affichée.",
    "Emotions": "Paramètres d'émotion",
    "FileInfo": "Placez le modèle Live2D que vous souhaitez utiliser dans le dossier public/live2d. Le fichier model3.json doit exister à la racine de ce dossier.\nS'il n'est pas affiché dans la sélection, veuillez recharger l'écran ou vérifier si le chemin du dossier est correct.",
    "Info": "Vous pouvez spécifier les émotions et les mouvements.\nChaque émotion est contrôlée par l'invite. Pour plus de détails, veuillez consulter \"Paramètres IA => Paramètres de personnage\".",
    "MotionGroups": "Paramètres des groupes de mouvement",
    "MotionGroupsInfo": "Les groupes de mouvement sont sélectionnés aléatoirement dans le groupe sélectionné.\nComme pour les paramètres d'émotion, veuillez les définir selon votre modèle.\n\"Idle\" est le mouvement affiché après la fin de la conversation.",
    "SelectMotionGroup": "Sélectionner le groupe de mouvement",
    "angryEmotions": "En colère",
    "angryMotionGroup": "En colère",
    "happyEmotions": "Heureux",
    "happyMotionGroup": "Heureux",
    "idleMotionGroup": "Inactif",
    "neutralEmotions": "Neutre",
    "neutralMotionGroup": "Neutre",
    "relaxedEmotions": "Détendu",
    "relaxedMotionGroup": "Détendu",
    "sadEmotions": "Triste",
    "sadMotionGroup": "Triste",
    "surprisedEmotions": "Surprise",
    "surprisedMotionGroup": "Surprise"
  },
  "LocalLLM": "LLM local",
  "LocalLLMInfo": "Le serveur LLM local doit être en cours d'exécution. La configuration est la suivante.",
  "LocalLLMInfo2": "Veuillez entrer l'URL du serveur LLM local (y compris le numéro de port) et le nom du modèle.",
  "LocalStorageReset": "Réinitialiser les paramètres",
  "LocalStorageResetButton": "Réinitialiser les paramètres",
  "LocalStorageResetInfo": "Les variables d'environnement sont prioritaires si définies. La page sera rechargée.",
  "LogSettings": "Historique des conversations",
  "MaxPastMessages": "Nombre de messages passés à conserver",
  "MaxTokens": "Nombre maximal de tokens",
  "MaxTokensInfo": "Le nombre maximal de tokens varie en fonction du modèle AI utilisé. Veuillez vérifier les spécifications de chaque modèle.",
  "MessageReceiver": "Recevoir des instructions de l'extérieur",
  "MessageReceiverDescription": "Vous pouvez utiliser l'API pour faire parler les personnages IA depuis l'extérieur.",
  "Milliseconds": "Millisecondes",
  "MistralAIAPIKeyLabel": "Clé API MistralAI",
  "NijiVoiceActorId": "ID de l'acteur",
  "NijiVoiceApiKey": "Clé API NijiVoice",
  "NijiVoiceEmotionalLevel": "Niveau émotionnel",
  "NijiVoiceInfo": "L'API NijiVoice est utilisée. Ne prend en charge que le japonais. La clé API peut être obtenue depuis l'URL ci-dessous.",
  "NijiVoiceSoundDuration": "Durée du son",
  "NijiVoiceSpeed": "Vitesse de parole",
  "NotConnectedToExternalAssistant": "Non connecté à un assistant externe.",
  "OpenAIAPIKeyLabel": "Clé API OpenAI",
  "OpenAITTSInfo": "Utilisation d'OpenAI. Prend en charge plusieurs langues. Si vous sélectionnez OpenAI comme service IA, vous n'avez pas besoin de définir la clé API ci-dessous.",
  "OpenAITTSModel": "Modèle",
  "OpenAITTSSpeed": "Vitesse",
  "OpenAITTSVoice": "Type de voix",
  "OpenSendMessagePage": "Ouvrir la page d'envoi de message",
  "OpenVRM": "Ouvrir VRM",
  "OtherSettings": "Autres",
  "PdfConvertButton": "Convertir PDF en diapositives",
  "PdfConvertDescription": "Convertir PDF en données de mode diaporama. Disponible uniquement lorsque le service IA sélectionné est OpenAI, Anthropic Claude ou Google Gemini.",
  "PdfConvertError": "Échec de la conversion",
  "PdfConvertFileUpload": "Sélectionner le fichier PDF",
  "PdfConvertFolderName": "Nom du dossier de sauvegarde",
  "PdfConvertLabel": "Conversion de diapositives PDF",
  "PdfConvertLoading": "Conversion en cours...",
  "PdfConvertModelSelect": "Sélectionner le modèle",
  "PdfConvertSubmitError": "Veuillez vous assurer que le fichier PDF, le nom du dossier et la clé API sont définis.",
  "PdfConvertSuccess": "Conversion terminée",
  "PerplexityAPIKeyLabel": "Clé API Perplexity",
  "PresetQuestions": "Questions prédéfinies",
  "PresetQuestionsInfo": "Vous pouvez créer et enregistrer plusieurs modèles de questions à l'avance. Les questions enregistrées seront affichées sous forme de boutons dans l'interface utilisateur, et en cliquant dessus, elles seront insérées dans le champ de saisie de chat.",
  "RealtimeAPIMode": "Mode API en temps réel",
  "RealtimeAPIModeContentType": "Type d'envoi",
  "RealtimeAPIModeVoice": "Type de voix",
  "RepositoryURL": "URL du dépôt :",
  "SearchGrounding": "Utiliser la recherche contextuelle",
  "SearchGroundingDescription": "Lors de l'utilisation de la fonction multimodale, la fonction de recherche est automatiquement désactivée.",
  "Select": "Sélectionner",
  "SelectAIService": "Sélectionner le service IA",
  "SelectModel": "Sélectionner le modèle",
  "SelectedSlideDocs": "Documents diaporama sélectionnés",
  "SendMessage": {
    "aiGenerateDescription": "L'IA génère une réponse à partir du message envoyé puis la prononce. Si plusieurs messages sont envoyés, ils sont traités dans l'ordre. Le modèle IA et le modèle de voix sont ceux sélectionnés dans les paramètres AITuberKit. L'invite système peut être sélectionnée pour utiliser l'invite système AITuberKit ou une invite système personnalisée. Si vous voulez charger l'historique des conversations passées, incluez la chaîne [conversation_history] dans l'invite système ou le message utilisateur.",
    "aiGenerateTitle": "Générer une réponse IA puis parler",
    "directSendDescription": "Vous pouvez envoyer le message directement au personnage IA. Si plusieurs messages sont envoyés, ils sont traités dans l'ordre. Le modèle de voix est celui sélectionné dans les paramètres AITuberKit.",
    "directSendTitle": "Parler directement au personnage IA",
    "title": "Adaptateur externe AITuberKit",
    "useCurrentSystemPrompt": "Utiliser l'invite système AITuberKit",
    "userInputDescription": "Le message envoyé est traité de la même manière que lorsqu'il est saisi depuis le formulaire d'entrée AITuberKit. Si plusieurs messages sont envoyés, ils sont traités dans l'ordre. Le modèle IA et le modèle de voix sont ceux sélectionnés dans les paramètres AITuberKit. L'invite système et l'historique des conversations sont les valeurs définies dans AITuberKit.",
    "userInputTitle": "Envoyer une entrée utilisateur"
  },
  "ShowAssistantText": "Afficher la boîte de réponse",
  "ShowCharacterName": "Afficher le nom du personnage dans la boîte de réponse",
  "ShowCharacterPresetMenu": "Afficher le bouton du menu des préréglages de personnage",
  "ShowControlPanel": "Afficher le bouton des paramètres",
  "ShowControlPanelInfo": "L'écran des paramètres peut être affiché avec Cmd + . (Mac) / Ctrl + . (Windows).\nSi vous utilisez un smartphone, vous pouvez également le faire en maintenant enfoncé le coin supérieur gauche de l'écran (environ 1 seconde).",
  "ShowSilenceProgressBar": "Afficher la barre de progression de détection de silence",
  "SlideMode": "Mode diaporama",
  "SlideModeDescription": "C'est un mode où l'IA présente automatiquement des diapositives. Il n'est disponible que lorsque le service IA sélectionné est OpenAI, Anthropic Claude ou Google Gemini.",
  "SlideSettings": "Paramètres de diaporama",
  "SourceCodeDescription1": "Le code source de cette application est disponible publiquement sur GitHub. N'hésitez pas à le modifier et l'adapter comme vous le souhaitez.",
  "SourceCodeDescription2": "Pour une utilisation commerciale, veuillez consulter le README du même dépôt.",
  "SpeakerSelection": "Sélection du locuteur",
  "SpeechInputSettings": "Paramètres d'entrée vocale",
  "SpeechRecognitionMode": "Mode de reconnaissance vocale",
  "SpeechRecognitionModeDisabledInfo": "Lorsque le mode audio est activé, seule la reconnaissance vocale du navigateur est disponible.\nDe plus, en mode API en temps réel, seule la reconnaissance vocale du navigateur est disponible et la fonction de délai d'expiration de la reconnaissance vocale est désactivée.",
  "SpeechRecognitionModeInfo": "Vous pouvez choisir le mode de reconnaissance vocale.\n\"Standard du navigateur\" utilise la reconnaissance vocale intégrée au navigateur. \"OpenAI TTS\" utilise l'API Text to Speech d'OpenAI.\nEn général, le mode \"Standard du navigateur\" est recommandé car il est plus précis et plus rapide. Cependant, si vous utilisez un navigateur qui ne prend pas en charge l'API WebSpeech comme Firefox, choisissez \"OpenAI TTS\".",
  "StatusOff": "Statut : DÉSACTIVÉ",
  "StatusOn": "Statut : ACTIVÉ",
  "StyleBeatVITS2ApiKey": "Clé API",
  "StyleBeatVITS2Length": "Débit de parole",
  "StyleBeatVITS2ModelID": "ID du modèle",
  "StyleBeatVITS2SdpRatio": "Ratio de mixage SDP/DP",
  "StyleBeatVITS2ServerURL": "URL du serveur",
  "StyleBeatVITS2Style": "Style",
  "StyleBertVITS2Info": "Utilisation de Style-Bert-VITS2. Ne prend en charge que le japonais, l'anglais et le chinois. Si vous utilisez une API locale, vous devez télécharger et lancer l'application qui convient à votre environnement depuis le site ci-dessous. Veuillez également configurer une clé API si nécessaire.",
  "SyntheticVoiceEngineChoice": "Choisir le moteur de synthèse vocale",
  "TechnologyIntroduction": "Introduction à la technologie",
  "TechnologyIntroductionDescription1": "Cette application a été créée en modifiant le <b>ChatVRM</b> de pixiv. Le code source original peut être trouvé",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "Pour l'affichage et la manipulation des modèles 3D,",
  "TechnologyIntroductionDescription4": "est utilisé. Pour générer le texte de conversation, divers LLM tels que",
  "TechnologyIntroductionDescription5": "sont utilisés. Pour la synthèse vocale, divers moteurs TTS comme",
  "TechnologyIntroductionDescription6": "sont utilisés. Pour plus de détails, consultez cet",
  "TechnologyIntroductionDescription7": ".",
  "TechnologyIntroductionLink1": "ici",
  "TechnologyIntroductionLink2": "article explicatif",
  "Temperature": "Température",
  "TestVoice": "Tester la voix",
  "Toasts": {
    "FirefoxNotSupported": "Cette fonctionnalité n'est pas prise en charge sur Firefox",
    "FunctionExecuting": "Exécution de {{funcName}}",
    "FunctionExecutionFailed": "L'exécution de {{funcName}} a échoué",
    "PresetSwitching": "Vous avez basculé sur {{presetName}}.",
    "SpeechRecognitionError": "Une erreur de reconnaissance vocale s'est produite",
    "WebSocketConnectionAttempt": "Tentative de connexion WebSocket...",
    "WebSocketConnectionClosed": "Connexion WebSocket fermée",
    "WebSocketConnectionError": "Erreur survenue dans la connexion WebSocket",
    "WebSocketConnectionSuccess": "Connexion WebSocket réussie",
    "WhisperError": "Une erreur s'est produite lors de la reconnaissance vocale avec Whisper"
  },
  "UpdateRealtimeAPISettings": "Mettre à jour les paramètres API en temps réel",
  "UpdateRealtimeAPISettingsInfo": "Lors de la mise à jour de la clé API, du point de terminaison Azure, du type de voix, du modèle ou de l'invite système, veuillez appuyer sur le bouton de mise à jour pour démarrer une nouvelle session WebSocket.",
  "UpdateSpeakerList": "Mettre à jour la liste des locuteurs",
  "UploadBackground": "Télécharger l'image de fond",
  "UseVideoAsBackground": "Utiliser l'écran partagé ou la webcam comme arrière-plan",
  "UsingAivisSpeech": "AivisSpeech",
  "UsingAzureTTS": "Utilisation d'Azure OpenAI",
  "UsingElevenLabs": "ElevenLabs",
  "UsingGSVITTS": "GSVI TTS",
  "UsingGoogleTTS": "Utiliser Google Text-to-Speech",
  "UsingKoeiromap": "Koeiromap",
  "UsingNijiVoice": "NijiVoice",
  "UsingOpenAITTS": "Utilisation d'OpenAI",
  "UsingStyleBertVITS2": "Style-Bert-VITS2",
  "UsingVoiceVox": "VOICEVOX",
  "VoiceAdjustment": "Ajustement de la voix",
  "VoiceEngineInstruction": "Sélectionnez le moteur de synthèse vocale que vous souhaitez utiliser.",
  "VoiceSettings": "Paramètres de synthèse vocale",
  "VoiceVoxInfo": "Utilisation de VOICEVOX. Ne prend en charge que le japonais. Utilise une API locale, vous devez télécharger et lancer l'application qui convient à votre environnement depuis le site ci-dessous.",
  "VoicevoxIntonation": "Intonation",
  "VoicevoxPitch": "Hauteur",
  "VoicevoxServerUrl": "URL du serveur VOICEVOX",
  "VoicevoxSpeed": "Vitesse",
  "WhisperAPIKeyInfo": "Le mode Whisper nécessite une clé API OpenAI. Veuillez configurer la clé API d'OpenAI dans les paramètres de l'IA.",
  "WhisperSpeechRecognition": "Utiliser la reconnaissance vocale OpenAI TTS",
  "WhisperTranscriptionModel": "Modèle de transcription",
  "WhisperTranscriptionModelInfo": "Vous pouvez choisir le modèle à utiliser pour la reconnaissance vocale. Plus le modèle est performant, plus il est précis, mais cela peut augmenter le coût de l'API.",
  "YoutubeAPIKey": "Clé API YouTube",
  "YoutubeInfo": "Le premier caractère du commentaire est '#' et sera ignoré.",
  "YoutubeLiveID": "ID en direct YouTube",
  "YoutubeMode": "Mode YouTube",
  "YoutubeSettings": "Paramètres YouTube",
  "characterpresetInfo": "La sélection d'un préréglage modifie l'invite de caractères.\nCmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows) pour les raccourcis.\nLa sélection d'un préréglage tout en maintenant la touche Shift enfoncée permet d'enregistrer l'invite de caractères actuelle dans le préréglage."
}
