{
  "AISettings": "Paramètres d'IA",
  "APIKeyInstruction": "Vous pouvez obtenir une clé API via le lien ci-dessous. Veuillez entrer la clé API obtenue dans le formulaire.",
  "APIKeyNotEntered": "Aucune clé API n'a été saisie.",
  "AboutThisApplication": "À propos de cette application",
  "AboutThisApplicationDescription": "Interagissez avec un personnage 3D dans votre navigateur web en utilisant un microphone, la saisie de texte et la synthèse vocale. Vous pouvez modifier le personnage (VRM), définir sa personnalité et ajuster la voix.<br />Les paramètres peuvent être modifiés en cliquant sur le bouton de menu en haut à gauche.",
  "AboutThisApplicationDescription2": "Avec AITuberKit, vous pouvez profiter de conversations avec un personnage IA directement dans votre navigateur web. Consultez les sections de paramètres pour modifier le personnage, sa personnalité et les réglages vocaux.",
  "AivisSpeechInfo": "Utilise AivisSpeech. Prend en charge uniquement le japonais. Comme il utilise une API locale, vous devez télécharger et exécuter l'application correspondant à votre environnement depuis le site ci-dessous.",
  "AivisSpeechIntonation": "Intonation",
  "AivisSpeechPitch": "Hauteur de voix",
  "AivisSpeechServerUrl": "URL du serveur AivisSpeech",
  "AivisSpeechSpeaker": "Locuteur",
  "AivisSpeechSpeed": "Vitesse de parole",
  "AnswerGenerating": "Génération de la réponse",
  "AnthropicAPIKeyLabel": "Clé API Anthropic",
  "AudioMode": "Mode audio",
  "AuthFileInstruction": "Une clé API ou un fichier JSON d'authentification est nécessaire. Obtenez-le à partir du lien ci-dessous et, s'il s'agit d'un fichier JSON, placez-le à la racine du dépôt sous le nom credentials.json.",
  "AzureAPIKeyLabel": "Clé API Azure OpenAI",
  "AzureAPIURL": "URL API Azure OpenAI",
  "AzureEndpoint": "Point de terminaison Azure",
  "AzureTTSInfo": "Utilise Azure OpenAI. Prend en charge plusieurs langues.",
  "BackgroundImage": "Image d'arrière-plan",
  "BackgroundSettings": "Paramètres d'arrière-plan",
  "BackgroundSettingsDescription": "Vous pouvez télécharger et sélectionner une image d'arrière-plan pour l'application.",
  "BasedSettings": "Paramètres de base",
  "BrowserSpeechRecognition": "Utiliser la reconnaissance vocale standard du navigateur",
  "CannotUseParameters": "Lorsque le mode API en temps réel ou le mode audio est activé, les paramètres Temperature et Max Tokens ne peuvent pas être spécifiés.",
  "CannotUseVoice": "Lorsque le mode API en temps réel ou le mode audio est activé,\nles paramètres de synthèse vocale ne sont pas nécessaires.",
  "ChangeBackgroundImage": "Changer l'image d'arrière-plan",
  "CharacterModelInfo": "Le chargement initial peut prendre du temps selon le modèle.",
  "CharacterModelLabel": "Modèle de personnage",
  "CharacterName": "Nom du personnage",
  "CharacterSettings": "Paramètres du personnage",
  "CharacterSettingsInfo": "Cette valeur sera définie comme prompt système.\nEn vous référant au prompt initial, vous pouvez contrôler les expressions et les mouvements du personnage en spécifiant des balises d'émotion. Exemple: [neutral]Bonjour![happy]Merci pour votre travail aujourd'hui!",
  "CharacterSettingsPrompt": "Prompt du personnage",
  "Characterpreset1": "Préréglage 1",
  "Characterpreset2": "Préréglage 2",
  "Characterpreset3": "Préréglage 3",
  "Characterpreset4": "Préréglage 4",
  "Characterpreset5": "Préréglage 5",
  "CharacterpresetInfo": "La sélection d'un préréglage changera le prompt du personnage.\nVous pouvez utiliser les raccourcis Cmd + Maj + 1~5 (Mac) / Ctrl + Maj + 1~5 (Windows).",
  "ChatLog": "Journal de conversation",
  "ClientID": "ID Client",
  "Close": "Fermer",
  "CohereAPIKeyLabel": "Clé API Cohere",
  "Contact": "Contact",
  "ContactDescription": "Pour toute question concernant cette application, veuillez contacter l'adresse e-mail ou le compte Twitter ci-dessous.",
  "ContinuousMic": "Entrée micro permanente",
  "ContinuousMicActive": "Entrée micro permanente active",
  "ContinuousMicInfo": "L'entrée micro redémarre automatiquement lorsque l'IA finit de parler. L'entrée est envoyée automatiquement après le délai de silence configuré.\nSi aucune reconnaissance vocale n'est effectuée dans le délai configuré, l'entrée micro permanente se désactive automatiquement. Si vous souhaitez qu'elle reste toujours active, réglez le délai d'attente de reconnaissance vocale à 0 seconde.",
  "ContinuousMicModeOff": "Le mode d'entrée micro permanente est désactivé",
  "ContinuousMicModeOn": "Le mode d'entrée micro permanente est activé",
  "ConversationContinuityMode": "Mode de continuité de conversation (bêta)",
  "ConversationContinuityModeInfo": "Mode où l'IA tente de poursuivre la conversation lorsqu'il n'y a pas de commentaires. Actuellement compatible uniquement avec OpenAI, Anthropic Claude et Google Gemini.",
  "ConversationContinuityModeInfo2": "Comme l'IA est appelée plusieurs fois par réponse, les frais d'API peuvent augmenter. Veuillez en tenir compte.",
  "ConversationContinuityModeInfo3": "Fonctionne de manière relativement stable avec gpt-4o, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet.",
  "ConversationHistory": "Historique des conversations",
  "ConversationHistoryInfo": "Les {{count}} dernières conversations sont conservées en mémoire.",
  "ConversationHistoryReset": "Réinitialiser l'historique des conversations",
  "Creator": "Informations sur le créateur",
  "CreatorDescription": "Créateur: Nike",
  "CustomAPIBody": "Corps personnalisé",
  "CustomAPIBodyInfo": "Veuillez saisir les informations du corps à inclure dans la requête API au format JSON. Les messages sont inclus automatiquement.",
  "CustomAPIDescription": "Remarque : Les messages sont automatiquement inclus dans le corps de la requête. En mode streaming, le serveur doit renvoyer text/event-stream.",
  "CustomAPIEndpoint": "Point de terminaison API personnalisé",
  "CustomAPIEndpointInfo": "Veuillez saisir l'URL du point de terminaison API auquel envoyer des requêtes POST.",
  "CustomAPIHeaders": "En-têtes personnalisés",
  "CustomAPIHeadersInfo": "Veuillez saisir les informations d'en-tête à inclure dans la requête API au format JSON.",
  "CustomAPIStream": "Mode streaming",
  "CustomAPIStreamForced": "Actuellement, le mode streaming est toujours activé.",
  "CustomVoiceTextPlaceholder": "Entrez le texte que vous souhaitez écouter",
  "DeepSeekAPIKeyLabel": "Clé API DeepSeek",
  "DefaultBackground": "Arrière-plan par défaut",
  "Description": "À propos de l'application",
  "DifyAPIKeyLabel": "Clé API Dify",
  "DifyInfo": "Dify ne prend en charge que les types chatbot ou agent.",
  "DifyInfo2": "La longueur de l'historique des conversations dépend des paramètres du chatbot Dify.",
  "DifyInfo3": "Exemple: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "Lorsque vous utilisez Dify, ce prompt système n'est pas utilisé. Veuillez le configurer dans votre chatbot Dify.",
  "Documentation": "Documentation",
  "DocumentationDescription": "Consultez l'URL ci-dessous pour des tutoriels et des instructions détaillées sur l'utilisation d'AITuberKit.",
  "DontShowIntroductionNextTime": "Ne plus afficher cette boîte de dialogue",
  "DragToReorder": "Glisser pour réorganiser",
  "EditSlideScripts": "セリフ編集",
  "ElevenLabsApiKey": "Clé API ElevenLabs",
  "ElevenLabsInfo": "Utilise l'API ElevenLabs. Prend en charge plusieurs langues. Veuillez obtenir une clé API à partir de l'URL ci-dessous.",
  "ElevenLabsVoiceId": "ID de voix ElevenLabs",
  "ElevenLabsVoiceIdInfo": "Veuillez sélectionner l'ID de voix à partir de l'URL ci-dessous.",
  "EnglishToJapanese": "Lire les mots anglais en japonais",
  "EnterPresetQuestion": "Veuillez saisir une question",
  "EnterURL": "Entrer l'URL",
  "EnterYourQuestion": "Entrez votre question ici",
  "Errors": {
    "AIAPIError": "Une erreur s'est produite lors de l'exécution de l'API IA",
    "AIInvalidProperty": "La valeur du paramètre du service d'IA est incorrecte",
    "CustomAPIError": "Une erreur s'est produite dans l'API personnalisée",
    "EmptyAPIKey": "La clé API n'est pas définie",
    "EmptyLocalLLMURL": "L'URL du LLM local n'est pas définie",
    "InvalidAIService": "Le service d'IA sélectionné est incorrect",
    "InvalidJSON": "Le format JSON est incorrect",
    "LocalLLMAPIError": "Une erreur s'est produite dans l'API du LLM local",
    "LocalLLMConnectionError": "Impossible de se connecter au serveur LLM local",
    "LocalLLMError": "Une erreur s'est produite dans le LLM local",
    "LocalLLMNotFound": "Le point de terminaison du LLM local est introuvable",
    "LocalLLMStreamError": "Une erreur s'est produite dans le traitement du flux du LLM local",
    "MethodNotAllowed": "La requête n'est pas appropriée",
    "TTSServiceError": "Une erreur s'est produite dans le service TTS {{serviceName}}: {{message}}",
    "UnexpectedError": "Une erreur inconnue s'est produite"
  },
  "ExternalLinkageMode": "Mode de liaison externe (bêta)",
  "FireworksAPIKeyLabel": "Clé API Fireworks",
  "GSVITTSBatchSize": "Taille du lot GSVI TTS (1 ~ 100, plus la valeur est élevée, plus l'inférence est rapide, mais une valeur trop élevée peut épuiser la mémoire)",
  "GSVITTSInfo": "Paramètres GSVI TTS",
  "GSVITTSModelID": "ID du modèle GSVI TTS",
  "GSVITTSServerUrl": "URL du serveur GSVI TTS",
  "GSVITTSSpeechRate": "Vitesse de parole (0.5 ~ 2.0, plus la valeur est élevée, plus c'est rapide)",
  "GoogleAPIKeyLabel": "Clé API Google Gemini",
  "GoogleTTSInfo": "Utilise Google Cloud Text-to-Speech. Prend en charge plusieurs langues.",
  "GroqAPIKeyLabel": "Clé API Groq",
  "GroqInfo": "L'API Groq est accessible directement depuis le navigateur.",
  "IncludeSystemMessages": "Inclure les messages du système",
  "IncludeTimestampInUserMessage": "Inclure un horodatage dans les messages de l'utilisateur",
  "IncludeTimestampInUserMessageInfo": "L'inclusion d'un horodatage dans les messages de l'utilisateur permet à l'IA de générer des réponses en tenant compte du temps.\nVeuillez inclure la phrase suivante dans votre prompt système:\n\n\"Lorsque les entrées de l'utilisateur sont accompagnées d'un [timestamp], celui-ci représente l'heure UTC au moment de la requête, veuillez donc tenir compte de cette heure lors de la génération de votre réponse.\"",
  "InitialSpeechTimeout": "Délai d'attente de reconnaissance vocale",
  "InitialSpeechTimeoutInfo": "Définit le temps d'attente après le début de la reconnaissance vocale jusqu'à ce que la première parole soit détectée. Si aucune parole n'est détectée dans ce délai, la reconnaissance vocale s'arrêtera automatiquement.\nSi défini à 0 secondes, le temps d'attente est illimité.",
  "InputAudio": "Audio",
  "InputText": "Texte",
  "KoeiromapInfo": "Utilise l'API Koeiromap de Koemotion. Prend en charge uniquement le japonais. Pour plus de détails, consultez ci-dessous.",
  "Language": "Paramètres de langue",
  "LanguageChoice": "Sélection de la langue",
  "LanguageModelURL": "Veuillez sélectionner le modèle de langue à partir de l'URL ci-dessous.",
  "ListeningContinuously": "En attente d'entrée vocale...",
  "Live2D": {
    "EmotionInfo": "Les émotions peuvent être spécifiées avec plusieurs valeurs séparées par des virgules. Si plusieurs sont spécifiées, une sera choisie aléatoirement.\nLes valeurs par défaut correspondent aux modèles fournis avec AITuberKit. Si vous utilisez votre propre modèle, entrez des valeurs adaptées à celui-ci.\nAprès la fin de la conversation, l'expression 'normale' sera affichée.",
    "Emotions": "Paramètres d'expressions",
    "FileInfo": "Placez le dossier du modèle Live2D que vous souhaitez utiliser dans public/live2d. Ce dossier doit contenir un fichier model3.json directement à sa racine.\nSi l'option n'apparaît pas dans la liste, rechargez la page ou vérifiez que le chemin du dossier est correct.",
    "Info": "Vous pouvez spécifier les émotions et les mouvements.\nChaque émotion est contrôlée par le prompt. Pour plus de détails, consultez 'Paramètres d'IA => Paramètres du personnage'.",
    "MotionGroups": "Paramètres des groupes de mouvements",
    "MotionGroupsInfo": "Les mouvements sont sélectionnés aléatoirement dans le groupe choisi.\nComme pour les paramètres d'expressions, configurez-les en fonction de votre modèle.\n'Au repos' correspond aux mouvements affichés après la fin d'une conversation.",
    "SelectMotionGroup": "Sélectionner un groupe de mouvements",
    "angryEmotions": "En colère",
    "angryMotionGroup": "En colère",
    "happyEmotions": "Heureux",
    "happyMotionGroup": "Heureux",
    "idleMotionGroup": "Au repos",
    "neutralEmotions": "Normal",
    "neutralMotionGroup": "Normal",
    "relaxedEmotions": "Détendu",
    "relaxedMotionGroup": "Détendu",
    "sadEmotions": "Triste",
    "sadMotionGroup": "Triste",
    "surprisedEmotions": "Surpris",
    "surprisedMotionGroup": "Surpris"
  },
  "LocalLLM": "LLM local",
  "LocalLLMInfo": "Vous devez avoir un serveur LLM local en cours d'exécution.",
  "LocalLLMInfo2": "Veuillez entrer l'URL du LLM local (avec le numéro de port) et le nom du modèle.",
  "LocalStorageReset": "Réinitialiser les paramètres",
  "LocalStorageResetButton": "Réinitialiser les paramètres",
  "LocalStorageResetInfo": "Si des variables d'environnement sont définies, leurs valeurs prévaudront. La page sera rechargée.",
  "LogSettings": "Historique des conversations",
  "MaxPastMessages": "Nombre de messages passés à conserver",
  "MaxTokens": "Nombre maximum de tokens",
  "MaxTokensInfo": "Le nombre maximum de tokens varie selon le modèle d'IA utilisé. Veuillez consulter les spécifications de chaque modèle.",
  "MessageReceiver": "Accepter les instructions externes",
  "MessageReceiverDescription": "Vous pouvez diriger les déclarations du personnage IA depuis l'extérieur en utilisant l'API.",
  "Milliseconds": "millisecondes",
  "MistralAIAPIKeyLabel": "Clé API MistralAI",
  "NijiVoiceActorId": "ID du locuteur",
  "NijiVoiceApiKey": "Clé API NijiVoice",
  "NijiVoiceEmotionalLevel": "Niveau émotionnel",
  "NijiVoiceInfo": "Utilise l'API NijiVoice. Prend en charge uniquement le japonais. Veuillez obtenir une clé API à partir de l'URL ci-dessous.",
  "NijiVoiceSoundDuration": "Durée du son",
  "NijiVoiceSpeed": "Vitesse de parole",
  "NoSpeechTimeout": "Délai de détection de silence",
  "NoSpeechTimeoutInfo": "Définit le temps après lequel l'entrée se termine automatiquement lorsqu'un silence persiste pendant l'entrée vocale.\nSi défini à 0 secondes, l'envoi automatique par détection de silence est désactivé.",
  "NotConnectedToExternalAssistant": "Non connecté à un assistant externe.",
  "OpenAIAPIKeyLabel": "Clé API OpenAI",
  "OpenAITTSInfo": "Utilise OpenAI. Prend en charge plusieurs langues. Si vous avez sélectionné OpenAI comme service d'IA, il n'est pas nécessaire de configurer la clé API ci-dessous.",
  "OpenAITTSModel": "Modèle",
  "OpenAITTSSpeed": "Vitesse de parole",
  "OpenAITTSVoice": "Type de voix",
  "OpenSendMessagePage": "Ouvrir la page d'envoi de messages",
  "OpenVRM": "Ouvrir VRM",
  "OtherSettings": "Autres",
  "PdfConvertButton": "Convertir le PDF en diapositives",
  "PdfConvertDescription": "Convertit les PDF en données pour le mode diapositives. Uniquement disponible lorsque le service d'IA sélectionné est OpenAI, Anthropic Claude ou Google Gemini.",
  "PdfConvertError": "Échec de la conversion",
  "PdfConvertFileUpload": "Sélectionner un fichier PDF",
  "PdfConvertFolderName": "Nom du dossier de sauvegarde",
  "PdfConvertLabel": "Conversion de diapositives PDF",
  "PdfConvertLoading": "Conversion en cours...",
  "PdfConvertModelSelect": "Sélectionner un modèle",
  "PdfConvertSubmitError": "Veuillez vérifier que le fichier PDF, le nom du dossier et la clé API sont configurés",
  "PdfConvertSuccess": "Conversion terminée",
  "PerplexityAPIKeyLabel": "Clé API Perplexity",
  "PleaseSelectSlide": "スライドを選択してください",
  "PresetQuestions": "Questions prédéfinies",
  "PresetQuestionsInfo": "Vous pouvez créer et enregistrer plusieurs modèles de questions à l'avance. Les questions enregistrées apparaîtront sous forme de boutons dans l'interface utilisateur et seront insérées dans la zone de saisie du chat lorsque vous cliquerez dessus.",
  "RealtimeAPIMode": "Mode API en temps réel",
  "RealtimeAPIModeContentType": "Type d'envoi",
  "RealtimeAPIModeVoice": "Type de voix",
  "RepositoryURL": "URL du dépôt:",
  "SearchGrounding": "Utiliser la fonction de recherche",
  "SearchGroundingDescription": "Lors de l'utilisation de la fonction multimodale, la fonction de recherche est automatiquement désactivée.",
  "Select": "Veuillez sélectionner",
  "SelectAIService": "Sélectionner le service d'IA",
  "SelectModel": "Sélectionner le modèle",
  "SelectedSlideDocs": "Diapositives à utiliser",
  "SendMessage": {
    "aiGenerateDescription": "L'IA génère une réponse à partir du message envoyé, puis le personnage IA prononce cette réponse. Si plusieurs messages sont envoyés, ils seront traités dans l'ordre.\nLes modèles d'IA et de voix utilisés sont ceux sélectionnés dans les paramètres d'AITuberKit.\nVous pouvez choisir d'utiliser le prompt système d'AITuberKit ou un prompt système personnalisé.\nPour inclure l'historique des conversations précédentes, incluez la chaîne [conversation_history] n'importe où dans le prompt système ou le message utilisateur.",
    "aiGenerateTitle": "Générer une réponse avec l'IA puis la faire prononcer",
    "directSendDescription": "Permet de faire prononcer directement le message envoyé par le personnage IA. Si plusieurs messages sont envoyés, ils seront traités dans l'ordre.\nLe modèle vocal utilisé est celui sélectionné dans les paramètres d'AITuberKit.",
    "directSendTitle": "Faire parler directement le personnage IA",
    "title": "Adaptateur externe AITuberKit",
    "useCurrentSystemPrompt": "Utiliser le prompt système d'AITuberKit",
    "userInputDescription": "Le message envoyé sera traité comme s'il avait été saisi dans le formulaire d'entrée d'AITuberKit. Si plusieurs messages sont envoyés, ils seront traités dans l'ordre.\nLes modèles d'IA et de voix utilisés sont ceux sélectionnés dans les paramètres d'AITuberKit.\nLe prompt système et l'historique des conversations d'AITuberKit seront utilisés.",
    "userInputTitle": "Envoyer une entrée utilisateur"
  },
  "ShowAssistantText": "Afficher la zone de réponse",
  "ShowCharacterName": "Afficher le nom du personnage dans la zone de réponse",
  "ShowCharacterPresetMenu": "Afficher le bouton du menu des préréglages de personnages",
  "ShowControlPanel": "Afficher le panneau de contrôle",
  "ShowControlPanelInfo": "L'écran de configuration peut être affiché en appuyant sur Cmd + . (Mac) / Ctrl + . (Windows).\nSi vous utilisez un smartphone, vous pouvez également appuyer longuement (environ 1 seconde) sur le coin supérieur gauche de l'écran.",
  "ShowSilenceProgressBar": "Afficher la barre de progression de détection de silence",
  "SlideMode": "Mode diapositives",
  "SlideModeDescription": "Mode où l'IA présente automatiquement des diapositives. Uniquement disponible lorsque le service d'IA sélectionné est OpenAI, Anthropic Claude ou Google Gemini.",
  "SlideSettings": "Paramètres des diapositives",
  "SourceCodeDescription1": "Le code source de cette application est disponible sur GitHub. Vous êtes libre de le modifier.",
  "SourceCodeDescription2": "Pour l'utilisation commerciale, veuillez consulter le README dans le même dépôt.",
  "SpeakerSelection": "Sélection du type de voix",
  "SpeechInputSettings": "Paramètres d'entrée vocale",
  "SpeechRecognitionMode": "Mode de reconnaissance vocale",
  "SpeechRecognitionModeDisabledInfo": "Lorsque le mode audio est activé, seule la reconnaissance vocale du navigateur est disponible.\nDe plus, en mode API en temps réel, seule la reconnaissance vocale du navigateur est disponible et la fonction de délai d'attente de reconnaissance vocale est désactivée.",
  "SpeechRecognitionModeInfo": "Vous pouvez sélectionner le mode de reconnaissance vocale.\n'Standard du navigateur' utilise la reconnaissance vocale intégrée au navigateur. 'OpenAI TTS' utilise l'API Text to Speech d'OpenAI.\nEn général, 'Standard du navigateur' est recommandé car il est plus précis et plus rapide. Cependant, si vous utilisez un navigateur comme Firefox qui ne prend pas en charge l'API WebSpeech, sélectionnez 'OpenAI TTS'.",
  "StatusOff": "État: OFF",
  "StatusOn": "État: ON",
  "StyleBeatVITS2ApiKey": "Clé API",
  "StyleBeatVITS2Length": "Vitesse de parole",
  "StyleBeatVITS2ModelID": "ID du modèle",
  "StyleBeatVITS2SdpRatio": "Ratio mixte SDP/DP",
  "StyleBeatVITS2ServerURL": "URL du serveur",
  "StyleBeatVITS2Style": "Style",
  "StyleBertVITS2Info": "Utilise Style-Bert-VITS2. Prend en charge uniquement le japonais, l'anglais et le chinois. Si vous utilisez l'API locale, vous devez télécharger et exécuter l'application correspondant à votre environnement depuis le site ci-dessous. Configurez également une clé API si nécessaire.",
  "SyntheticVoiceEngineChoice": "Sélection du moteur de synthèse vocale",
  "TechnologyIntroduction": "Introduction technologique",
  "TechnologyIntroductionDescription1": "Cette application est basée sur <b>ChatVRM</b> de pixiv, modifié. Le code source original est disponible",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "Elle utilise",
  "TechnologyIntroductionDescription4": "pour l'affichage et la manipulation des modèles 3D,",
  "TechnologyIntroductionDescription5": "et divers LLM pour la génération de texte, ainsi que",
  "TechnologyIntroductionDescription6": "et divers TTS pour la synthèse vocale. Pour plus de détails, consultez cet",
  "TechnologyIntroductionDescription7": ".",
  "TechnologyIntroductionLink1": "ici",
  "TechnologyIntroductionLink2": "article explicatif",
  "Temperature": "Température",
  "TestSelectedVoice": "Lire",
  "TestVoice": "Tester la voix",
  "TestVoiceSettings": "Test vocal",
  "Toasts": {
    "FirefoxNotSupported": "Firefoxではこの機能はサポートされていません",
    "FunctionExecuting": "{{funcName}}を実行しています",
    "FunctionExecutionFailed": "{{funcName}}の実行に失敗しました",
    "NoSpeechDetected": "音声が検出されませんでした。",
    "PresetSwitching": "{{presetName}}に切り替わりました。",
    "SpeechRecognitionError": "音声認識エラーが発生しました",
    "UsingTool": "{{toolName}}を使用中",
    "WebSocketConnectionAttempt": "WebSocket接続を試みています...",
    "WebSocketConnectionClosed": "WebSocket接続が閉じられました",
    "WebSocketConnectionError": "WebSocket接続にエラーが発生しました",
    "WebSocketConnectionSuccess": "WebSocket接続に成功しました",
    "WhisperError": "Whisperによる音声認識でエラーが発生しました"
  },
  "UpdateRealtimeAPISettings": "Mettre à jour les paramètres de l'API en temps réel",
  "UpdateRealtimeAPISettingsInfo": "Lorsque vous mettez à jour la clé API, le point de terminaison Azure, le type de voix, le modèle ou le prompt système, appuyez sur le bouton de mise à jour pour démarrer une nouvelle session WebSocket.",
  "UpdateSpeakerList": "Mettre à jour la liste des locuteurs",
  "UploadBackground": "Télécharger une image d'arrière-plan",
  "UseVideoAsBackground": "Utiliser un écran partagé ou une webcam comme arrière-plan",
  "UsingAivisSpeech": "Utiliser AivisSpeech",
  "UsingAzureTTS": "Utiliser Azure OpenAI",
  "UsingElevenLabs": "Utiliser ElevenLabs",
  "UsingGSVITTS": "Utiliser GSVI TTS",
  "UsingGoogleTTS": "Utiliser Google Text-to-Speech",
  "UsingKoeiromap": "Utiliser Koeiromap",
  "UsingNijiVoice": "Utiliser NijiVoice",
  "UsingOpenAITTS": "Utiliser OpenAI",
  "UsingStyleBertVITS2": "Utiliser Style-Bert-VITS2",
  "UsingVoiceVox": "Utiliser VOICEVOX",
  "VoiceAdjustment": "Ajustement de la voix",
  "VoiceEngineInstruction": "Veuillez sélectionner le moteur de synthèse vocale à utiliser.",
  "VoiceSettings": "Paramètres de synthèse vocale",
  "VoiceVoxInfo": "Utilise VOICEVOX. Prend en charge uniquement le japonais. Comme il utilise une API locale, vous devez télécharger et exécuter l'application correspondant à votre environnement depuis le site ci-dessous.",
  "VoicevoxIntonation": "Intonation",
  "VoicevoxPitch": "Hauteur de voix",
  "VoicevoxServerUrl": "URL du serveur VOICEVOX",
  "VoicevoxSpeed": "Vitesse de parole",
  "WhisperSpeechRecognition": "Utiliser la reconnaissance vocale OpenAI TTS",
  "WhisperTranscriptionModel": "Modèle de transcription",
  "WhisperTranscriptionModelInfo": "Vous pouvez sélectionner le modèle à utiliser pour la reconnaissance vocale. Les modèles plus performants offrent une meilleure précision, mais peuvent entraîner des coûts API plus élevés.",
  "YoutubeAPIKey": "Clé API YouTube",
  "YoutubeInfo": "Les commentaires commençant par '#' seront ignorés.",
  "YoutubeLiveID": "ID YouTube Live",
  "YoutubeMode": "Mode YouTube",
  "YoutubeSettings": "Paramètres YouTube"
}
